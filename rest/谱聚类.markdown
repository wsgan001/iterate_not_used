---
author: evo
comments: true
date: 2018-05-06 13:13:07+00:00
layout: post
link: http://106.15.37.116/2018/05/06/spectral-clustering/
slug: spectral-clustering
title: 谱聚类
wordpress_id: 5346
categories:
- 随想与反思
---

<!-- more -->

[mathjax]

**注：非原创，推荐直接看原文**


# ORIGINAL





 	
  1. aaa




# TODO





 	
  * aaa




# MOTIVE





 	
  * aaa





* * *






# 谱聚类


这是一个非常重要的聚类


## 谱和谱聚类




![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda224ab6b3.png)


谱就是一个方阵的所有特征值的全体，就是谱


## 谱分析的整体过程




![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda22f29352.png)


小于阈值的清零。

往往我们会给定一个对称的相似度度量函数，这样我们得到的这个图就是对称的相似度的图。

**利害的方法。**


## 若干概念


**这部分关于图的概念看看能不能抽出来单独总结**


![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda23954d41.png)


W是一个邻接的对称阵

第i号节点的所有的边的和叫做第i号节点的度，所以第一个样本的度，第二个样本的度等等写在对角线上就得到了一个度矩阵D。

因此W和D都是对称的。


![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda2410a8a9.png)


如何建立相似度的图呢？


## 相似度图G的建立方法




![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda24b51e29.png)





## 相似度图G的举例




![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda2542d98f.png)





## 权值比较





 	
  * ε近邻图：ε=0.3，“月牙部分”非常紧的连接了，但“高斯部分”很多都没连接。当数据有不同的“密度”时，往往发生这种问题。

 	
  * k近邻图：可以解决数据存在不同密度时有些无法连接的问题，甚至低密度的“高斯部分”与高密度的“月牙部分”也能够连接。同时，虽然两个“月牙部分”的距离比较近，但k近邻还可以把它们区分开。

 	
  * 互k近邻图：它趋向于连接相同密度的部分，而不连接不同密度的部分。这种性质介于ε近邻图和k近邻图之间。如果需要聚类不同的密度，这个性质非常有用。

 	
  * 全连接图：使用高斯相似度函数可以很好的建立权值矩阵。但缺点是建立的矩阵不是稀疏的。


总结：不知道如何选，就直接用k近邻。首先尝试使用k近邻图。


## 下面我们建立拉普拉斯矩阵


拉普拉斯矩阵及其性质


![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda296cc460.png)


事实上这样一个拉式矩阵，0一定是它的特征值，并且0有可能是k重的，k重的意思意味着这张图有k个联通分量。**什么是联通分量？**


## 拉普拉斯矩阵的定义




![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda2a36a055.png)








![](http://106.15.37.116/wp-content/uploads/2018/04/img_5ae19d28e4c2d.png)但是wii我也是强制赋值为0，因为这个有好处，我把它再第i行加起来就能得到度。






对称拉式矩阵和随机游走拉式矩阵。

为什么叫做随机游走拉式矩阵？D是第i行所有元素的和，D^{-1}W相当于对这一行的加和为1，所以随机游走的D^{-1}W相当于任何一个点给出的不只是相似度，还是转移概率，也就是我这个点转移到别的点的概率值。可以按照这个点的转移概率把它转到别的点上去，然后最终得到那个图就是它的聚类的过程。**还是没有很清楚。**




## 介绍一下谱聚类的算法的过程


比较麻烦的。

谱聚类算法：未正则拉普拉斯矩阵


![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda2af3c610.png)


因为L这个拉式矩阵是n行n列的，所以 u_k是n行一列的。（注意，前k个特征向量，排列实际上是按照特征值的从小到大排列的。如果说两个联通分量，![](http://106.15.37.116/wp-content/uploads/2018/04/img_5ae19d527b9c5.png) 那么对于0这么一个特征值，它其实就会有两个特征向量，而，正好，可以进行聚类，所以谱聚类里面是从小到大的。）

所以我可以组成矩阵U。然后我横着看，n个点，k维的行向量。用k-means进行聚类，最后的对应是：如果U中的第1行属于第三个簇，那么原始的第1个点也就属于第三个簇。

这样就完成了未正则化拉式矩阵的谱聚类算法

特征值是有物理意义的，它的物理意义是降维PCA，只不过PCA中是取最大的，但是这里是取最小的。

任何一种聚类的方式都不能通杀所有的情形，都只能适用于某些样本，只不过谱聚类可以当作参考，比如说如果我做一个聚类比谱聚类号，那么就可以说你的聚类还比较不错

**如果已经聚类好了，又新增样本，怎么聚类？这种情况下就不能使用谱聚类了，因为样本n根本不固定，所以没法算拉式矩阵。所以只能增量的去改。怎么改？**

其实我们在用密度聚类的时候，更多考虑的是簇中心，而不是去调某一个样本是什么样。


## 谱聚类算法：随机游走拉普拉斯矩阵




![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda2c065702.png)





## 谱聚类算法：对称拉普拉斯矩阵




![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda2ccd5c37.png)


那么这三个我选择哪一个呢？如果不知道选择哪一个，就选择随机游走拉式矩阵。


## 一个实例




![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda2daaee80.png)


4个特征值对应了不同的特征向量

如何自适应的去选择k值。![](http://106.15.37.116/wp-content/uploads/2018/04/img_5ae19e2ab5f20.png)从4到5跳的最大，谁的跳跃值越大，我们就选那个作为我们的k值的选取。一般而言，谱聚类可以这么选择k。


## 代码如下




![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda2f7eccb6.png)





## 聚类情况


谱聚类不是一定成功的：比如说k-means中的k选择不好，或者带宽选的不好

成功的情况：


![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda3205cca5.png)




失败的情况：




![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda32f9e58e.png)


所以写好代码之后还是需要调参的，而且，对理论有深入的理解，那么调参就能把握住

这个聚类失败，是否与分类一样？在低维的时候不好聚类，如果用Kernel 转到高维，就更好聚类了？ 不是的，这三种失败的情况我都是用的高斯相似度做的，但是仍然是失败，因为参数给的不合理。已经映射到高维上去了。


## 进一步思考




![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda33977ae9.png)


随机游走和拉普拉斯矩阵的关系


![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda3444c9ee.png)







# 谱聚类的理论推导：没有讲




## 拉普拉斯矩阵的性质：




![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda39ec0932.png)




![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda3a8c3d52.png)


正则拉普拉斯矩阵的性质


![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda3b4ab61f.png)




![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda3c0a3ad1.png)


切割图


![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda3caadf3a.png)


修正目标函数


![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda3d71b237.png)


分析分母对目标函数的影响


![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda3e8a77d6.png)


当k=2时的RatioCut


![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda3fb24555.png)


RatioCut与拉普拉斯矩阵的关系


![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda40d09702.png)


目标函数


![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda418509d0.png)


考察f的性质


![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda422e549e.png)


目标函数约束条件的放松relaxation


![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda42cd7bb6.png)


基于子图划分的结论


![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda43903734.png)


附：将子图划分从2扩展到k


![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda442f2586.png)


附：考察指示向量组成的矩阵


![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda45016c3f.png)


附：目标函数


![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda4560a541.png)




![](http://106.15.37.116/wp-content/uploads/2018/03/img_5abda4619b3a7.png)






















* * *





# COMMENT



