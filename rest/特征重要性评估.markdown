---
author: evo
comments: true
date: 2018-04-29 05:15:12+00:00
layout: post
link: http://106.15.37.116/2018/04/29/features-evaluate/
slug: features-evaluate
title: 特征重要性评估
wordpress_id: 4555
categories:
- 随想与反思
tags:
- '@NULL'
- '@todo'
---

<!-- more -->

[mathjax]


# REF





 	
  1. 《机器学习 实践应用》




# TODO





 	
  * **还是有些问题需要确认的。**

 	
  * **还有别的评估的方法吗？**




# MOTIVE





 	
  * 这个特征评估的要不要合并在别的文章里面？





* * *





# 知识前提





 	
  * 信息熵





# 为什么要对特征重要性进行评估？


实际上，每个特征对于目标列的影响程度是不同的，那么我们能不能对特征的重要性做一些评估呢？

如果可以评估的话，那么：



 	
  * 有些不重要的特征就可以去掉，这样就达到了降维的效果。

 	
  * 重要的特征可以在模型效果调优的时候就可以有所指导。


那么有哪些特征评判的方法呢？

实际上评判特征的方法还是有很多的。下面依次讲解下。**不知道现在都怎么评判特征？有什么更利害的方法吗？评判特征的本质是什么？**


# 回归模型系数判断法


对于一些线性模型来说，它们训练出的结果是一个数学公式，类似：

\[y=a_1x_1+a_2x_2+a_3x_3+\cdots \]

其中，\(a_1\)、\(a_2\)、\(a_3\) 就是我们模型最终得到的系数。

比如，我们可以对处理后的样本进行逻辑回归，得到一个模型，而这个模型里面对应每个特征都有一个系数，那么我们就可以根据这个系数来判断这个特征对于这个目标列的重要程度。**这个是不是只能说明这个特征与目标列之间有线性联系？如果是非线性联系，还能发现吗？ 关于逻辑回归再掌握下。**


# 信息熵判断法


比如下面这个数据集：

![](http://106.15.37.116/wp-content/uploads/2018/04/img_5ae5515a46082.png)

特征列共 3 种颜色，有5个样本，特征列信息熵可以计算如下：

\[H(U)=-[\frac{2}{5}\times log(\frac{2}{5})+\frac{2}{5}\times log(\frac{2}{5})+\frac{1}{5}\times log(\frac{1}{5})]\]

我们指导，一个事物的不确定性越大，那么这个事物未来发展的可能性也就越多，那么它的信息量也就越大，信息熵也越大。**这句话对不对？**

那么我们如何来理解特征的重要性和信息熵的关联呢？

这里引出一个名词：信息增益（Information Gain）。在信息增益中，衡量标准是看特征能够为分类系统带来多少信息，带来的信息越多，则该特征越重要。对于一个特征而言，系统有他和没它的时候的信息量将发生变化，而前后信息量的差就是这个特征给系统的信息量。

听着的确是有些道理的。那么具体怎么做i呢？

比如，对于上面这个数据集而言，目标列减去特征列的信息增益代表这个特征对结果的影响，公式如下：

\[G(喜好颜色)=H(性别)-H(喜好颜色)\]

**这样真的可以吗？这个真能表达这个特征给这个系统带来的信息增益吗？这个只是把特征和目标单独拿出来考虑了吧？特征和目标之间的对应不需要考虑吗？要确认下。**

在实际的使用中，我们通过遍历每个特征的信息增益来将特征排序，这个顺序既可以用来评判特征的重要性，也可以来在决策树算法中排列树的顺序（参见随机森林算法）。**在决策树算法中这个能够用来排列树吗？确认下。**




# 总结


上面两种方法的评估角度和计算方法不同，实际中需要根据具体的使用场景来决定。**具体有哪些对应的场景？有没有别的方法来评估？**









* * *





# COMMENT



