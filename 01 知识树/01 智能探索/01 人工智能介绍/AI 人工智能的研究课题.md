
# TODO


  * **只是直接复制的 wiki ，还需要慢慢补充和调整。**










目前人工智能的研究方向已经被分成几个子领域，研究人员希望一个人工智能系统应该具有某些特定能力，以下将这些能力列出并说明。


# 演绎、推理和解决问题


早期的人工智能研究人员直接模仿人类进行逐步的推理，就像是玩棋盘游戏或进行逻辑推理时人类的思考模式。到了1980和1990年代，利用概率和经济学上的概念，人工智能研究还发展了非常成功的方法处理不确定或不完整的资讯。**一直想知道怎么模仿人类进行逐步的推理的？非常成功的方法是指的哪些方法？**

对于困难的问题，有可能需要大量的运算资源，也就是发生了“可能组合爆增”：当问题超过一定的规模时，电脑会需要天文数量级的存储器或是运算时间。寻找更有效的算法是优先的人工智能研究项目。

人类解决问题的模式通常是用最快捷、直观的判断，而不是有意识的、一步一步的推导，早期人工智能研究通常使用逐步推导的方式。人工智能研究已经于这种 “次表征性的” 解决问题方法获取进展：实体化 Agent 研究强调感知运动的重要性。神经网络研究试图以模拟人类和动物的大脑结构重现这种技能。**什么是实体化Agent 研究？现在对于这种直观的判断有什么研究吗？**


# 知识表示法


本体论将知识表示为一个领域内的一组概念以及这些概念之间的关系。

知识表示是人工智能领域的核心研究问题之一，它的目标是让机器存储相应的知识，并且能够按照某种规则推理演绎得到新的知识。有许多需要解决的问题需要大量的对世界的知识，这些知识包括事先存储的先验知识和通过智能推理得到的知识。




  * 事先存储的先验知识指：人类通过某种方式告诉给机器的知识。

  * 通过智能推理得到的知识指：结合先验知识和某种特定的推理规则（逻辑推理）得到的知识。


首先，先验知识可以指描述目标，特征，种类以及目标之间的关系的知识， 也可以描述事件，时间，状态，原因和结果， 以及任何知识你想要机器存储的。

比如：今天有太阳，没有太阳就是阴天。那么以命题逻辑语言，这些知识可以被表示为：今天--->没有太阳， 没有太阳--->阴天。这是知识是先验知识，那么通过推理可以得到新知识：今天--->阴天。

由此例子可以看出，先验知识的正确性非常重要，这个例子中没有太阳就是阴天，这个命题是不严谨的，比较笼统的，因为没有太阳可能是下雨，也可能下雪。逻辑命题表示在知识表示中非常重要，逻辑推理规则是目前主要推理规则。可以在机器中用逻辑符号定义每一个逻辑命题，然后再让机器存储相应的逻辑推理规则，那么自然而然机器便可进行推理。

目前知识表达有许多困境，尚无法解决。这些困境有：


  * 创建一个完备的知识库几乎不太可能，所以知识库的资源受到限制；

  * 先验知识的正确性需要进行检验，而且先验知识有时候不一定是只有对或者错两种选择，而且有概率性的选择；


**现在有什么进展吗？**


# 规划


智能 Agent 必须能够制定目标和实现这些目标。他们需要一种方法来创建一个可预测的世界模型（将整个世界状态用数学模型表现出来，并能预测它们的行为将如何改变这个世界），这样就可以选择功效最大的行为。

在传统的规划问题中，智能 Agent 被假定它是世界中唯一具有影响力的，所以它要做出什么行为是已经确定的。但是，如果事实并非如此，它必须定期检查世界模型的状态是否和自己的预测相匹配。如果不匹配，它必须改变它的计划。因此智能代理必须具有在不确定结果的状态下推理的能力。**现在有什么说法吗？**

在多Agent中，多个Agent规划以合作和竞争的方式去完成一定的目标，使用演化算法和群体智能可以达成一个整体的突现行为目标。**什么是演化算法？什么是群体智能？**


# 学习


机器学习的主要目的是为了让机器从用户和输入数据等处获得知识，从而让机器自动地去判断和输出相应的结果。这一方法可以帮助解决更多问题、减少错误，提高解决问题的效率。对于人工智能来说，机器学习从一开始就很重要。1956年，在最初的达特茅斯夏季会议上，雷蒙德·索洛莫诺夫写了一篇关于不监视的概率性机器学习：一个归纳推理的机器。

机器学习的方法各种各样，主要分为监督学习和非监督学习两大类。




  * 监督学习指事先给定机器一些训练样本并且告诉样本的类别，然后根据这些样本的类别进行训练，提取出这些样本的共同属性或者训练一个分类器，等新来一个样本，则通过训练得到的共同属性或者分类器进行判断该样本的类别。监督学习根据输出结果的离散性和连续性，分为分类和回归两类。

  * 非监督学习是不给定训练样本，直接给定一些样本和一些规则，让机器自动根据一些规则进行分类。无论哪种学习方法都会进行误差分析，从而知道所提的方法在理论上是否误差有上限。




# 自然语言处理


自然语言处理探讨如何处理及运用自然语言，自然语言认知则是指让电脑 “懂” 人类的语言。自然语言生成系统把计算机数据转化为自然语言。自然语言理解系统把自然语言转化为计算机程序更易于处理的形式。


# 运动和控制


主条目：机器人学


#
知觉


主条目：机器感知、计算机视觉和语音识别

机器感知是指能够使用感测器所输入的数据（如照相机、麦克风、声纳以及其他的特殊感测器）然后推断世界的状态。计算机视觉能够分析视频输入。另外还有语音识别[19]、人脸辨识和物体辨识。


# 社交


主条目：情感计算

情感和社交技能对于一个智能agent是很重要的。首先，通过了解他们的动机和情感状态，代理人能够预测别人的行动（这涉及要素博弈论、决策理论以及能够塑造人的情感和情绪感知能力检测）。此外，为了良好的人机交互，智能代理人也需要表现出情绪来。至少它必须出现礼貌地和人类打交道。至少，它本身应该有正常的情绪。什么是要素博弈论？


# 创造力




主条目：计算机创造力

一个人工智能的子领域，代表了理论（从哲学和心理学的角度）和实际（通过特定的实现产生的系统的输出是可以考虑的创意，或系统识别和评估创造力）所定义的创造力。相关领域研究的包括了人工直觉和人工想像。**现在有什么发展吗？**


# 伦理管理


史蒂芬·霍金、比尔盖茨、马斯克、 Jaan Tallinn 以及 Nick Bostrom 等人都对于人工智能技术的未来公开表示忧心，人工智能若在许多方面超越人类智能水平的智能、不断更新、自我提升，进而获取控制管理权，人类是否有足够的能力及时停止人工智能领域的“军备竞赛”，能否保有最高掌控权，现有事实是：机器常失控导致人员伤亡，这样的情况是否会更加扩大规模出现，历史显然无法给出可靠的乐观答案。特斯拉电动车马斯克（Elon Musk）在麻省理工学院（MIT）航空航天部门百年纪念研讨会上称人工智能是“召唤恶魔”行为，英国发明家Clive Sinclair认为一旦开始制造抵抗人类和超越人类的智能机器，人类可能很难生存，盖茨同意马斯克和其它人所言，且不知道为何有些人不担忧这个问题。

DeepMind的人工智能（AI）系统在2016年“AlphaGo”对战韩国棋王李世乭获胜，开发商表示在内部设立伦理委员会，针对人工智能的应用制定政策，防范人工智能沦为犯罪开发者。

科技进步，人工智能科技产生 “自主武器” 军备竞赛已悄悄展开，英国、以色列与挪威，都已部署自主导弹与无人操控的无人机，具 “射后不理”（fire-and-forget）能力的导弹，多枚导弹还可互相沟通，分享找到攻击目标。这些武器还未被大量投入，但很快就会出现在战场上，且并非使用人类所设计的程序，而是完全利用机器自行决策。 霍金等人在英国独立报发表文章警告未来人工智能可能会比人类金融市场、科学家、人类领袖更能操纵人心、甚至研发出人们无法理解的武器。专家恐发展到无法控制的局面，援引联合国禁止研发某些特定武器的“特定常规武器公约”加以限制。新南威尔士大学（New South Wales）人工智能的沃尔什（Toby Walsh）教授认为这是一种欺骗，因为机器无区别战敌和平民的技术。**甚至研发出人们无法理解的武器 厉害了。**


# 经济冲击


据CNN财经网数字媒体未来学家兼Webbmedia集团创始人艾米·韦伯（Amy Webb）；美国在线...等纷纷预测一些即将被机器人取代的职业，日本野村总合研究所也与英国牛津大学的研究学者共同调查指出，10至20年后，日本有49%的职业(235种职业)可能会被机械和人工智能取代而消失，直接影响约达2500万人，例如：超市店员、一般事务员、计程车司机、收费站运营商和收银员、市场营销人员、客服人员、制造业工人、金融中间人和分析师、新闻记者、电话公司职员、麻醉师、士兵和保安、律师、医生、软件开发者和操盘手、股票交易员等等高薪酬的脑力职业将最先受到冲击。

2017年6月份马云在美国底特律举行“链接世界”（Gateway 17）产业大会，会上提出人工智能可能导致第三次世界大战，因为前两次产业革命都导致两次大战，战争原因并非这些创新发明本身，而是发明对社会上许多人的生活方式冲击处理不当，新科技在社会上产生新工作也取代旧工作，产生了新的输家和赢家，若是输家的人数太多将造成一股社会不稳的能量而这股能量被有心人利用可能导致各种事件。他认为各国应该强制订定规定AI机器只能用于人类不能做的工作，避免短时间大量人类被取代的失业大潮，但马云没有提出这种世界性规定将如何实现并确保遵守的细节方案。

数据科学和人工智能被哈佛商业评论称为《二十一世纪最Sexy的职业》，人才只能需求量大，鼓励了不少大学诸如伯克利大学专门成立数据科学系。硅谷和纽约为主的《The Data Incubator》公司,2012年成立，焦点是数据科学，大数据，和人工智能企业培训，提供国际大数据培训服务。







# REF
