## 第 17 章 使用期物处理并发

抨击线程的往往是系统程序员，他们考虑的使用场景对一般的应用程序员来说，也许 一生都不会遇到……应用程序员遇到的使用场景， 99% 的情况下只需知道如何派生 一堆独立的线程，然后用队列收集结果。 1

——Michele Simionato 深度思考 Python 的人

1摘自 Michele Simionato 发表的文章“Threads, processes and concurrency in Python: some

thoughts” (<http://www.artima.com/weblogs/viewpost.jsp?thread=299551>)，畐ij标题为'“Removing the hype around the multicore (non) revolution and some (hopefully) sensible comment about threads and other forms of concurrency”。

本章主要讨论 Python 3.2 引入的 concurrent.futures 模块，从 PyPI 中安装 futures 包 (<https://pypi.python.org/pypi/futures/>)之后，也能在 Python 2.5 及以上版本中使用这个库。

这个库封装了前面的引文中 Michele Simionato 所述的模式，特别易于使用。

这一章还会介绍“期物”(future) 2的概念。期物指一种对象，表示异步执行的操作。这个 概念的作用很大，是 concurrent.futures 模块和 asyncio 包(第 18 章讨论)的基 础。

2“期物”是我自创的词，其中的“物”是指“物件”(object，也就是对象)。起初读者可能不明其意，可与期货、期权和期 房对比理解。一译者注

下面举个示例，作为引子。

### 17.1 示例：网络下载的三种风格

#### 为了高效处理网络I/O,需要使用并发，因为网络有很高的延迟，所以为了不浪费CPU周 期去等待，最好在收到网络响应之前做些其他的事。

为了通过代码说明这一点，我写了三个示例程序，从网上下载 20 个国家的国旗图像。第 一个示例程序 flags.py 是依序下载的：下载完一个图像，并将其保存在硬盘中之后，才请 求下一个图像。另外两个脚本是并发下载的：几乎同时请求所有图像，每下载完一个文件

就保存一个文件。 flags_threadpool .py 脚本使用 concurrent.futures 模块，而 flags_asyncio.py 脚本使用 asyncio 包。

示例 17-1 是运行这三个脚本得到的结果，每个脚本都运行三次。我还在 YouTube 上发布 了一个 73 秒的视频([https://www+youtube+com/watch?v=A9e9Cy1UkME](https://www.youtube.com/watch?v=A9e9Cy1UkME))，让你观看这些 脚本的运行情况，你会看到一个 OS X Finder 窗口，显示运行过程中保存的国旗图像文 件。这些脚本从 flupy.org 下载图像，而这个网站架设在 CDN 之后，因此第一次运行时可 能要等很久才能看到结果。示例 17-1 中显示的结果是运行几次之后收集的，因此 CDN 中 己经有了缓存。

示例 17-1 运行 flags.py、flags_threadpool.py 和 flags_asyncio.py 脚本得到的结果

$ python3 flags.py

BD BR CD CN DE EG ET FR ID IN IR JP MX NG PH PK RU TR US VN O 20 flags downloaded in 7.26s ©

$ python3 flags.py

BD BR CD CN DE EG ET FR ID IN IR JP MX NG PH PK RU TR US VN 20 flags downloaded in 7.20s $ python3 flags.py

BD BR CD CN DE EG ET FR ID IN IR JP MX NG PH PK RU TR US VN 20 flags downloaded in 7.09s $ python3 flags_threadpool.py

DE BD CN JP ID EG NG BR RU CD IR MX US PH FR PK VN IN ET TR 20 flags downloaded in 1.37s ©

$ python3 flags_threadpool.py

EG BR FR IN BD JP DE RU PK PH CD MX ID US NG TR CN VN ET IR 20 flags downloaded in 1.60s $ python3 flags_threadpool.py

BD DE EG CN ID RU IN VN ET MX FR CD NG US JP TR PK BR IR PH 20 flags downloaded in 1.22s $ python3 flags_asyncio.py ©

BD BR IN ID TR DE CN US IR PK PH FR RU NG VN ET MX EG JP CD 20 flags downloaded in 1.36s $ python3 flags_asyncio.py

RU CN BR IN FR BD TR EG VN IR PH CD ET ID NG DE JP PK MX US 20 flags downloaded in 1.27s $ python3 flags_asyncio.py

RU IN ID DE BR VN PK MX US IR ET EG NG BD FR CN JP PH CD TR © 20 flags downloaded in 1.42s

#### ❶ 每次运行脚本后，首先显示下载过程中下载完毕的国家代码，最后显示一个消息，说 明耗时。

❷ flags+py 脚本下载 20 个图像平均用时 7+18 秒。

❸ flags_threadpool+py 脚本平均用时 1+40 秒。

❹ flags_asynci o+py 脚本平均用时 1+35 秒。

❺ 注意国家代码的顺序：对并发下载的脚本来说，每次下载的顺序都不同。

两个并发下载的脚本之间性能差异不大，不过都比依序下载的脚本快 5 倍多。这只是一个 特别小的任务，如果把下载的文件数量增加到几百个，并发下载的脚本能比依序下载的脚

本快 20 倍或更多。

![img](08414584Python-79.jpg)



在公网中测试HTTP并发客户端可能不小心变成拒绝服务(Denial-of-Service，DoS)攻击，或者有这么做的嫌疑。我们可以像示例17-1那样做，因为那 三个脚本被硬编码，限制只发起 20 个请求。如果想大规模测试 HTTP 服务器，应该 自己架设测试服务器。在本书的 GitHub 仓库中

([https://github+com/fluentpython/example-code](https://github.com/fluentpython/example-code)) ， 1 7-futures/countries/README+rst 文件 (https://github+com/fluentpython/example-code/blob/master/17-futures/countries/README+rst)说明了如何在本地架设Nginx服务器。

下面我们来分析示例17-1测试的两个脚本-flags+py和flags_threadpool+py，看看它们的

实现方式。第三个脚本 flags_asynci o+py 留到第 18 章再分析。将这三个脚本一起演示是为 了表明一个观点：在 I/O 密集型应用中，如果代码写得正确，那么不管使用哪种并发策略 (使用线程或 asyncio 包)，吞吐量都比依序执行的代码高很多。

下面分析代码。

17.1.1 依序下载的脚本

示例 17-2 不太有吸引力，不过实现并发下载的脚本时会重用其中的大部分代码和设置 因此值得分析一下。

为了清楚起见， 说明代码的基本结构，



示例 17-2 没有处理异常。稍后会处理异常，这里我们想集中 以便和并发下载的脚本进行对比。

示例17-2 flags+py：依序下载的脚本；另外两个脚本会重用其中几个函数

'MX PH VN ET EG DE IR TR CD FR').split() &

BASE_URL = '<http://flupy.org/data/flags'>    ©

DEST_DIR = 'downloads/' ©

def save_flag(img, filename):❺

path = os.path.join(DEST_DIR, filename) with open(path, 'wb') as fp:

fp.write(img)

def get_flag(cc):    ©

url = '{}/{cc}/{cc}.gif'.format(BASE_URL, cc=cc.lower()) resp = requests.get(url) return resp.content

def show(text):    &

print(text, end=' ') sys.stdout.flush()

def download_many(cc_list):❻ for cc in sorted(cc_list): ©

image = get_flag(cc) show(cc)

save_flag(image, cc.lower() + '.gif') return len(cc_list)

def main(download_many): © t0 = time.time() count = download_many(POP20_CC) elapsed = time.time() - t0 msg = '\n{} flags downloaded in {:.2f}s print(msg.format(count, elapsed))

if __name__ == '__main__': main(download_many) ®

❹ 保存图像的本地目录。

❺把img (字节序列)保存到DEST_DIR目录中，命名为filename。

❻指定国家代码，构建URL，然后下载图像，返回响应中的二进制内容。

❼显示一个字符串，然后刷新sys.stdout，这样能在一行消息中看到进度。在Python 中得这么做，因为正常情况下，遇到换行才会刷新 stdout 缓冲。

❽ download_many 是与并发实现比较的关键函数。

❾ 按字母表顺序迭代国家代码列表，明确表明输出的顺序与输入一致。返回下载的国旗 数量。

❿ main 函数记录并报告运行 download_many 函数之后的耗时。

G main函数必须调用执行下载的函数；我们把download_many函数当作参数传给main 函数，这样 main 函数可以用作库函数，在后面的示例中接收 download_many 函数的其 他实现。

Kenneth Reitz开发的requests库可通过PyPI安装 ([https://pypi+python+org/pypi/requests](https://pypi.python.org/pypi/requests)) ，比 Python 3 标准库中的 urllib.request 模 块更易于使用。其实， requests 库提供的 API 更符合 Python 的习惯用法，而且与 Python 2+6 及以上版本兼容。因为 Python 2 中删除了 urllib2， Python 3 又使用了其 他名称，所以不管使用哪一版Python，使用requests库都更方便。

flags+py 脚本中没有什么新知识，只是与其他脚本对比的基准，而且我把它作为一个库使



用，避免实现其他脚本时重复编写代码。下面分析使用 concurrent.futures 模块重新 实现的版本。

17.1.2 使用 concurrentfutures 模块下载

concurrent.futures 模块的主要特色是 ThreadPoolExecutor 和

ProcessPoolExecutor 类，这两个类实现的接口能分别在不同的线程或进程中执行可调

用的对象。这两个类在内部维护着一个工作线程或进程池，以及要执行的任务队列。不

过，这个接口抽象的层级很高，像下载国旗这种简单的案例，无需关心任何实现细节。

示例 17-3 展示如何使用 ThreadPoolExecutor.map 方法，以最简单的方式实现并发下 载。

示例 17-3 flags_threadpool+py:使用 futures.ThreadPoolExecutor 类实现多线程

下载的脚本

def download_one(cc): © image = get_flag(cc) show(cc)

save_flag(image, cc.lower() + '.gif') return cc

def download_many(cc_list):

workers = min(MAX_WORKERS, len(cc_list)) ©

with futures.ThreadPoolExecutor(workers) as executor: ©

res = executor.map(download_one, sorted(cc_list)) © return len(list(res)) O

if __name__ == '__main__': main(download_many)❻

❶ 重用 flags 模块(见示例 17-2)中的几个函数。

❷ 设定 ThreadPoolExecutor 类最多使用几个线程。

❸ 下载一个图像的函数；这是在各个线程中执行的函数。

❹设定工作的线程数量：使用允许的最大值(MAX_WORKERS)与要处理的数量之间较小 的那个值，以免创建多余的线程。

❺使用工作的线程数实例化ThreadPoolExecutor类；executor.__exit__方法会调

用 executor.shutdown(wait=True) 方法，它会在所有线程都执行完毕前阻塞线程。

❻ map 方法的作用与内置的 map 函数类似，不过 download_one 函数会在多个线程中并 发调用； map 方法返回一个生成器，因此可以迭代，获取各个函数返回的值。

❼ 返回获取的结果数量；如果有线程抛出异常，异常会在这里抛出，这与隐式调用 next() 函数从迭代器中获取相应的返回值一样。

❽ 调用 flags 模块中的 main 函数，传入 download_many 函数的增强版。

注意，示例 17-3 中的 download_one 函数其实是示例 17-2 中 download_many 函数的 for 循环体。编写并发代码时经常这样重构：把依序执行的 for 循环体改成函数，以便 并发调用。

我们用的库叫concurrency.futures，可是在示例17-3中没有见到期物，因此你可能

想知道期物在哪里。下一节会解答这个问题。

17.1.3 期物在哪里

期物是 concurrent.futures 模块和 asyncio 包的重要组件，可是，作为这两个库的用

户，我们有时却见不到期物。示例 17-3 在背后用到了期物，但是我编写的代码没有直接

使用。这一节概述期物，还会举一个例子，展示用法。

从Python3.4起，标准库中有两个名为Future的类：concurrent.futures .Future和 asyncio.Future。这两个类的作用相同：两个Future类的实例都表示可能己经完成或 者尚未完成的延迟计算。这与 Twisted 引擎中的 Deferred 类、 Tornado 框架中的 Future 类，以及多个 JavaScript 库中的 Promise 对象类似。

期物封装待完成的操作，可以放入队列，完成的状态可以查询，得到结果(或抛出异常)

后可以获取结果(或异常)。

我们要记住一件事：通常情况下自己不应该创建期物，而只能由并发框架

(concurrent.futures或asyncio)实例化。原因很简单：期物表示终将发生的事

情，而确定某件事会发生的唯一方式是执行的时间己经排定。因此，只有排定把某件事交

给 concurrent.futures.Executor 子类处理时，才会创建

concurrent.futures.Future 实例。例如， Executor.submit() 方法的参数是一个可 调用的对象，调用这个方法后会为传入的可调用对象排期，并返回一个期物。

客户端代码不应该改变期物的状态，并发框架在期物表示的延迟计算结束后会改变期物的

状态，而我们无法控制计算何时结束。

这两种期物都有 .done() 方法，这个方法不阻塞，返回值是布尔值，指明期物链接的可 调用对象是否己经执行。客户端代码通常不会询问期物是否运行结束，而是会等待通知。 因此，两个 Future 类都有 .add_done_callback() 方法：这个方法只有一个参数，类 型是可调用的对象，期物运行结束后会调用指定的可调用对象。

此外，还有 .result() 方法。在期物运行结束后调用的话，这个方法在两个 Future 类 中的作用相同：返回可调用对象的结果，或者重新抛出执行可调用的对象时抛出的异常。 可是，如果期物没有运行结束， result 方法在两个 Future 类中的行为相差很大。对 concurrency.futures.Future 实例来说，调用 f.result() 方法会阻塞调用方所在的 线程，直到有结果可返回。此时， result 方法可以接收可选的 timeout 参数，如果在指 定的时间内期物没有运行完毕，会抛出 TimeoutError 异常。读到 18.1.1 节你会发 现， asyncio.Future.result 方法不支持设定超时时间，在那个库中获取期物的结果最 好使用 yield from 结构。不过，对 concurrency.futures.Future 实例不能这么做。

这两个库中有几个函数会返回期物，其他函数则使用期物，以用户易于理解的方式实现自 身。使用 17-3 中的 Executor.map 方法属于后者：返回值是一个迭代器，迭代器的 __next__ 方法调用各个期物的 result 方法，因此我们得到的是各个期物的结果，而非 期物本身。

为了从实用的角度理解期物，我们可以使用 concurrent.futures.as_completed 函数 ([https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.as_completed](https://docs.python.org/3/library/concurrent.futures.html%23concurrent.futures.as_completed))重

写示例 17-3。这个函数的参数是一个期物列表，返回值是一个迭代器，在期物运行结束 后产出期物。

为了使用 futures.as_completed 函数，只需修改 download_many 函数，把较抽象的

executor.map 调用换成两个 for 循环：一个用于创建并排定期物，另一个用于获取期物

的结果。同时，我们会添加几个 print 调用，显示运行结束前后的期物。修改后的

download_many 函数如示例 17-4，代码行数由 5 变成 17，不过现在我们能一窥神秘的期 物了。其他函数不变，与示例 17-3 中的一样。

示例 17-4 flags_threadpool_ac+py：把downloadjmany 函数中的 executor.map 方法 换成 executor.submit 方法和 futures.as_completed 函数

def download_many(cc_list): cc_list = cc_list[:5] O

with futures.ThreadPoolExecutor(max_workers=3) as executor: © to_do = []

for cc in sorted(cc_list): ©

future = executor.submit(download_one, cc) © to_do.append(future) ©

msg = 'Scheduled for {}: {}' print(msg.format(cc, future)) © results = []

for future in futures.as_completed(to_do): O res = future.result() ❻ msg = '{} result: {!r}' print(msg.format(future, res)) © results.append(res) return len(results)

❶ 这次演示只使用人口最多的 5 个国家。

❷ 把 max_workers 硬编码为 3，以便在输出中观察待完成的期物。

❸ 按照字母表顺序迭代国家代码，明确表明输出的顺序与输入一致。

❹ executor.submit 方法排定可调用对象的执行时间，然后返回一个期物，表示这个待

执行的操作。

❺ 存储各个期物，后面传给 as_completed 函数。

❻ 显示一个消息，包含国家代码和对应的期物。

❼ as_completed 函数在期物运行结束后产出期物。

❽ 获取该期物的结果。

❾ 显示期物及其结果。

注意，在这个示例中调用 future.result() 方法绝不会阻塞，因为 future 由 as_completed 函数产出。运行示例 17-4 得到的输出如示例 17-5 所示。

示例 17-5 flags_threadpool_ac.py 脚本的输出

$ python3 flags_threadpool_ac.py

Scheduled for BR: <Future at 0x100791518 state=running> O Scheduled for CN: <Future at 0x100791710 state=running>

Scheduled for ID: <Future at 0x100791a90 state=running>

Scheduled for IN: 〈Future at 0x101807080 state=pending> ©

Scheduled for US: <Future at 0x101807128 state=pending>

CN <Future at 0x100791710 state=finished returned str> result: 'CN'

BR ID <Future at 0x100791518 state=finished returned str> result: 'BR' o <Future at 0x100791a90 state=finished returned str> result: 'ID'

IN <Future at 0x101807080 state=finished returned str> result: 'IN'

US <Future at 0x101807128 state=finished returned str> result: 'US'

5 flags downloaded in 0.70s

❶ 排定的期物按字母表排序；期物的 repr() 方法会显示期物的状态：前三个期物的状

态是running，因为有三个工作的线程。

❷后两个期物的状态是pending，等待有线程可用。

❸ 这一行里的第一个 CN 是运行在一个工作线程中的 download_one 函数输出的，随后的 内容是 download_many 函数输出的。

❹ 这里有两个线程输出国家代码，然后主线程中的 download_many 函数输出第一个线程 的结果。

多次运行flags_threadpool_ac+py脚本，看到的结果有所不同。如果把 max_workers 参数的值增大到 5，结果的顺序变化更多。把 max_workers 参数的值 设为 1，代码依序运行，结果的顺序始终与调用 submit 方法的顺序一致。

我们分析了两个版本的使用 concurrent.futures 库实现的下载脚本：使用 ThreadPoolExecutor.map 方法的示例 17-3 和使用 futures.as_completed 函数的示 例 17-4。如果你对 flags_asynci o+py 脚本的代码好奇，可以看一眼第 18 章中的示例 18-5。

严格来说，我们目前测试的并发脚本都不能并行下载。使用 concurrent.futures 库实

现的那两个示例受GIL (Global Interpreter Lock，全局解释器锁)的限制，而 flags_asyncio+py 脚本在单个线程中运行。 读到这里，你可能会对前面做的非正规基准测试有下述疑问。

•既然Python线程受GIL的限制，任何时候都只允许运行一个线程，那么 flags_threadpool+py 脚本的下载速度怎么会比 flags+py 脚本快 5 倍？

• flags_asyncio+py脚本和flags+py脚本都在单个线程中运行，前者怎么会比后者快5

倍？

第二个问题在 18+3 节解答。

GIL 几乎对 I/O 密集型处理无害，原因参见下一节。

### 17.2    阻塞型I/O和GIL

CPython解释器本身就不是线程安全的，因此有全局解释器锁(GIL)，一次只允许使用 一个线程执行 Python 字节码。因此，一个 Python 进程通常不能同时使用多个 CPU 核

心。 5

I5这是CPython解释器的局限，与Python语言本身无关。Jython和IronPython没有这种限制。不过，目前最快的Python 解释器PyPy也有GIL。

编写Python代码时无法控制GIL;不过，执行耗时的任务时，可以使用一个内置的函数或 一个使用C语言编写的扩展释放GIL。其实，有个使用C语言编写的Python库能管理 GIL，自行启动操作系统线程，利用全部可用的CPU核心。这样做会极大地增加库代码的 复杂度，因此大多数库的作者都不这么做。

然而，标准库中所有执行阻塞型 I/O 操作的函数，在等待操作系统返回结果时都会释放 GIL。这意味着在Python语言这个层次上可以使用多线程，而I/O密集型Python程序能从 中受益：一个Python线程等待网络响应时，阻塞型I/O函数会释放GIL，再运行一个线 程。

因此 David Beazley 才说： “Python 线程毫无作用。 ”6

6出自“Generators: The Final Frontier” (<http://www.dabeaz.com/finalgenerator/>)，第 106 张幻灯片。

Python标准库中的所有阻塞型I/O函数都会释放GIL，允许其他线程运 行。time.sleep()函数也会释放GIL。因此，尽管有GIL，Python线程还是能在I/O

密集型应用中发挥作用。

下面简单说明如何在 CPU 密集型作业中使用 concurrent.futures 模块轻松绕开 GIL。

### 17.3 使用concurrentfutures模块启动进程

concurrent.futures 模块的文档

([https://docs+python.org/3/library/concurrent.futures+html](https://docs.python.org/3/library/concurrent.futures.html))畐ij标题是“Launching parallel tasks” (执行并行任务)。这个模块实现的是真正的并行计算，因为它使用 ProcessPoolExecutor 类把工作分配给多个 Python 进程处理。因此，如果需要做 CPU 密集型处理，使用这个模块能绕开GIL，利用所有可用的CPU核心。

ProcessPoolExecutor 和 ThreadPoolExecutor 类都实现了通用的 Executor 接口，因 此使用 concurrent.futures 模块能特别轻松地把基于线程的方案转成基于进程的方 案。

下载国旗的示例或其他 I/O 密集型作业使用 ProcessPoolExecutor 类得不到任何好处。 这一点易于验证，只需把示例 17-3 中下面这几行：

def download_many(cc_list):

workers = min(MAX_WORKERS, len(cc_list))

with futures.ThreadPoolExecutor(workers) as executor:

改成：

def download_many(cc_list):

with futures.ProcessPoolExecutor() as executor:

对简单的用途来说，这两个实现 Executor 接口的类唯一值得注意的区别

是， ThreadPoolExecutor.__init__ 方法需要 max_workers 参数，指定线程池中线程 的数量。在 ProcessPoolExecutor 类中，那个参数是可选的，而且大多数情况下不使用 ——默认值是 os.cpu_count() 函数返回的 CPU 数量。这样处理说得通，因为对 CPU 密 集型的处理来说，不可能要求使用超过 CPU 数量的职程。而对 I/O 密集型处理来说，可 以在一个 ThreadPoolExecutor 实例中使用 10 个、100 个或 1000 个线程；最佳线程数 取决于做的是什么事，以及可用内存有多少，因此要仔细测试才能找到最佳的线程数。

经过几次测试，我发现使用 ProcessPoolExecutor 实例下载 20 面国旗的时间增加到了 1.8 秒，而原来使用 ThreadPoolExecutor 的版本是 1.4 秒。主要原因可能是，我的电脑 用的是四核CPU，因此限制只能有4个并发下载，而使用线程池的版本有20个工作的线 程。

ProcessPoolExecutor 的价值体现在 CPU 密集型作业上。我用两个 CPU 密集型脚本做 了一些性能测试。

arcfour_futures.py

这个脚本(代码清单参见示例A-7)纯粹使用Python实现RC4算法。我加密并解密 了 12 个字节数组，大小从 149KB 到 384KB 不等。

sha_futures+py

这个脚本（代码清单参见示例A-9）使用标准库中的hashlib模块（使用OpenSSL 库实现）实现 SHA-256 算法。我计算了 12 个 1MB 字节数组的 SHA-256 散列值。

这两个脚本除了显示汇总结果之外，没有使用I/O。构建和处理数据的过程都在内存中完 成，因此 I/O 对执行时间没有影响。

我运行了 64 次 RC4 示例， 48 次 SHA 示例，平均时间如表 17-1 所示。统计的时间中包含 派生工作进程的时间。

表17-1：在配有Intel Core i7 2.7 GHz四核CPU的设备中，使用Python 3.4运行RC4和

SHA示例，分别使用1~4个职程得到的时间和提速倍数

| 职程数 | 运行RC4示例的时间 | RC4示例的提速倍数 | 运行SHA示例的时间 | SHA示例的提速倍数 |
| ------ | ----------------- | ----------------- | ----------------- | ----------------- |
| 1      | 11+48s            | 1+00X             | 22+66s            | 1+00X             |
| 2      | 8+65s             | 1+33x             | 14+90s            | 1+52x             |
| 3      | 6+04s             | 1+90x             | 11+91s            | 1+90x             |
| 4      | 5+58s             | 2+06x             | 10+89s            | 2+08x             |

可以看出，对加密算法来说，使用 ProcessPoolExecutor 类派生 4 个工作的进程后（如 果有 4 个 CPU 核心的话），性能可以提高两倍。

对那个纯粹使用 Python 实现的 RC4 示例来说，如果使用 PyPy 和 4 个职程，与使用 CPython 和 4 个职程相比，速度能提高 3+8 倍。以表 17-1 中使用 CPython 和一个职程的运 行时间为基准，速度提升了 7+8 倍。

如果使用Python处理CPU密集型工作，应该试试PyPy （[http://pypy+org](http://pypy.org)）。使 用 PyPy 运行 arcfour_futures+py 脚本，速度快了 3+8~5+1 倍；具体的倍数由职程的数量 决定。我测试时使用的是 PyPy 2+4+0，这一版与 Python 3+2+5 兼容，因此标准库中有 concurrent.futures 模块。

下面通过一个演示程序来研究线程池的行为。这个程序会创建一个包含 3 个职程的线程 池，运行 5 个可调用的对象，输出带有时间戳的消息。

### 17.4    实验 Executor.map 方法

若想并发运行多个可调用的对象，最简单的方式是使用示例 17-3 中见过的 Executor.map 方法。示例 17-6 中的脚本演示了 Executor.map 方法的某些运作细节。 这个脚本的输出在示例 17-7 中。

#### 示例 17-6 demo_executor_map.py:简单演示 ThreadPoolExecutor 类的 map 方法

from time import sleep, strftime from concurrent import futures

def display(*args): O

print(strftime('[%H:%M:%S]'), end=' ') print(*args)

def loiter(n): ©

msg = '{}loiter({}): doing nothing for {}s...'

display(msg.format('\t'*n, n, n))

sleep(n)

msg = '{}loiter({}): done.' display(msg.format('\t'*n, n)) return n * 10 &

def main():

display('Script starting.')

executor = futures.ThreadPoolExecutor(max_workers=3) o results = executor.map(loiter, range(5))❺ display('results:', results) ©

display('Waiting for individual results:') for i, result in enumerate(results): O

display('result {}: {}'.format(i, result))

main()

#### ❶ 这个函数的作用很简单，把传入的参数打印出来，并在前面加上 [HH:MM:SS] 格式的

时间戳。

❷ loiter 函数什么也没做，只是在开始时显示一个消息，然后休眠 n 秒，最后在结束时 再显示一个消息；消息使用制表符缩进，缩进的量由 n 的值确定。

❸ loiter 函数返回 n * 10，以便让我们了解收集结果的方式。

#### ❹ 创建 ThreadPoolExecutor 实例，有 3 个线程。

#### ❺把五个任务提交给executor (因为只有3个线程，所以只有3个任务会立即开 始：loiter(0)、loiter(1)和 loiter(2));这是非阻塞调用。

#### ❻ 立即显示调用 executor.map 方法的结果：一个生成器，如示例 17-7 中的输出所示。

#### ❼for循环中的enumerate函数会隐式调用next(results)，这个函数又会在(内部) 表示第一个任务(loiter(0))的_f期物上调用_f.result()方法。result方法会阻

塞，直到期物运行结束，因此这个循环每次迭代时都要等待下一个结果做好准备。

我建议你运行示例 17-6，看着结果逐渐显示出来。此外，还可以修改

ThreadPoolExecutor 构造方法的 max_workers 参数，以及 executor.map 方法中

range 函数的参数；或者自己挑选几个值，以列表的形式传给 map 方法，得到不同的延 迟。

示例 17-7 是运行示例 17-6 得到的输出示例。

示例 17-7 示例 17-6 中 demo_executor_map.py 脚本的运行示例

$ python3 demo_executor_map.py [15:56:50] Script starting. O [15:56:50] loiter(0): doing nothing for 0s... ©

[15:56:50] loiter(0): done.

[15:56:50]    loiter(1): doing nothing for 1s... ©

[15:56:50]    loiter(2): doing nothing for 2s...

[15:56:50] results: 〈generator object result_iterator at 0x106517168> © [15:56:50]    loiter(3): doing nothing for 3s...❺

[15:56:50] Waiting for individual results:

[15:56:50] result 0: 0 ©

[15:56:51]    loiter(1): done. ©

[15:56:51]    loiter(4): doing nothing for 4s...

[15:56:51] result 1: 10 ©

[15:56:52]    loiter(2): done. ©

[15:56:52] result 2: 20

[15:56:53]    loiter(3): done.

[15:56:53] result 3: 30

[15:56:55]    loiter(4): done. ©

[15:56:55] result 4: 40

#### ❶ 这次运行从 15:56:50 开始。

#### ❷第一个线程执行loiter(0)，因此休眠0秒，甚至会在第二个线程开始之前就结束，

不过具体情况因人而异。 7

7具体情况因人而异：对线程来说，你永远不知道某一时刻事件的具体排序；有可能在另一台设备中会看到

loiter(1)在loiter(0)结束之前开始，这是因为sleep函数总会释放GIL。因此，即使休眠0秒，Python也可能

会切换到另一个线程。

#### ❸ loiter(1) 和 loiter(2) 立即开始(因为线程池中有三个职程，可以并发运行三个函 数)。

❹这一行表明，executor.map方法返回的结果(results)是生成器；不管有多少任 务，也不管 max_workers 的值是多少，目前不会阻塞。

❺ loiter(0) 运行结束了，第一个职程可以启动第四个线程，运行 loiter(3)。

❻ 此时执行过程可能阻塞，具体情况取决于传给 loiter 函数的参数： results 生成器 的 __next__ 方法必须等到第一个期物运行结束。此时不会阻塞，因为 loiter(0) 在循 环开始前结束。注意，这一点之前的所有事件都在同一刻发生——15:56:50。

❼ 一秒钟后，即 15:56:51， loiter(1) 运行完毕。这个线程闲置，可以开始运行

loiter(4) 。

❽ 显示 loiter(1) 的结果： 10。现在， for 循环会阻塞，等待 loiter(2) 的结果。

❾同上：loiter(2)运行结束，显示结果；loiter(3)也一样。

❿ 2 秒钟后 loiter(4) 运行结束，因为 loiter(4) 在 15:56:51 时开始，休眠了 4 秒。

Executor.map 函数易于使用，不过有个特性可能有用，也可能没用，具体情况取决于需 求：这个函数返回结果的顺序与调用开始的顺序一致。如果第一个调用生成结果用时 10 秒，而其他调用只用 1 秒，代码会阻塞 10 秒，获取 map 方法返回的生成器产出的第一个

结果。在此之后，获取后续结果时不会阻塞，因为后续的调用已经结束。如果必须等到获

取所有结果后再处理，这种行为没问题；不过，通常更可取的方式是，不管提交的顺序，

只要有结果就获取。为此，要把 Executor.submit 方法和 futures.as_completed 函

数结合起来使用，像示例 17-4 中那样。 17+5+2 节会继续讨论这种方式。

executor.submit 和 futures.as_completed 这个组合比 executor.map 更 灵活，因为 submit 方法能处理不同的可调用对象和参数，而 executor.map 只能处 理参数不同的同一个可调用对象。此外，传给 futures.as_completed 函数的期物 集合可以来自多个 Executor 实例，例如一些由 ThreadPoolExecutor 实例创建， 另一些由 ProcessPoolExecutor 实例创建。

下一节根据新的需求继续实现下载国旗的示例，这一次不使用 executor.map 方法，而 是迭代 futures.as_completed 函数返回的结果。

### 17.5 显示下载进度并处理错误

前面说过， 17.1 节中的几个脚本没有处理错误，这样做是为了便于阅读和比较三种方案

（依序、多线程和异步）的结构。

为了处理各种错误，我创建了 flags2 系列示例。

flags2_common.py

这个模块中包含所有 flags2 示例通用的函数和设置，例如 main 函数，负责解析命

令行参数、计时和报告结果。这个脚本中的代码其实是提供支持的，与本章的话题没有直

接关系，因此我把源码放在附录 A 里的示例 A-10 中。

flags2_sequential.py

能正确处理错误，以及显示进度条的 HTTP 依序下载客户端。 flags2_threadpool.py 脚 本会用到这个模块里的 download_one 函数。 flags2_threadpool.py

基于 futures.ThreadPoolExecutor 类实现的 HTTP 并发客户端，演示如何处理错 误，以及集成进度条。

flags2_asyncio.py

与前一个脚本的作用相同，不过使用 asyncio 和 aiohttp 实现。这个脚本在第 18

章的 18.4 节中分析。

测试并发客户端时要小心

在公开的 HTTP 服务器上测试 HTTP 并发客户端时要小心，因为每秒可能会发起很多

请求，这相当于是拒绝服务（DoS）攻击。我们不想攻击任何人，只是在学习如何开

发高性能的客户端。访问公开的服务器时一定要管好自己的客户端。做高并发试验 时，应该在本地架设 HTTP 服务器供测试。本书代码仓库中的 17-futures/countries/ 目 录里有个 README.rst 文件( <https://github.com/fluentpython/example-code/blob/master/17-futures/countries/README.rst>[) ，那里有架设说明](https://github.com/fluentpython/example-code/blob/master/17-futures/countries/README.rst)。

flags2系列示例最明显的特色是，有使用TQDM包（[https://github+com/noamraph/tqdm](https://github.com/noamraph/tqdm)

实现的文本动画进度条。我在 YouTube 上发布了一个 108 秒的视频 （[https://www+youtube+com/watch?v=M8Z65tAl5l4](https://www.youtube.com/watch?v=M8Z65tAl5l4)） ，展示了这个进度条，还对比了三个 flags 脚本的下载速度。在那个视频中，我先运行依序下载的脚本，不过 32 秒后中断

了，因为那个脚本要用5分多钟访问676个URL，下载194面国旗；然后，我分别运行 多线程和 asyncio 版三次，每次都在 6 秒之内（即快了 60 多倍）完成任务。图 17-1 中 有两个截图，分别是 flags2_threadpool+py 脚本运行中和运行结束后。

![img](08414584Python-81.jpg)



![img](08414584Python-82.jpg)



![img](08414584Python-83.jpg)



图 17-1：（左上） flags2_threadpool.py 运行中，显示着 tqdm 包生成的进度条；（右 下）同一个终端窗口，脚本运行完毕后

TQDM 包特别易于使用，项目的 README+md 文件

（ [https: //github+com/noamraph/tqdm/blob/master/README+md](https://github.com/noamraph/tqdm/blob/master/README.md) ）中有个 GIF 动画，演示了最 简单的用法。安装 tqdm 包之后， 8 在 Python 控制台中输入下述代码，会在注释那里看到

进度条动画：

8可以使用pip install tqdm命令安装tqdm包。-编者注

\>>> import time

\>>> from tqdm import tqdm

\>>> for i in tqdm(range(1000)):

time.sleep(.01)



\>>> # -> 进度条会出现在这里 <-

除了这个灵巧的效果之外， tqdm 函数的实现方式也很有趣：能处理任何可迭代的对象， 生成一个迭代器；使用这个迭代器时，显示进度条和完成全部迭代预计的剩余时间。为了

计算预计剩余时间， tqdm 函数要获取一个能使用 len 函数确定大小的可迭代对象，或者

在第二个参数中指定预期的元素数量。借助在flags2系列示例中集成TQDM，我们可以 深入了解这几个脚本的运作方式，因为我们必须使用 futures.as_completed 函数

( [https: //docs+python+ org/3/library/concurrent+futures+html#concurrent+futures+as_completed](https://docs.python.org/3/library/concurrent.futures.html%23concurrent.futures.as_completed) )和 asyncio.as_completed 函数(https://docs+python+org/3/library/asyncio-



[task+html#asyncio+as_completed](https://docs.python.org/3/library/asyncio-task.html%23asyncio.as_completed)[） ，这样 tqdm 函数才能在每个期物运行结](https://docs.python.org/3/library/asyncio-task.html%23asyncio.as_completed)束后更新进度。

flags2 系列示例的另一个特色是，提供了命令行接口。三个脚本接受的选项相同，运行 任意一个脚本时指定 -h 选项就能看到所有选项。示例 17-8 显示的是帮助文本。

示例 17-8 flags2 系列脚本的帮助界面

[-v]

[CC [CC ...]]

Download flags for country codes. Default: top 20 countries by population.

positional arguments

CC



country code or 1st letter (eg. B for BA...BZ)

optional arguments:

-h, --help -a, --all

-e, --every

-l N, --limit N

-m CONCURRENT, --max



show this help message and exit

get all available flags (AD to ZW)

get flags for every possible code (AA...ZZ)

limit to N first codes



-s LABEL, --server LABEL



_req CONCURRENT

maximum concurrent requests (default=30)



-v, --verbose



Server to hit; one of DELAY, ERROR, LOCAL, REMOTE

(default=LOCAL)

output detailed progress info



使用 [http://localhost:8003/flags](http://localhost:8003/flags%ef%bc%9b%e8%bf%99%e6%98%af%e4%b8%80%e4%b8%aa%e4%bb%a3%e7%90%86%ef%bc%8c%e7%9b%91%e5%90%ac)[；这是一个代理，监听](http://localhost:8003/flags%ef%bc%9b%e8%bf%99%e6%98%af%e4%b8%80%e4%b8%aa%e4%bb%a3%e7%90%86%ef%bc%8c%e7%9b%91%e5%90%ac) 8003 端口，引入了

HTTP 错误，并延迟响应。这个服务器使用的 Vaurien 配置与前面不同。

仅当在本地架设HTTP服务器，并且监听8001端口时，才能使用LOCAL选 项。 DELAY 和 ERROR 选项需要代理，分别监听 8002 和 8003 端口。在 GitHub 上本书 的代码仓库中有个 1 7-futures/countries/README+rst 文件

[（](https://github.com/fluentpython/example-code/blob/master/17-futures/countries/README.rst)[https://github+com/fluentpython/example-code/blob/master/17-](https://github.com/fluentpython/example-code/blob/master/17-futures/countries/README.rst)

futures/countries/README+rst），说明了如何配置 Nginx 和 Mozilla Vaurien，以实现这

些选项的要求。

默认情况下，各个 flags2 脚本会使用默认的并发连接数（各脚本有所不同）从 LOCAL 服务器（<http://localhost:8001/flags>）中下载人口最多的20个国家的国旗。示例17-9是全 部使用默认值运行 flags2_sequential+py 脚本得到的输出。

示例17-9全部使用默认值运行flags2_sequential+py脚本：LOCAL服务器，人口最多

的 20 国国旗， 1 个并发连接

$ python3 flags2_sequential.py LOCAL site: <http://localhost:8001/flags> Searching for 20 flags: from BD to VN 1 concurrent connection will be used.

20 flags downloaded. Elapsed time: 0.10s

我们可以使用多种不同的方式选择下载哪些国家的国旗。示例 17-10 展示如何下载国家代

码以字母 A、B 或 C 开头的所有国旗。

示例 17-10 运行 flags2_threadpool+py 脚本，从 DELAY 服务器中下载国家代码以 A、

B 或 C 开头的所有国旗

$ python3 flags2_threadpool.py -s DELAY a b c DELAY site: <http://localhost:8002/flags> Searching for 78 flags: from AA to CZ 30 concurrent connections will be used.

43 flags downloaded. 35 not found.

Elapsed time: 1.72s

不管使用什么方式选择国家代码，下载的国旗数量都可以使用 -l/--limit 选项限制。示 例 17-11 演示如何发起 100 个请求，结合 -a 和 -l 选项下载 100 面国旗。

示例17-11运行flags2_asyncio+py脚本，使用100个并发请求（-m 100）从ERROR

服务器中下载100面国旗（-al 100）

ERROR site: <http://localhost:8003/flags> Searching for 100 flags: from AD to LK 100 concurrent connections will be used.

73 flags downloaded. 27 errors.

Elapsed time: 0.64s

#### 以上是 flags2 系列示例的用户界面。下面分析实现方式。

17.5.1    flags2系列示例处理错误的方式

这三个示例在负责下载一个文件的函数(download_one)中使用相同的策略处理HTTP 404 错误(未找到)。其他异常则向上冒泡，交给 download_many 函数处理。

我们还是先分析依序下载的代码，因为这些代码更易于理解，而且使用线程池的脚本重用 了这里的大部分代码。示例 17-12 列出的是 flags2_sequential+py 和 flags2_threadpool+py 脚 本真正用于下载的函数。

#### 示例 17-12 flags2_sequential+py：负责下载的基本函数；flags2_threadpool+py 脚本重

用了这两个函数

def get_flag(base_url, cc):

url = '{}/{cc}/{cc}.gif'.format(base_url, cc=cc.lower()) resp = requests.get(url) if resp.status_code != 200: O resp.raise_for_status() return resp.content

def download_one(cc, base_url, verbose=False): try:

image = get_flag(base_url, cc) except requests.exceptions.HTTPError as exc: ©

res = exc.response if res.status_code == 404:

status = HTTPStatus.not_found © msg = 'not found' else: ©

raise

else:

save_flag(image, cc.lower() + '.gif')

status = HTTPStatus.ok

msg = 'OK'

if verbose: ❺ print(cc, msg)

return Result(status, cc) ©

#### ❶ get_flag 函数没有处理错误，当 HTTP 代码不是 200 时，10使用 requests.Response.raise_for_status 方法抛出异常。 10

| 10HTTP代码200表示成功完成HTTP请求。一编者注

❷ download_one 函数捕获 requests.exceptions.HTTPError 异常，特别处理 HTTP 404 错误……

#### ❸......方法是，把局部变量status设为HTTPStatus. not_found； HTTPStatus是从

flags2_common模块（见示例A-10）中导入的Enum对象。

❹ 重新抛出其他 HTTPError 异常；这些异常会向上冒泡，传给调用方。

❺ 如果在命令行中设定了 -v/--verbose 选项，显示国家代码和状态消息；这就是详细

模式中看到的进度信息。

#### © download_one函数的返回值是一个namedtuple-Result，其中有个status字

段，其值是 HTTPStatus.not_found 或 HTTPStatus.ok。

示例 17-13 列出的是 download_many 函数的依序下载版。代码虽然简单，不过值得分析 一下，以便后面与并发版对比。我们要关注的是报告进度、处理错误和统计下载数量的方 式。

#### 示例 17-13 flags2_sequential+py：实现依序下载的 download_many 函数

def download_many(cc_list, base_url, verbose, max_req):

counter = collections.Counter() O cc_iter = sorted(cc_list) © if not verbose:

cc_iter = tqdm.tqdm(cc_iter) © for cc in cc_iter: ©

try:

res = download_one(cc, base_url, verbose) except requests.exceptions.HTTPError as exc: ©

error_msg = 'HTTP error {res.status_code} - {res.reason} error_msg = error_msg.format(res=exc.response) except requests.exceptions.ConnectionError as exc: O error_msg = 'Connection error'

else:❻

error_msg = '' status = res.status

if error_msg:

status = HTTPStatus.error 0 counter[status] += 1    ©

if verbose and error_msg: ®

print('*** Error for {}: {}'.format(cc, error_msg)) return counter ❽

#### ❶ 这个 Counter 实例用于统计不同的下载状

态： HTTPStatus.ok、HTTPStatus.not_found 或 HTTPStatus.error。

❷ 按字母顺序传入的国家代码列表，保存在 cc_iter 变量中。

❸ 如果不是详细模式，把 cc_iter 传给 tqdm 函数，返回一个迭代器，产出 cc_iter 中 的元素，还会显示进度条动画。

❹这个for循环迭代cc_iter......

❺ ……不断调用 download_one 函数，执行下载。

❻ 处理 get_flag 函数抛出的与 HTTP 有关的且 download_one 函数没有处理的异常。

❼ 处理其他与网络有关的异常。其他异常会中止这个脚本，因为调用 download_many 函 数的 flags2_common.main 函数中没有 try/except 块。

❽ 如果没有异常从 download_one 函数中逃出，从 download_one 函数返回的 namedtuple (HTTPStatus) "中获取 status。

❾ 如果有错误，把局部变量 status 设为相应的状态。

❿以HTTPStatus (一个Enum)中的值为键，增加计数器。

®如果是详细模式，而且有错误，显示带有当前国家代码的错误消息。

©返回counter，以便main函数能在最终的报告中显示数量。

下面分析重构后的线程池示例-fl ags2_threadpool.py。

17.5.2 使用 futures.as_completed 函数

为了集成 TQDM 进度条，并处理各次请求中的错误， flags2_threadpool.py 脚本用到我们见 过的 futures.ThreadPoolExecutor 类和 futures.as_completed 函数。示例 17-14 是 flags2_threadpool.py 脚本的完整代码清单。这个脚本只实现了 download_many 函数， 其他函数都重用 flags2_common 和 flags2_sequential 模块里的。

示例17-14 flags2_threadpool+py:完整的代码清单

import collections

from concurrent import futures

import requests

import tqdm O

from flags2_common import main, HTTPStatus ©

from flags2_sequential import download_one ©

DEFAULT_CONCUR_REQ = 30 ©

MAX_CONCUR_REQ = 1000 ❺

def download_many(cc_list, base_url, verbose, concur_req): counter = collections.Counter()

with futures.ThreadPoolExecutor(max_workers=concur_req) as executor: ©

to_do_map = {}    ©

for cc in sorted(cc_list):❻

future = executor.submit(download_one,

cc, base_url, verbose) o

to_do_ma p[fut u re] = cc © done_iter = futures.as_completed(to_do_map) ® if not verbose:

done_iter = tqdm.tqdm(done_iter, total=len(cc_list)) ® for future in done_iter: ©

try:

res = future.result() © except requests.exceptions.HTTPError as exc: ©

error_msg = 'HTTP {res.status_code} - {res.reason}' error_msg = error_msg.format(res=exc.response)

except requests.exceptions.ConnectionError as exc: error_msg = 'Connection error'

else:

error_msg = '' status = res.status

if error_msg:

status = HTTPStatus.error

counter[status] += 1 if verbose and error_msg:

cc = to_do_ma p[fut u re]    ©

print('*** Error for {}: {}'.format(cc, error_msg)) return counter

if __name__ == '__main__':

main（download_many, DEFAULT_CONCUR_REQ, MAX_CONCUR_REQ）

#### ❶ 导入显示进度条的库。

❷ 从 flags2_common 模块中导入一个函数和一个 Enum。

❸ 重用 flags2_sequential 模块（见示例 17-12）里的 download_one 函数。

❹ 如果没有在命令行中指定 -m/--max_req 选项，使用这个值作为并发请求数的最大 值，也就是线程池的大小；真实的数量可能会比这少，例如下载的国旗数量较少。

❺ 不管要下载多少国旗，也不管 -m/--max_req 命令行选项的值是多

少， MAX_CONCUR_REQ 会限制最大的并发请求数；这是一项安全预防措施。

#### ❻把 max_workers 设为 concur_req，创建 ThreadPoolExecutor 实例；main 函数会

把下面这三个值中最小的那个赋值给 concur_req： MAX_CONCUR_REQ、cc_list 的长

度、-m/--max_req命令行选项的值。这样能避免创建超过所需的线程。

❼ 这个字典把各个 Future 实例（表示一次下载）映射到相应的国家代码上，在处理错 误时使用。

#### ❽ 按字母顺序迭代国家代码列表。结果的顺序主要由 HTTP 响应的时间长短决定，不

过，如果线程池的大小（由 concur_req 设定）比 len（cc_list） 小得多，可能会发现 有按字母顺序批量下载的情况。

❾ 每次调用 executor.submit 方法排定一个可调用对象的执行时间，然后返回一个 Future 实例。第一个参数是可调用的对象，其余的参数是传给可调用对象的参数。

❿ 把返回的 future 和国家代码存储在字典中。

G futures.as_completed函数返回一个迭代器，在期物运行结束后产出期物。

© 如果不是详细模式，把 as_completed 函数返回的结果传给 tqdm 函数，显示进度 条；因为 done_iter 没有 len 函数，所以我们必须通过 total= 参数告诉 tqdm 函数预 期的元素数量，这样 tqdm 才能预计剩余的工作量。

®迭代运行结束后的期物。

©在期物上调用result方法，要么返回可调用对象的返回值，要么抛出可调用的对象 在执行过程中捕获的异常。这个方法可能会阻塞，等待确定结果；不过，在这个示例中不 会阻塞，因为 as_completed 函数只返回已经运行结束的期物。

吸处理可能出现的异常；这个函数余下的代码与依序下载版download_many函数一样

（见示例 17-13），不过下一点除外。

©为了给错误消息提供上下文，以当前的future为键，从to_do_map中获取国家代

码。在依序下载版中无须这么做，因为那一版迭代的是国家代码，所以知道当前国家的代

码；而这里迭代的是期物。

示例 17-14 用到了一个对 futures.as_completed 函数特别有用的惯用法：构建一个字 典，把各个期物映射到其他数据（期物运行结束后可能有用）上。这里，在 to_do_map 中，我们把各个期物映射到对应的国家代码上。这样，尽管期物生成的结果顺序已经乱 了，依然便于使用结果做后续处理。

Python 线程特别适合 I/O 密集型应用， concurrent.futures 模块大大简化了某些使用场 景下 Python 线程的用法。我们对 concurrent.futures 模块基本用法的介绍到此结束。 下面讨论不适合使用 ThreadPoolExecutor 或 ProcessPoolExecutor 类时，有哪些替

代方案。

17.5.3 线程和多进程的替代方案

Python 自 0.9.8 版（1993 年）就支持线程了， concurrent.futures 只不过是使用线程的 最新方式。 Python 3 废弃了原来的 thread 模块，换11成了高级的 threading 模块

（<https://docs.python.org/3/library/threading.html>） 。 11 如果

futures.ThreadPoolExecutor 类对某个作业来说不够灵活，可能要使用 threading 模

块中的组件（如 Thread、Lock、Semaphore 等）自行制定方案，比如说使用 queue 模 块（[https://docs+python+org/3/library/queue+html](https://docs.python.org/3/library/queue.html)）创建线程安全的队列，在线程之间传递数

据。 futures.ThreadPoolExecutor 类已经封装了这些组件。

thread模块重命名为_thread，以此强调这是低层实现，不应该在应用代码中使用。

对CPU密集型工作来说，要启动多个进程，规避GIL。创建多个进程最简单的方式是， 使用 futures.ProcessPoolExecutor 类。不过和前面一样，如果使用场景较复杂，需

要更高级的工具。 multiprocessing 模块

[https://docs+python+org/3/library/multiprocessing+html](https://docs.python.org/3/library/multiprocessing.html)）的 API 与 threading 模块相仿，不 过作业交给多个进程处理。对简单的程序来说，可以用 multiprocessing 模块代替 threading 模块，少量改动即可。不过， multiprocessing 模块还能解决协作进程遇到

的最大挑战：在进程之间传递数据。

### 17.6 本章小结

本章开头对两个 HTTP 并发客户端和一个依序下载的客户端做了对比，结果是并发版比依

序下载的脚本性能高很多。

分析过使用 concurrent.futures 实现的第一个示例后，我们深入探讨了期物对象，即 concurrent.futures.Future 或 asyncio.Future 类的实例，着重说明了二者的共同

点(区别在第 18 章详述)。我们说明了如何使用 Executor.submit(...) 方法创建期 物，以及如何使用 concurrent.futures.as_completed(...) 函数迭代运行结束的期 物。

接下来，我们分析了为什么尽管有 GIL， Python 线程仍然适合 I/O 密集型应用：标准库中

每个使用C语言编写的I/O函数都会释放GIL，因此，当某个线程在等待I/O时，Python

调度程序会切换到另一个线程。然后，我们讨论了如何借助

concurrent.futures.ProcessPoolExecutor 类使用多进程，以此绕开 GIL，使用多个

CPU 核心运行加密算法，并通过四个职程实现一倍多的速度提升。

在随后的一节中，我们深入分析了 concurrent.futures.ThreadPoolExecutor 类的运

作方式。为了说明问题，我特意举了一个示例，创建几个任务，但是休眠几秒钟，什么也

不做，只是显示带有时间戳的状态。

接下来，本章回到下载国旗的示例，增加了进度条和错误处理代码，并且进一步探索了

future.as_completed 生成器函数。我们得知一个常见的做法：把期物存储在一个字典 中，提交期物时把期物与相关的信息联系起来；这样， as_completed 迭代器产出期物 后，就可以使用那些信息。

最后，本章简要说明了多线程和多进程并发的低层实现(但却更灵活) ——threading

和 multiprocessing 模块。这两个模块代表在 Python 中使用线程和进程的传统方式。

### 17.7 延伸阅读

Brian Quinlan 是 concurrent.futures 包的贡献者，他在 PyCon Australia 2010 上所做 的“The Future Is Soon!” （http://www+pyvideo+org/video/480/pyconau-2010--the-future-is-soon）演讲对这个包做了介绍。Quinlan演讲时没用幻灯片，而是直接在Python控制台中 输入代码，以此说明这个库的用途。作为引子，他在演讲中推荐了 XKCD 漫画家和程序 员 Randall Munroe 制作的一个视频， Randall 在这个视频中对 Google Maps 发起了 DoS 攻 击（非有意为之），绘制一个彩色地图，显示他驾车绕城的路线。这个库的正式介绍文件 是“PEP 3148—futures—execute computations

asynchronously” （[https://www+python+org/dev/peps/pep-3148/](https://www.python.org/dev/peps/pep-3148/)） 。在这个 PEP 中， Quinlan 写 道， concurrent.futures 库“受 Java 的 java.util.concurrent 包影响很大”。

Jan Palach 写的 Parallel Programming with Python（ Packt 出版社）一书介绍了几个并发编 程的工具，包括 concurrent.futures、threading 和 multiprocessing 库。除了标 [准库之外，这本书还讨论了 ](http://celery.readthedocs.org/en/latest/getting-started/introduction.html)[Celery （http://celery+readthedocs+org/en/latest/getting-](http://celery.readthedocs.org/en/latest/getting-started/introduction.html)started/introduction+html） 。这是一个任务队列，用于把工作分配给多个线程和进程，甚至 是不同的设备。在 Django 社区中，为了减轻繁重任务的负担（例如，把生成 PDF 的工作 交给其他进程，防止 HTTP 响应延迟生成）， Celery 可能是使用最广泛的系统。

Beazley与Jones的著作《Python Cookbook （第3版）中文版》有多个使用

concurrent.futures 的诀窍，首先是“11+12 理解事件驱动型 I/O”。 “12+7 创建线程池”展 示了一个简单的 TCP 回显服务器， “12+8 实现简单的并行编程”提供了一个特别实用的示 例：借助 ProcessPoolExecutor 实例分析一整个目录中使用 gzip 压缩的 Apache 日志 文件。这本书的第 12 章对线程做了更多介绍，特别值得一提的是“12+10 定义一个 Actor 任务”，这个诀窍演示了参与者模型：通过传递消息协调多个线程的可行方式。

Brett Slatkin写的《Effective Python：编写高质量Python代码的59个有效方法》一书中有

一章探讨了并发的多个话题，包括：协程；使用 concurrent.futures 库处理线程和进 程；不使用 ThreadPoolExecutor 类，而使用锁和队列做线程编程。

Micha Gorelick 与 Ian Ozsvald 写的 High Performance Python （O'Reilly 出版社）和 Doug Hellmann写的《Python标准库》都涵盖了线程和进程。

若想了解不使用线程或回调的现代并发方式，推荐阅读 Paul Butcher 写的《七周七并发模 型》。12我喜欢这本书的副标题“When Threads Unravel” （线程束手无策之时）。这本书 的第 1 章简单介绍了线程和锁，后面的六章探讨了不同语言（不包括 Python、Ruby 和 JavaScript）为并发编程提供的现代化替代方案。

12该书己由人民邮电出版社出版，书号：978-7-115-38606-9。——编者注

如果对 GIL 感兴趣，请先阅读 Python 文档中的“Python Library and Extension FAQ” （“Can't we get rid of the Global Interpreter Lock?”， [https://docs+python+org/3/faq/library+html#id18](https://docs.python.org/3/faq/library.html%23id18)） 。 Guido van Rossum 写的“It isn't Easy to Remove the

GIL” （[http:"www+artima+com/weblogs/viewpost.jsp?thread=214235](http://www.artima.com/weblogs/viewpost.jsp?thread=214235)）和 Jesse

Noller （multiprocessing 包的贡献者）写的“Python Threads and the Global Interpreter

Lock’ ([http://jessenoller+com/2009/02/01/python-threads-and-the-global-interpreter-lock/](http://jessenoller.com/2009/02/01/python-threads-and-the-global-interpreter-lock/))也值 得一读。此外，David Beazley 在“Understanding the Python

GIL’ ([http://www+ dabeaz.com/GIL/](http://www.dabeaz.com/GIL/))中详细探讨了 GIL的内部运作。13在这次演讲的第54 张幻灯片中([http://www+dabeaz+com/python/UnderstandingGIL+pdf](http://www.dabeaz.com/python/UnderstandingGIL.pdf))，Beazley 得出了一些令 人担忧的结果，例如，使用 Python 3+2 引入的新 GIL 算法做基准测试时，他发现处理时间 增加了 20 倍。不过， Beazley 似乎使用一个空的 while True: pass 循环模拟 CPU 密集 型工作，而现实中不会这样做。在Beazley提交的缺陷报告中，根据Antoine Pitrou (实现 新 GIL 算法的人)的评论([http://bugs+python+org/issue7946#msg223110](http://bugs.python.org/issue7946%23msg223110))，这个问题与工作 负载没有太大关系。

13感谢Lucas Brunialti把这个演讲的链接发给我。

GIL 是实际存在的问题，而且短时间内不可能消失，不过 Jesse Noller 和 Richard Oudkerk

开发了一个库，能让CPU密集型应用轻松地绕开这个问题-multiprocessing包。这

个包在多个进程中模拟threading模块的API，而且支持基础设施的锁、队列、管道、 共享内存，等等。这个包由“PEP371 —Addition of the multiprocessing package to the standard library” ([https://www+python+org/dev/peps/pep-0371/](https://www.python.org/dev/peps/pep-0371/))引入。这个包的官方文档是个 93KB 的 +rst 文件(大约 63 页)，是 Python 标准库文档中最长的一章。多进程是

concurrent.futures.ProcessPoolExecutor 类的基础。

对于 CPU 密集型和数据密集型并行处理，现在有个新工具可用——分布式计算引擎

Apache Spark([https://spark+apache+org/](https://spark.apache.org/))。 Spark 在大数据领域发展势头强劲，提供了友好 的Python API，支持把Python对象当作数据，如示例页面所示

([https://spark+apache+org/examples+html](https://spark.apache.org/examples.html)) 。

Joao S+ O+ Bueno 开发的 lelo 库([https://pypi+python+org/pypi/lelo](https://pypi.python.org/pypi/lelo))和 Nat Pryce 开发的 python-parallelize 库( [https ://gi thub + com/npryce/python-parall elize](https://github.com/npryce/python-parallelize) )简洁且十分易于使 用，它们的作用是使用多个进程处理并行任务。 lelo 包定义了一个 @parallel 装饰器， 可以应用到任何函数上，把函数变成非阻塞：调用被装饰的函数时，函数在一个新进程中 执行。 Nat Pryce 开发的 python-parallelize 包提供了一个 parallelize 生成器，能 把 for 循环分配给多个 CPU 执行。这两个包在内部都使用了 multiprocessing 模块。

杂谈

远离线程

并发是计算机科学中最难的概念之一(通常最好别去招惹它)。 14

——David Beazley Python 教练和科学狂人

上面引自 David Beazley 的话与本章开头引自 Michele Simionato 的话明显矛盾，但我

都同意。在大学学过一门并发课程之后(那门课把“并发编程’与管理线程和锁划上等

号)，我得出一个结论，我不该自己管理线程和锁，而应该管理内存分配和释放。线

程和锁最好由懂行的系统程序员管理，他们有这种爱好，也有时间去管理(但愿如

此)。

因此我觉得 concurrent.futures 包很棒，它把线程、进程和队列视作服务的基础 设施，不用自己动手直接处理。当然，这个包针对的是简单的作业，也就是所谓

的“高度并行，，问题（https://en.wikipedia.org/wiki/Embarrassingly_parallel）。可是，正 如本章开头 Simionato 所说的那样，编写应用（而非操作系统或数据库服务器）时，

遇到的大部分并发问题都属于这一种。

对于并发程度不高的问题来说，线程和锁也不是解决之道。在操作系统层面，线程永 远不会消失；不过，过去七年我觉得让人眼前一亮的编程语言（包括 Go、 Elixir 和

Clojure）都对并发做了更好、更高层的抽象，正如《七周七并发模型》一书所述。 Erlang （实现Elixir的语言）是典型示例，设计这门语言时彻底考虑到了并发。我对

这门语言不感兴趣的原因很简单——句法丑陋。我被 Python 的句法宠坏了。

Jose Valim是著名的Ruby on Rails核心贡献者，他设计的Elixir提供了友好而现代的 句法。与 Lisp 和 Clojure 一样， Elixir 也实现了句法宏。这是把双刃剑。使用句法宏 能实现强大的DSL，可是衍生语言多起来之后，代码基会出现兼容问题，社区会分 裂。大量涌现的宏导致 Lisp 没落，因为各种 Lisp 实现都使用独特难懂的方言。标准 化的 Common Lisp 则开始复苏。我希望 Jose Valim 能引领 Elixir 社区，不要重蹈覆 辙。

与 Elixir 类似， Go 也是一门充满新意的现代语言。可是，与 Elixir 相比，某些方面

有点保守。 Go 不支持宏，句法比 Python 简单。 Go 也不支持继承和运算符重载，而

且提供的元编程支持没有 Python 多。这些限制被认为是 Go 语言的特点，因为行为和 性能更可预料。这对高并发来说是好事，而 Go 的重要使命是取代 C++、 Java 和

Python。

虽然 Elixir 和 Go 在高并发领域是直接的竞争者，但是设计原理的不同则吸引了不同 的用户群。这两门语言都可能蓬勃发展。可是纵观编程语言的历史，保守的语言更能 吸引程序员。我希望自己能精通 Go 和 Elixir。

关于 GIL

GIL 简化了 CPython 解释器和 C 语言扩展的实现。得益于 GIL， Python 有很多 C 语言 扩展——这绝对是如今 Python 如此受欢迎的主要原因之一。

多年以来，我一直觉得 GIL 导致 Python 线程几乎没有用武之地，只能开发一些玩具 应用。直到发现标准库中每一个阻塞型 I/O 函数都会释放 GIL 之后，我才意识到

Python 线程特别适合在 I/O 密集型系统（鉴于我的工作经验，客户经常付费让我开发

这种应用）中使用。

竞争对手对并发的支持

MRI （推荐使用的Ruby实现）也有GIL，因此，Ruby线程与Python线程受到同样的 限制。相比之下， JavaScript 解释器则根本不支持用户层级的线程。在 JavaScript 中，只能通过回调式异步编程实现并发。我提到这些是因为， Ruby 和 JavaScript 是最 能直接与 Python 竞争的通用动态编程语言。

在深谙并发的这一批新语言中， Go 和 Elixir 或许是最能蚕食 Python 的语言。不过， 现在有 asyncio 了。既然这么多人相信纯粹使用回调的 Node.js 平台可以做并发编

#### 程，那么 asyncio 生态系统成熟后， Python 赢回这些人能有多难呢？不过，这是下

一章“杂谈”的话题。

14摘自 PyCon 2009 教程“A Curious Course on Coroutines and Concurrency” ([http://www+ dabeaz+com/coroutines/](http://www.dabeaz.com/coroutines/))的第 9 张

幻灯片。
