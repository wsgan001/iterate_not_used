---
author: evo
comments: true
date: 2018-05-22 07:09:31+00:00
layout: post
link: http://106.15.37.116/2018/05/22/gan-%e8%ae%ad%e7%bb%83%e6%97%b6%e8%a6%81%e6%b3%a8%e6%84%8f%e7%9a%84/
slug: gan-%e8%ae%ad%e7%bb%83%e6%97%b6%e8%a6%81%e6%b3%a8%e6%84%8f%e7%9a%84
title: GAN 训练时要注意的
wordpress_id: 6264
categories:
- 人工智能学习
tags:
- GAN
---

<!-- more -->

[mathjax]

**注：非原创，只是按照自己的思路做了整合，修改。推荐直接看 ORIGINAL 中所列的原文。**


# ORIGINAL





 	
  1. aaa




# TODO





 	
  * aaa





* * *





# INTRODUCTION





 	
  * aaa





# **训练 GAN 的一些技巧**





 	
  1. 输入规范化到 (-1,1) 之间，最后一层的激活函数使用 tanh（BEGAN除外）

 	
  2. 使用 wassertein GAN 的损失函数。 什么是wassertein GAN？

 	
  3. 如果有标签数据的话，尽量使用标签，也有人提出使用反转标签效果很好，另外使用标签平滑，单边标签平滑或者双边标签平滑。**什么是反转标签？什么是标签平滑？**

 	
  4. 使用 mini-batch norm， 如果不用 batch norm 可以使用 instance norm 或者 weight norm 。**这些都是什么？**

 	
  5. 避免使用 RELU 和 pooling 层，减少稀疏梯度的可能性，可以使用 leakrelu 激活函数。**为什么？**

 	
  6. 优化器尽量选择 ADAM，学习率不要设置太大，初始 1e-4 可以参考，另外可以随着训练进行不断缩小学习率。**ADAM是什么？**

 	
  7. 给 D 的网络层增加高斯噪声，相当于是一种正则。**为什么要加噪声？为什么相当于一种正则？**






















* * *





# COMMENT



