


# ORIGINAL






    1. 《解析卷积神经网络》魏秀参

  2. 



# TODO






  * aaa





* * *





# INTRODUCTION






  * aaa










前言
人工智能，一个令人熟悉但却

萨克•阿西莫夫笔下的《机械

让现有的机器人咿呀学语邯郸

图灵设想的“图灵测试”，令

不再子虚乌有；让人熟悉的是

陌生的却是阿尔法狗究竟如何

人类为了满足自身强大好奇心

不提阿尔法狗，提起阿尔法狗

是科幻作家艾 却是到底如何 人工智能之父 在现实生活中 棋对决，令人

‘任督二脉”……不可否认，人工智能就是 开的产物，现在提及人工智能，就不得 不提到深度学习。深度学习究竟为何物？

本书从实用角度着重解析了深度学习中的一类神经网络模型——卷积神经网

络，向读者剖析了卷积神经网络的基本部件与工作机理，更重要的是系统性的

介绍了深度卷积神经网络在实践应用方面的细节配置与工程经验。笔者希望本

书“小而精”，避免像某些国外相关书籍一样浅尝辄止的“大而空”。

写作本书的主因源自笔者曾于2015年10月在个人主页(httP://lamda. nju.edu.cn/weixs)上开放的一个英文深度学习学习资料“深度神经网络之必 会技巧” (Must Know Tips/Tricks in Deep Neural Networks)。该资料随后被转 帖至新浪微博，颇受学术界和工业界朋友好评，至今已有逾31万的阅读量，后 又被国际知名论坛KDnuggets和Data Science Central特邀转载。期间曾接收 到不少国内外读过此学习资料的朋友微博私信或邮件来信表示感谢，其中不乏 有人提到希望开放一个中文版本以方便国人阅读学习。另一方面，随着深度学 习领域发展的日新月异，当时总结整理的学习资料现在看来已略显滞后，一些 最新研究成果并未涵盖其中，同时加上国内至今尚无一本侧重实践的深度学习 方面的中文书籍。因此，笔者笔耕不辍，希望将自己些许的所知所得所感及所 悟汇总于本书中，分享给大家供学习和查阅。

这是一本面向中文读者轻量级、偏实用的深度学习工具书，本书内容侧重深

度卷积神经网络的基础知识和实践应用。为了使更多不同技术背景的读者通过

本书对卷积神经网络和深度学习有所了解，笔者试图尽可能少的使用晦涩的数

学公式而尽可能多的使用具体的图表形象表达。本书的受众为对卷积神经网络

和深度学习感兴趣的入门者，以及没有机器学习背景但希望能快速掌握该方面

知识并将其应用于实际问题的各行从业者。为方便读者，本书附录给出了一些

相关数学基础知识简介。

全书共14章，除“绪论”外可分为2个篇章：第一篇“基础理论篇”包括 第1~4章，介绍卷积神经网络的基础知识、基本部件、经典结构和模型压缩 等基础理论内容；第二篇“实践应用篇”包括第5~14章，介绍深度卷积神经 网络自数据准备始，到模型参数初始化、不同网络部件的选择、网络配置、网 络模型训练、不平衡数据处理，最终直到模型集成等实践应用技巧和经验。另 外，本书基本在每章结束均有对应小结，读者在阅读完每章内容后不妨掩卷回 忆，看是否完全掌握此章节重点。对卷积神经网络和深度学习感兴趣的读者可 通读全书，做到“理论结合实践”；对于希望将深度卷积神经网络迅速应用来解 决实际问题的读者，也可直接参考第二篇的有关内容，做到“有的放矢”。

本书写作过程得到笔者很多同学和学术界工业界朋友的支持和帮助，在 此谨列出他们的姓名以致谢意（按姓氏拼音序）：高斌斌，高如如，罗建 豪，屈伟洋，谢晨伟，杨世才，张晨麟。感谢高斌斌和罗建豪帮助起草本书 第3.2.4节和第4章的有关内容。此外，特别感谢南京大学、澳大利亚阿德 莱德大学等高校的众多师长在笔者求学科研过程中不厌其烦细致入微的指 导、教育和关怀。最后非常感谢笔者的父母，感谢他们的养育和一直以来的 理解、体贴与照顾。写就本书，笔者自认才疏学浅，仅略知皮毛，更兼时间 和精力有限，书中错谬之处在所难免，若蒙读者不弃还望不吝赐教，将不胜感激。

魏秀参

2017年5月于澳大利亚阿德莱德

注：

§本书版本为17.05,成书于2017年五月。

§如诸君认为本书对您略有帮助，不妨扫码请笔者喝杯咖啡

§ 严正声明：本书可免费用于学习和研究目的,可自由传播,但切勿擅自用 于商业用途或私自引用，笔者保留著作权相关权利。

0.1引言

2015年10月，一场围棋的人机对决正在进行，但由于是闭门对弈，这场比赛 的进行时可谓“悄无声息”……

围棋，起源于中国，是迄今最古老的人类智力游戏之一。它的有趣和神奇，

不仅因为其规则简洁而优雅但玩法却千变万化，而且还因为它是世界上最复杂

的棋盘游戏之一，是当时唯一一个机器不能战胜人类的棋类游戏。那场对决的 一方是三届欧洲围棋冠军的樊麾二段，另一方则是Google DeepMind开发的

“阿尔法狗” (AlphaGo)人工智能(Artificial Intelligence,简称AI)围棋系统， 双方以正式比赛中使用的十九路棋盘进行了无让子的五局较量。与比赛进行时

大相径庭，赛后结局并非无人问津而是举世哗然：阿尔法狗以 5:0全胜的纪录

击败樊麾二段，而樊麾二段则成为了世界上第一个于十九路棋盘上被AI围棋 系统击败的职业棋手。樊麾二段在赛后接受Nature采访时曾谈到：“如果不知 道阿尔法狗是部电脑，我会以为对手是棋士，一名有点奇怪的高手。”霎时间消

息不胫而走，媒体报道铺天盖地，莫非人类就如此这般轻易的丢掉了自己“尊 严”？莫非

当然没有。樊麾一战过后不少围棋高手和学界专家站出来质疑阿尔法狗取胜 “含金量”，为人类“背书”：此役机器仅仅胜了人类的围棋职业二段，根本 不上战胜围棋高手，何谈战胜人类呢！就在人们一副淡定的品论这次“小游 ’时，阿尔法狗正在酝酿着下一次“大对决”，因为它即将在2016年3月迎 韩国籍世界冠军李世石九段。近十年来，李世石九段是夺取世界冠军头衔次 最多的超一流棋手，所以从严格意义上讲，那才是真正的“人机大战”。 与上次不同，2016年3月这次人机“巅峰对决”堪称举世瞩目万人空巷。不 就在赛前仍有不少人唱衰阿尔法狗，特别是整个围棋界一路的鄙视，基本上 阿尔法狗能赢一盘保住“面子”就善莫大焉了。但是随着比赛的进行，结 令人错愕。第一局李世石输了！“是不是李世石的状态不对，没发挥出真

0.2.什么是深度学习？

正的水平？”第二局李世石又输了！“阿尔法狗还是蛮厉害的啊。不过阿尔法狗

大局观应该不行，世石九段在这方面加强，应该能赢。”第三局李世石再次输了

比赛，赛前对人类棋手乐观一派悲观至极。“完了！虽然比赛已输，但李九段怎

么说也要赢一盘吧。果然，第四局78手出现神之一手，李世石终于赢了一盘，

让人有了些许宽慰。但末盘阿尔法狗没有再给李世石机会，最终4 : 1大胜人类 围棋的顶级高手，彻底宣告人类“丧失”了在围棋上的统治地位。“阿尔法狗” 则迅速成为全世界热议的话题，在阿尔法狗大红大紫的同时，也让人们牢牢记

住了一个原本陌生的专有名词 “深度学习”(deep learning)。

0.2什么是深度学习？
比起深度学习，“机器学习”一词应更耳熟能详。机器学习(machine learning)是人 工智能的一个分支，它致力于研究如何通过计算的手段，利用经验(experience) 来改善计算机系统自身的性能。通过从经验中获取知识(knowledge),机器学 习算法摒弃了人为向机器输入知识的操作，转而凭借算法自身来学到所需所有 知识。对于传统机器学习算法而言，“经验”往往对应以“特征”(feature)形式 存储的“数据”(data)，传统机器学习算法所做的事情便是依靠这些数据产生 “模型”(model)。

但是“特征”为何？如何设计特征更有助于算法学到优质模型？……一开始 人们通过“特征工程”(feature engineering)形式的工程试错性方式来得到数

据特征。可是随着机器学习任务的复杂多变，人们逐渐发现针对具体任务生成

特定特征不仅费时费力，同时还特别敏感，很难将其应用于另一任务。此外对

于一些任务，人类根本不知道该如何用特征有效表示数据。例如，人们知道一

辆车的样子，但完全不知道怎样设计的像素值配合起来才能让机器“看懂”这

是一辆车。这种情况就会导致若特征“造”的不好，最终学习任务的性能也会 受到极大程度的制约，可以说，特征工程决定了最终任务性能的“天花板”。聪 明而倔强的人类并没有屈服：既然模型学习的任务可以通过机器自动完成，那 么特征学习这个任务自然完全可以通过机器自己实现。于是，人们尝试将特征 学习这一过程也用机器自动的“学”出来，这便是“表示学习” (representation

learning)。

表示学习的发展大幅提高了很多人工智能应用场景下任务的最终性能，同时

由于其自适应性使得人工智能系统可以很快移植到新的任务上去。“深度学习”

便是表示学习中的一个经典代表。

深度学习以数据的原始形态(raw data)作为算法输人，经过算法层层抽 象将原始数据逐层抽象为自身任务所需的最终特征表示，最后以特征到任务

目标的映射(mapping)作为结束，从原始数据到最终任务目标，“一气呵成” 并无夹杂任何人为操作。如图1所示，相比传统机器学习算法仅学得模型这一 单一“任务模块”而言，深度学习除了模型学习，还有特征学习、特征抽象等 任务模块的参与，借助多层任务模块完成最终学习任务，故称其为“深度”学 习。深度学习中的一类代表算法是神经网络算法，包括深度置信网络(deep belief network)、递归神经网络(recurrent neural network)和卷积神经网络 (Convolution Neural Network,简称CNN)等等。特别是卷积神经网络，目前 在计算机视觉、自然语言处理、医学图像处理等领域“一枝独秀”，它也是本书 将侧重介绍的一类深度学习算法。有关人工智能、机器学习、表示学习和深度 学习等概念间的关系可由图2中的韦恩图表示。

0.3
虽说阿尔法狗一鸣惊人，但它背后的深度学习却是由来已久。相对今日之繁荣，

它一路而来的发展不能说一帆风顺，甚至有些跌宕起伏。追根溯源，深度学习

的思维范式实际上是人工神经网络(artificial neural networks),从古溯今，该 类算法的发展经历了三次高潮和两次衰落。

第一次高潮是二十世纪四十至六十年代当时广为人知的控制论(cybernetics)。 当时的控制论是受神经科学启发的一类简单的线性模型，其研究内容是给 定一组输人信号xi,x2,...,xn去拟合一个输出信号y，所学模型便是最简单的 线性加权：f (X,⑷=X1叫+ •••+ Xn^n。显然，如此简单的线性模型令其应用 领域极为受限，最为著名的是：它不能处理“异或”问题(XOR function)。因 此，人工智能之父Marvin Minsky曾在当时撰文批判神经网络存在的两点关键

0.3.深度学习的前世今生

图1:传统机器学习算法与深度学习概念性对比。图中阴影标注的模块表示该模 块可由算法直接从数据中自学习所得。

问题：首先，单层神经网络无法处理“异或”问题；其次，当时的计算机缺乏足

够的计算能力满足大型神经网络长时间的运行需求。Minsky对神经网络的批判 将其研究在60年代末带人“寒冬”，人工智能产生了很多不同的研究方向，可 唯独神经网络好像逐渐被人淡忘。

直到80年代，David Rumelhar和Geoffery E. Hinton等人提出了反向传播 (back propagation)算法，解决了两层神经网络所需要的复杂计算量问题，同 时克服了 Minsky说过神经网络无法解决异或问题，自此神经网络“重获生机”， 迎来了第二次高潮，即二十世纪八十至九十年代的连接主义(connectionism)。 不过好景不长，受限于当时数据获取的瓶颈，神经网络只能在中小规模数据上 训练，因此过拟合(overfitting)极大困扰着神经网络型算法。同时，神经网络 算法的不可解释性令它俨然成为一个“黑盒”，训练模型好比撞运气般，有人无

图2:人工智能、机器学习、表示学习、深度学习和卷积神经网络(CNN)之间 的关系。

奈的讽刺说它根本不是“科学” (science)而是一种“艺术”(art)。另外加上当 时硬件性能不足而带来的巨大计算代价使人们对神经网络望而却步，相反，如 支持向量机(support vector machine)等数学优美且可解释性强的机器学习算

法逐渐变成历史舞台上的“主角”。短短十年，神经网络再次跌入“谷底”。甚至

当时在一段时间内只要和神经网络沾边的学术论文几乎都会收到类似这样的评

审意见：“The biggest issue with this paper is that it relies on neural networks. 这篇论文最大的问题，就是它使用了神经网络。)”

但可贵的是， 尽管当时许多人抛弃神经网络转行做了其他方向， 但如 Geoffery E. Hinton, Yoshua Bengio 和 Yann LeCun 等人仍“笔耕不辍”在神 经网络领域默默耕耘，可谓“卧薪尝胆”。在随后的30年，随着软件算法和硬 件性能的不断优化，直到2006年，Geoffery E. Hinton等在Science上发表文 章［38］提出：一种称为“深度置信网络”(deep belief network)的神经网络模 型可通过逐层预训练(greedy layer-wise pretraining)的方式有效完成模型训练 过程。很快，更多的实验结果证实了这一发现，更重要的是除了证明神经网络

0.3.深度学习的前世今生

训练的可行性外，实验结果还表明神经网络模型的预测能力相比其他传统机器 学习算法可谓“鹤立鸡群”。Hinton发表在Science上的这篇文章无疑为神经网 络类算法带来了一片曙光。接着，被冠以“深度学习”名称的神经网络终于可 以大展拳脚，首先于2011年在语音识别领域大放异彩，其后便是在2012年计 算机视觉“圣杯” ImageNet竞赛上强势夺冠，再来于2013年被MIT科技纵览

(MIT Technology Review)评为年度十大科技突破之首 这就是第三次高潮，

也就是大家都比较熟悉的深度学习(deep learning)时代。其实，深度学习中的 “deep” 一部分是为了强调当下人们已经可以训练和掌握相比之前神经网络层数 多得多的网络模型。不过也有人说深度学习无非是“新瓶装旧酒”，而笔者更愿 意将其比作“鸟枪换炮”。正因为有效数据的急剧扩增、高性能计算硬件的实现 以及训练方法的大幅完善，三者作用最终促成了神经网络的第三次“复兴”。

细细想来，其实第三次神经网络的鼎盛与前两次大有不同，这次深度学习的

火热不仅体现在学术研究领域的繁荣，它更引发相关技术产生了巨大的现实影

响力和商业价值——人工智能不再是一张“空头支票”。尽管目前阶段的人工智

能还没有达到科幻作品中的强人工智能水平，但当下的系统质量和性能已经足

以让机器在特定任务中完胜人类，也足以产生巨大的产业生产力。

深度学习作为当前人工智能热潮的技术核心，哪怕研究高潮过段时间会有所 回落，但仍不会像前两次衰落一样被人彻底遗忘。它的伟大意义在于，它就像一 个人工智能时代人类不可或缺的工具，真正让研究者或工程师摆脱了复杂的特 征工程，从而可以专注于解决更加宏观的关键问题；它又像一门人工智能时代 人类必需的语言，掌握了它就可以用之与机器“交流”完成之前无法企及的现 实智能任务。因此许多著名的大型科技公司，如Google、Amazon、Facebook、 微软、百度、腾讯和阿里巴巴等纷纷第一时间成立了自己聚焦深度学习的人工 智能研究院或研究机构。相信随着人工智能大产业的发展，慢慢的，人类重复 性的工作可被机器替代，从而提升社会运转效率，把人们从枯燥的劳动中解放 出来参与到其他更富创新的活动中去。

有人说“人工智能是不懂美的”，即便阿尔法狗在围棋上赢了人类，但它根

本无法体会“落子知心路”给人带来的微妙感受。不过转念一想，如果真有这

样一位可随时与你“手谈”的朋友，怎能不算是件乐事？我们应该庆幸可以目

睹并且亲身经历、甚至参与这次人工智能的革命浪潮，相信今后一定还会有更

多像阿尔法狗一样的奇迹发生。此时，我们登高望远，极目远眺；此时，我们

指点江山，挥斥方裘。正是此刻站在浪潮之巅，因此我们兴奋不已、彻夜难眠。















* * *





# COMMENT



