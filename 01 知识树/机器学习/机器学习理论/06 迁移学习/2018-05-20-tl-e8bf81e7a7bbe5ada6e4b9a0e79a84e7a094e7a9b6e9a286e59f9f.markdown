---
author: evo
comments: true
date: 2018-05-20 12:11:02+00:00
layout: post
link: http://106.15.37.116/2018/05/20/tl-%e8%bf%81%e7%a7%bb%e5%ad%a6%e4%b9%a0%e7%9a%84%e7%a0%94%e7%a9%b6%e9%a2%86%e5%9f%9f/
slug: tl-%e8%bf%81%e7%a7%bb%e5%ad%a6%e4%b9%a0%e7%9a%84%e7%a0%94%e7%a9%b6%e9%a2%86%e5%9f%9f
title: TL 迁移学习的研究领域
wordpress_id: 6079
categories:
- 人工智能学习
tags:
- Transfer Learning
---

<!-- more -->

[mathjax]

**注：非原创，只是按照自己的思路做了整合，修改。推荐直接看 ORIGINAL 中所列的原文。**


# ORIGINAL





 	
  1. [迁移学习简明手册](https://github.com/jindongwang/transferlearning-tutorial)  [王晋东](https://zhuanlan.zhihu.com/p/35352154)




# TODO





 	
  * aaa





* * *





# INTRODUCTION





 	
  * aaa







# 迁移学习的研究领域与研究方法分类


依据目前较流行的机器学习分类方法，机器学习主要可以分为有监督、半监督和无监督机器学习三大类。同理，迁移学习也可以进行这样的分类。需要注意的是，依据的分类准则不同，分类结果也不同。在这一点上，并没有一个统一的说法。我们在这里仅根据目前较流行的方法，对迁移学习的研究领域进行一个大致的划分。

迁移学习的研究领域与研究方法分类：


![](http://106.15.37.116/wp-content/uploads/2018/05/img_5b0163ae981b1.png)


大体上讲，迁移学习的分类可以按照四个准则进行：



 	
  * 按目标域有无标签分

 	
  * 按学习方法分

 	
  * 按特征分

 	
  * 按离线与在线形式分


不同的分类方式对应着不同的专业名词。当然，即使是一个分类下的研究领域，也可能同时处于另一个分类下。

下面我们对这些分类方法及相应的领域作简单描述。


# 按目标域标签分


这种分类方式最为直观。类比机器学习，按照目标领域有无标签，迁移学习可以分为以下三个大类：



 	
  * 监督迁移学习 (Supervised Transfer Learning)

 	
  * 半监督迁移学习 (Semi-Supervised Transfer Learning)

 	
  * 无监督迁移学习 (Unsupervised Transfer Learning)


显然，少标签或无标签的问题 (半监督和无监督迁移学习) ，是研究的热点和难点。**嗯，比较重要。**


# 按学习方法分类 （重点）


将迁移学习按学习方法分为以下四个大类：



 	
  * 基于实例的迁移学习方法 (Instance based Transfer Learning)

 	
  * 基于特征的迁移学习方法 (Feature based Transfer Learning)

 	
  * 基于模型的迁移学习方法 (Model based Transfer Learning)

 	
  * 基于关系的迁移学习方法 (Relation based Transfer Learning)


这是一个很直观的分类方式，按照数据、特征、模型的机器学习逻辑进行区分，再加上不属于这三者中的关系模式。


## 基于实例的迁移


简单来说就是通过权重重用，对源域和目标域的样例进行迁移。就是说直接对不同的样本赋予不同权重，比如说相似的样本，我就给它高权重，这样我就完成了迁移，非常简单非常直接。**什么意思？什么权重重用？为什么相似的样本就给他高权重？有什么例子吗？**


## 基于特征的迁移


就是更进一步对特征进行变换。意思是说，假设源域和目标域的特征原来不在一个空间，或者说它们在原来那个空间上不相似，那我们就想办法把它们变换到一个空间里面，那这些特征不就相似了？这个思路也非常直接。这个方法是用得非常多的，一直在研究，目前是感觉是研究最热的。**怎么变换到同一个空间的？有那些应用？有什么例子吗？这个现在一般研究什么？**


## 基于模型的迁移


就是说构建参数共享的模型。这个主要就是在神经网络里面用的特别多，因为神经网络的结构可以直接进行迁移。比如说神经网络最经典的 微调（fine tune）就是模型参数迁移的很好的体现。**这个的确，比如用 VGG 16 拆掉后面几层的 FC，装上自己的 FC，然后用自己的样本进行微调 fine tuning 。有实际的例子的话这里引用下。**


## 基于关系的迁移


这个方法用的比较少，这个主要就是说挖掘和利用关系进行类比迁移。比如老师上课、学生听课就可以类比为公司开会的场景。这个就是一种关系的迁移。**什么意思？这个怎么体现在算法上？**



目前最热的就是基于特征还有模型的迁移，然后基于实例的迁移方法和他们结合起来使用。**怎么结合的？有什么例子吗？**






# 按特征分类


按照特征的属性进行分类，也是一种常用的分类方法。按照特征属性，迁移学习可以分为两个大类：



 	
  * 同构迁移学习 (Homogeneous Transfer Learning)

 	
  * 异构迁移学习 (Heterogeneous Transfer Learning)


这也是一种很直观的方式：

 	
  * 如果特征语义和维度都相同，那么就是同构。比如：不同图片的迁移

 	
  * 如果特征完全不相同，那么就是异构。比如：图片到文本的迁移


**为什么叫同构和异构这种名字呢？异构的时候，怎么定义相似性？怎么知道什么与什么是相似的？可以迁移的？**




# 按离线与在线形式分


按照离线学习与在线学习的方式，迁移学习还可以被分为：



 	
  * 离线迁移学习 (Offline Transfer Learning)

 	
  * 在线迁移学习 (Online Transfer Learning)


目前绝大多数的迁移学习方法，都采用了离线方式。即，源域和目标域均是给定的，迁移一次即可。这种方式的缺点是显而易见的：算法无法对新加入的数据进行学习，模型也无法得到更新。

与之相对的，是在线的方式。即随着数据的动态加入，迁移学习算法也可以不断地更新。**这个更新与迁移学习算法有关吗？数据的动态加入指的是原域里的数据还是目标域的数据？怎么更新？  有在线的迁移学习吗？怎么搭建的？**



















* * *





# COMMENT



