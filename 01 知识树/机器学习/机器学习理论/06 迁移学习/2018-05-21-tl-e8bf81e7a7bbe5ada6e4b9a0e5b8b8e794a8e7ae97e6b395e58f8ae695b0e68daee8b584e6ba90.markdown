---
author: evo
comments: true
date: 2018-05-21 15:12:55+00:00
layout: post
link: http://106.15.37.116/2018/05/21/tl-%e8%bf%81%e7%a7%bb%e5%ad%a6%e4%b9%a0%e5%b8%b8%e7%94%a8%e7%ae%97%e6%b3%95%e5%8f%8a%e6%95%b0%e6%8d%ae%e8%b5%84%e6%ba%90/
slug: tl-%e8%bf%81%e7%a7%bb%e5%ad%a6%e4%b9%a0%e5%b8%b8%e7%94%a8%e7%ae%97%e6%b3%95%e5%8f%8a%e6%95%b0%e6%8d%ae%e8%b5%84%e6%ba%90
title: TL 迁移学习常用算法及数据资源
wordpress_id: 6218
categories:
- 人工智能学习
tags:
- Transfer Learning
---

<!-- more -->

[mathjax]

**注：非原创，只是按照自己的思路做了整合，修改。推荐直接看 ORIGINAL 中所列的原文。**


# ORIGINAL





 	
  1. [迁移学习简明手册](https://github.com/jindongwang/transferlearning-tutorial)  [王晋东](https://zhuanlan.zhihu.com/p/35352154)




# TODO





 	
  * **数据集要单独整理出来，把机器学习和深度学习等等使用到的都要整理一下，而且有的持续更新的就保留更新地址。**

 	
  * **并且要添加对这些数据集的描述文字，和一般应用场景和算法，不然使用的时候不知道使用哪些。**





* * *





# INTRODUCTION





 	
  * aaa


这个暂时没有整理：

数据集：[迁移学习领域常用数据集](https://github.com/jindongwang/transferlearning/blob/master/doc/dataset.md)

[常用算法的实验结果](https://github.com/jindongwang/transferlearning/blob/master/doc/benchmark.md)

[算法收集及实现](https://github.com/jindongwang/transferlearning)






# 




# 迁移学习常用数据集的简要介绍




## 1. 手写体识别图像数据集


MNIST和USPS是两个通用的手写体识别数据集，它们被广泛地应用于机器学习算法评测的各个方面。USPS数据集包括7,291张训练图片和2,007张测试图片，图片大小为16 \(\times\) 16。MNIST数据集包括60,000张训练图片和10,000张测试图片，图片大小28 \(\times\) 28。USPS和MNIST数据集分别服从显著不同的概率分布，两个数据集都包含10个类别，每个类别是1-10之间的某个字符。为了构造迁移学习人物，在USPS中随机选取1,800张图片作为辅助数据、在MNIST中随机选取2,000张图片作为目标数据。交换辅助领域和目标领域可以得到另一个分类任务MNIST vs USPS。图片预处理包括:将所有图片大小线性缩放为16 \(\times\) 16，每幅图片用256维的特征向量表征，编码了图片的像素灰度值信息。辅助领域和目标领域共享特征空间和类别空间，但数据分布显著不同。


## 2. 人脸识别图像数据集


PIE代表“朝向、光照、表情”的英文单词首字母，该数据集是人脸识别的基准测试集，包括68个不同人物的41,368幅人脸照片，图片大小为32 \(\times\) 32，每个人物的照片由13个同步的相机(不同朝向)、21个不同曝光程度拍摄。简单起见，实验中采用PIE的预处理集，包括2个不同子集PIE1和PIE2，是从正面朝向的人脸照片集合(C27)中按照不同的光照和曝光条件随机选出。按如下方法构造分类任务PIEI vs PIE2：将PIE1作为辅助领域、PIE2作为目标领域;交换辅助领域和目标领域可以得到分类任务PIE2 vs PIEI。这样，辅助领域和目标领域分别由不同光照、曝光条件的人脸照片组成，从而服从显著不同的概率分布。


## 3. 对象识别数据集


COIL20包含20个对象类别共1,440张图片;每个对象类别包括72张图片，每张图片拍摄时对象水平旋转5度(共360度)。每幅图片大小为32 \(\times\) 32，表征为1,024维的向量。实验中将该数据集划分为两个不相交的子集COIL1和COIL2：COIL1包括位于拍摄角度为 \([0\textdegree,85\textdegree]\cup[180\textdegree,265\textdegree]\) (第一、三象限)的所有图片；COIL2包括位于拍摄角度为 \([90\textdegree,175\textdegree]\cup[270\textdegree,355\textdegree]\) (第二、四象限)的所有图片。这样，子集COIL1和COIL2的图片因为拍摄角度不同而服从不同的概率分布。将COIL1作为辅助领域、COIL2作为目标领域，可以构造跨领域分类任务COIL1 vs COIL2；交换辅助领域和目标领域，可以得到另外一个分类任务COIL2 vs COIL1。

Office是视觉迁移学习的主流基准数据集，包含3个对象领域Amazon(在线电商图片)、Webcam(网络摄像头拍摄的低解析度图片)、DSLR(单反相机拍摄的高解析度图片)，共有4,652张图片31个类别标签。Caltech-256是对象识别的基准数据集，包括1个对象领域Caltech，共有30,607张图片256个类别标签。对每张图片抽取SURF特征，并向量化为800维的直方图表征，所有直方图向量都进行减均值除方差的归一化处理，直方图码表由K均值聚类算法在Amazon子集上生成。具体共有4个领域C(Caltech-256), A(Amazon), W(Webcam)和D(DSLR)，从中随机选取2个不同的领域作为辅助领域和目标领域，则可构造 \(4 \times 3 = 12\) 个跨领域视觉对象识别任务，如 \(A \rightarrow D, A \rightarrow C, \cdots, C \rightarrow W\) 。


## 4. 大规模图像分类数据集


大规模图像分类数据集包含了来自5个域的图像数据：ImageNet、VOC 2007、SUN、LabelMe、以及Caltech。它们包含5个类别的图像数据：鸟，猫，椅子，狗，人。对于每个域的数据，均使用DeCaf~\cite{donahue2014decaf}进行特征提取，并取第6层的特征作为实验使用，简称DeCaf6特征。每个样本有4096个维度。


## 5. 通用文本分类数据集


20-Newsgroups数据集包含约20,000个文档，4个大类分别为comp, rec,sci和talk，每个大类包含4个子类，详细信息如表2.2所示。在实验中构造了6组跨领域二分类任务，每组任务由4个大类中随机选取2个大类构成，一个大类记为正例，另一个大类记为负例，6个任务组具体为comp vs rec, comp vs sci, comp vs talk, rec vs sci, rec vs talk和、sci vs talk。每个跨领域分类任务(包括辅助领域和目标领域)按如下方法生成:每个任务组p VS的两个大类p和Q分别包含4个子类P1、P2、P3、P4和Q1、Q2、Q3、Q4;随机选取p的两个子类(如P1、P2)与Q的两个子类(如Q1、Q2)构成辅助领域，其余子类(P的P3和P4和Q3和Q4构成目标领域。以上构造策略既保证辅助领域和目标领域是相关的，因为它们都来自同样的大类;又保证辅助领域和目标领域是不同的，因为它们来自不同的子类。每个任务组P VS Q可以生成36个分类任务，总计6个任务组共生成6 \(\times\) 36 = 216个分类任务。数据集经过文本预处理后包含25,804个词项特征和15,033个文档，每个文档由tf-idf向量表征。

Reuters-21578是一个较难的文本数据集，包含多个大类和子类。其中最大3个大类为orgs, people和place，可构造6个跨领域文本分类任务orgs vs people,people vs orgs, orgs vs place, place vs orgs, people vs place和place vs people。


## 6. 行为识别公开数据集


行为识别是典型的时间序列分类任务。为了测试算法在时间序列任务上的性能，收集了3个公开的行为识别数据集：OPPORTUNITY、DASDS和PAMAP2。OPPORTUNITY数据集包含4个用户在智能家居中的多种不同层次的行为。DAADS数据集包含8个人的19种日常行为。PAMAP2数据集包含9个人的18种日常生活行为。所有数据集均包括加速度计、陀螺仪和磁力计三种运动传感器。

























* * *





# COMMENT



