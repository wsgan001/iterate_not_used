# TODO
-


神经元模型


神经网络(neural networks)方面的研究很早就已出现，今天“神经网络” 已是一个相当大的、多学科交叉的学科领域.各相关学科对神经网络的定义多 种多样，本书采用目前使用得最广泛的一种，即

“神经网络是由具有适应性的 简单单元组成的广泛并行互连的网络，它的组织能够模拟生物神经系统对真实世界物体所作出的交互反应” [Kohonen, 1988].

我们在机器学习中谈论神经网 络时指的是“神经网络学习”，或者说，是机器学习与神经网络这两个学科领域的交叉部分.

神经网络中最基本的成分是神经元(neuron)模型，即上述定义中的 “简单单元”.在生物神经网络中，每个神经元与其他神经元相连，当它“兴奋”时， 就会向相连的神经元发送化学物质，从而改变这些神经元内的电位；如果某神经元的电位超过了一个“阈值” (threshold),那么它就会被激活，即 “兴奋” 起来，向其他神经元发送化学物质.<span style="color:red;">不知道现在的神经元还是这种模型吗？</span>

1943年，[McCulloch and Pitts, 1943] 将上述情形抽象为图 5.1 所示的简单 模型，这就是一直沿用至今的 “M-P神经元模型”。在这个模型中，神经元接 收到来自 $n$ 个其他神经元传递过来的输入信号，这些输入信号通过带权重的连接(connection)进行传递，神经元接收到的总输入值将与神经元的阈值进行比较，然后通过 “激活函数”(activation function) 处理以产生神经元的输出。

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180626/afC8EK634L.png?imageslim)



理想中的激活函数是图 5.2(a) 所示的阶跃函数，它将输入值映射为输出值 “0”或 “1” ，显然 “1” 对应于神经元兴奋， “0” 对应于神经元抑制。然而，阶跃函数具有不连续、不光滑等不太好的性质，因此实际常用 Sigmoid 函数作为激活函数。典型的Sigmoid函数如图5.2(b)所示，它把可能在较大范围内变化的输入值挤压到(0,1)输出值范围内，因此有时也称为“挤压函数” (squashing function)。

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180626/KmBECCJJ26.png?imageslim)


把许多个这样的神经元按一定的层次结构连接起来，就得到了神经网络。<span style="color:red;">这个结构有没有什么理论支撑？</span>

事实上，从计算机科学的角度看，我们可以先不考虑神经网络是否真的模拟了生物神经网络，只需将一个神经网络视为包含了许多参数的数学模型，这个模型是若干个函数，例如 $y_j=f(\sum_{i} w_ix_i-\theta_j)$ 相互(嵌套)代入而得。有效的神经网络学习算法大多以数学证明为支撑。<span style="color:red;">为什么数学模型一定要是这样的？</span>





# REF
1. 《机器学习》周志华
