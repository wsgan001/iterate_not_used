

# TODO
- **还是没怎么明白 尤其是后面的先验概率和后验概率。**


# 什么是决策树？决策过程是什么样子的？


决策树 (decision tree) 是一类常见的机器学习方法。顾名思义，决策树是基于树结构来进行决策的，这恰是人类在面临决策问题时一种很自然的处理机制。

比如，我们要对 "这是好瓜吗?" 这样的问题进行决策时，通常会进行一系列的判断或 "子决策" ，我们先看 "它是什么颜色?"，如果是"青绿色"，则我们再看"它的根蒂是什么形态?"，等等，最后，得出一个结论，整个决策过程如图：


![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180626/CIFbe9L92k.png?imageslim)





# 决策树可以用来解决什么问题？


决策树可以用来解决分类问题，以二分类任务为例，比如我们希望从样本中学得一个模型来对新示例进行分类，那么这个分类的任务，就可以看作是对 "当前样本属于 XX 类吗?" 这个问题一个决策过程。

显然 ，上面这个决策过程的最终结论对应了我们所希望的判定结果，例如 "是" 或 "不是" 好瓜。

而整个决策过程中提出的每个判定问题都是对某个属性的测试，例如 "色泽=?" ，每个测试的结果或是导出最终结论，或是导出进一步的判定问题，其考虑的范围是在上次决策结果的限定范围之内的。


# 一般的决策树是什么样子的？


一般的，一棵决策树包含一个根结点、若干个内部结点和若干个叶结点。叶结点对应于决策结果，其他每个结点则对应于一个属性测试，每个结点包含的样本集合根据属性测试的结果被划分到子结点中，根结点包含样本全集。从根结点到每个叶结点的路径对应了一个判定测试序列。

而决策树学习的目的就是想产生一棵泛化能力强，即处理未见示例能力强的决策树，其基本流程遵循简单且直观的 "分而治之" (divide-and-conquer) 策略。<span style="color:red;">什么是分而治之策略？是一种数学算法吗？</span>


# 决策树的生成流程


决策树学习基本算法如下图所示：


![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180626/6aBKeL3IiF.png?imageslim)


<span style="color:red;">怎么选择划分属性的？</span>

显然，决策树的生成是一个递归过程。在决策树基本算法中，有三种情形会导致递归返回:

1. 当前结点包含的样本全属于同一类别，无需划分
2. 当前属性集为空，或是所有样本在所有属性上取值相同，无法划分 <span style="color:red;">什么是属性集为空？</span>
3. 当前结点包含的样本集合为空，不能划分

在递归返回时对应的处理如下：
- 在第 (2)种情形下，我们把当前结点标记为叶结点，井将其类别设定为该结点所含样本最多的类别
- 在第 (3)种情形下，同样把当前结点标记为叶结点，但将其类别设定为其父结点所含样本最多的类别。


注意这两种情形的处理实质不同：<span style="color:red;">没明白</span>


* 情形 (2)是在利用当前结点的后验分布
* 情形 (3)则是把父结点的样本分布作为当前结点的先捡分布






# REF
  1. 《机器学习》周志华
