

半监督SVM


半监督支持向量机(Semi-Supervised Support Vector Machine，简称 S3VM)是支持向量机在半监督学习上的推广.在不考虑未标记样本时，支 持向量机试图找到最大间隔划分超平面，而在考虑未标记样本后，S3VM试图找到能将两类有标记样本分开，且穿过数据低密度区域的划分超平面，如图13.3所示，这里的基本假设是“低密度分隔” (low-density separation)，显 然，这是聚类假设在考虑了线性超平面划分后的推广.

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180630/Fa2C4a9Gke.png?imageslim)



半监督支持向量机中最著名的是 TSVM (Transductive Support Vector Machine) .与标准SVM 一样，TSVM也是针对二分类问题 的学习方法.TSVM试图考虑对未标记样本进行各种可能的标记指派(label assignment),即尝试将每个未标记样本分别作为正例或反例，然后在所有这些 结果中，寻求一个在所有样本(包括有标记样本和进行了标记指派的未标记样 本)上间隔最大化的划分超平面.一旦划分超平面得以确定，未标记样本的最终 标记指派就是其预测结果.

形式化地说，给定 $D_l=\{(x_1,y_1),(x_2,y_2),\cdots ,(x_l,y_l)\}$和 $D_u=\{x_{l+1},x_{l+2},\ldots ,x_{l+u}\}$ 其中访 $y_i\in\{—1，+1\}$ ，$l\ll u$ ，$l+u=m$  TSVM 的学习目标是 为 $D_u$ 中的样本给出预测标记 $\hat{y}=(\hat{y}_{l+1},\hat{y}_{l+2},\cdots ,\hat{y}_{l+u},)$,$\hat{y}_i\in\{—1,+1\}$，使得

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180630/EB11hc93m5.png?imageslim)


其中， $(w,b)$ 确定了一个划分超平面; $\xi$ 为松弛向量，$\xi_i(i=1,2,\cdots ,l)$ 对应于有标记样本, $\xi_i(i=l+1,l+2,\cdots ,m)$ 对应于未标记样本；$C_l$ 与 $C_u$ 是由用户指 定的用于平衡模型复杂度、有标记样本与未标记样本重要程度的折中参数.

显然，尝试未标记样本的各种标记指派是一个穷举过程，仅当未标记样本 很少时才有可能直接求解.在一般情形下，必须考虑更高效的优化策略.

TSVM 采用局部搜索来迭代地寻找式 (13.9) 的近似解.具体来说，它先利用有标记样本学得一个 SVM ,即忽略式(13.9)中关于 $D_u$ 与 $\hat{y}$ 的项及约束.然后，利用这个SVM对未标记数据进行标记指派(label assignment),即将SVM 预测的结果作为“伪标记”(pseudo-label)赋予未标记样本.此时 $\hat{y}$ 成为已知，将其代入式(13.9)即得到一个标准SVM问题，于是可求解出新的划分超平面和 松弛向量;注意到此时未标记样本的伪标记很可能不准确，因此 $C_u$ 要设置为比 $C_l$ 小的值，使有标记样本所起作用更大.接下来，TSVM 找出两个标记指派为异类且很可能发生错误的未标记样本，交换它们的标记，再重新基于式(13.9)求 解出更新后的划分超平面和松弛向量,然后再找出两个标记指派为异类且很可能发生错误的未标记样本，......标记指派调整完成后，逐渐增大 $C_u$ 以提高未标记样本对优化目标的影响，进行下一轮标记指派调整，直至 $C_u=C_l$ 为止.此时 求解得到的SVM不仅给未标记样本提供了标记，还能对训练过程中未见的示例进行预测。TSVM的算法描述如图13.4所示.



在对未标记样本进行标记指派及调整的过程中，有可能出现类别不平衡问 题，即某类的样本远率于另一类，这将对SVM的训练造成困扰.为了减轻类别 不平衡性所造成的不利影响，可对图13.4的算法稍加改进：将优化目标中的 $C_u$ 项拆分为 $C_u^+$ 与$C_u_-$ 两项，分别对应基于伪标记而当作正、反例使用的未标记 样本，并在初始化时令

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180701/32GH4LLGlE.png?imageslim)

其中 $u_+$ 与 $u_-$ 为基于伪标记而当作正、反例使用的未标记样本数.

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180701/BFLBB6994c.png?imageslim)


在图13.4算法的第6-10行中,若存在一对未标记样本 $x_i$ 与 $x_j$ ,其标记 指派 $\hat{y}_i$ 与 $\hat{y}_j$ 不同，且对应的松弛变量满足 $\xi_i+\xi_j>2$ ,则意味着 $\hat{y}_i$ 与 $\hat{y}_j$ 很可 能是错误的，需对二者进行交换后重新求解式(13.9),这样每轮迭代后均可使 式(13.9)的目标函数值下降.

显然，搜寻标记指派可能出错的每一对未标记样本进行调整，是一个涉及巨大计算开销的大规模优化问题.因此，半监督SVM研究的一个重点是 如何设计出高效的优化求解策略，由此发展出很多方法，如基于图核(graph kernel)函数梯度下降的LDS 、基于标记均值估计的 meanS3VM 等.







# ORIGINAL
1. 《机器学习》周志华
