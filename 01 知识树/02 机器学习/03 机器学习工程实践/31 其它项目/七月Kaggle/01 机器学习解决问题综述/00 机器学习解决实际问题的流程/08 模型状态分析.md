## 然后，进行模型状态分析


### 模型的状态


模型的状态有：

- 过拟合(overfitting/high variance)
- 欠拟合(underfitting/high bias)

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180718/CB8GiIJBb4.png?imageslim)


### 怎么知道模型是出于过拟合还是欠拟合呢？

那么，我们怎么知道模型是出于过拟合还是欠拟合呢？

我们可以对模型的状态进行评估：

在 sklearn 中，我们可以使用 learning curve 学习曲线 来对模型的拟合状态进行评估。

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180718/lK5ae738Hl.png?imageslim)

<span style="color:red;">学习曲线到底是什么？之前没看到过</span>

在 sklearn 中，我们可以这样绘制学习曲线：

```python
from sklearn.svm import LinearSVC
from sklearn.learning_curve import learning_curve
#绘制学习曲线，以确定模型的状况
def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,
                        train_sizes=np.linspace(.1, 1.0, 5)):
    """
    画出data在某模型上的learning curve.
    参数解释
    ----------
    estimator : 你用的分类器。
    title : 表格的标题。
    X : 输入的feature，numpy类型
    y : 输入的target vector
    ylim : tuple格式的(ymin, ymax), 设定图像中纵坐标的最低点和最高点
    cv : 做cross-validation的时候，数据分成的份数，其中一份作为cv集，其余n-1份作为training(默认为3份)
    """
    plt.figure()
    train_sizes, train_scores, test_scores = learning_curve(
        estimator, X, y, cv=5, n_jobs=1, train_sizes=train_sizes)
    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std = np.std(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    test_scores_std = np.std(test_scores, axis=1)
    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,
                     train_scores_mean + train_scores_std, alpha=0.1,
                     color="r")
    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,
                     test_scores_mean + test_scores_std, alpha=0.1, color="g")
    plt.plot(train_sizes, train_scores_mean, 'o-', color="r",
             label="Training score")
    plt.plot(train_sizes, test_scores_mean, 'o-', color="g",
             label="Cross-validation score")
    plt.xlabel("Training examples")
    plt.ylabel("Score")
    plt.legend(loc="best")
    plt.grid("on")
    if ylim:
        plt.ylim(ylim)
    plt.title(title)
    plt.show()
#少样本的情况情况下绘出学习曲线
plot_learning_curve(LinearSVC(C=10.0), "LinearSVC(C=10.0)",
                    X, y, ylim=(0.8, 1.01),
                    train_sizes=np.linspace(.05, 0.2, 5))
```

上面这个这个 plot_learning_curve 可以直接拿来用。他会绘制出如下图：

 ![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180718/HBj1jICHAI.png?imageslim)




### 怎么解决过拟合问题？

过拟合和欠拟合都要总结进来。blog里面都有。


减少特征的量非常不推荐使用，如果不能增加样本的量，可以增加正则化作用。
