

值得思考的问题：

## 为什么这类问题首先被国外的CV 界同仁‘填坑’？

为什么这些 fancy 的问题都被国外的人发现了？咱们总是说创新，但是我们实际上都在做一些传统的东西，比如 visual tracking，object tracking ，detection 啦，人群分析啦，object detection啦。

image captioning 是一个比较新的，他们真的是对这个感兴趣，而不是被绩效考核什么的束缚的。所以更容易想一些比较好玩的有意思的东西。

比如说刚才讲到的一个 demo ，一个人拿着电脑在城市里转，我们也可以做，但是我们很少有人感兴趣把它放到网上。

有同学说：对神经网络的数学本质认识的不清楚。。老师说：他跟老外聊，老外很多也认识的不太清楚。而实际上 image captioning 这个东西也没有什么数学的东西，就是 CNN + RNN，然后他们就做得非常带劲。

但是我们国内就甚少有人这样，要不就是做传统的东西，

就导致，我们就在跟风，别人做 image captioning ，我们也做，为什么之前没有想到呢？我们就是空谈创新，

我们不是抱着兴趣，只是抱着赚工资，短期出成果，赚钱的目的在做科研。

## Better CNN baselines

这个就是这节课开头我们讲到的，就是：

一个是 可以把 baseline 换好，用 Resnet 做 recognition，因为毕竟你的captioning 最重要的就是你的feature，你的图的feature 越好，结果越好。

有同学说时间慢怎么办：换卡，或者加卡。 8 卡的 TitanX 没有就别做 ResNet 了。

有同学说不能实时：train 的时候不能实时，但是 test 的时候完全可以实时的。而且，test 的时候即使用 ResNet 也只需要 4~5G 的显存，刚才的 demo 用 mac pro 都可以的。<span style="color:red;">嗯，是的，看了那个demo 之后，的确对于这个实时就了解了些了，之前一直以为做不到实时，实际上用稍微好点的带 GPU 的电脑就可以做到。当然，如果是发到 server 上进行处理又是另外一套了。嗯，还是觉得，这个发到 server 上进行处理的这一整套是一定要做到的，因为 5G 以后普及，联网处理是很快的。</span>


## Stacked-Hourglass Architecture

Hourglass 是漏斗的意思。

就是可不可以使用一些 Stacked-Hourglass Architecture

- 使用模块进行网络设计
- 先降采样，再升采样的全卷积结构
- 跳级结构辅助升采样
- 中继监督训练

它是 unsampling ，因为你为了维度一致，这样你的highlevel 和 low level 都用到了。

这个创新是把 low level feature 又加到 hight level feature了。这项就相当于修饰了 low level feature。所以，他相当于有一种修饰 feature 的作用，那么我们再套上 CRF 或者feature 之间相互嵌套的关系，能得到更好的feature，那么会不会也帮助 image captioning 呢？<span style="color:red;">还不是很清楚。</span>



http://blog.csdn.net/shenxiaolu1984/article/details/51428392

<span style="color:red;">这个还是要整理明确下的。具体是做什么的？可以用在这个 densecap里面吗？老师好像没有说。</span>

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180816/eJIlC16LKF.png?imageslim)

原始的 Hourglass 是用来做人群姿态分析的，比如张开手、还是伸开手臂、还是蜷缩在一起，



作业：

1. 在Torch里复现neural talk 模型，在 MSCOCO dataset train 自⼰的模型。考虑 data augmentation.<span style="color:red;">查了下 data autmentation 才知道是数据增强，就是在数据量比较少的时候创造一些新的数据的方法。</span>
2. 复现denseCap 模型，思考该模型与neuralTalk的区别。能否加⼊其他struture的变种？<span style="color:red;">区别在网上已经有很多分析了。要总结下。什么叫其他的struture 的变种？</span>
3. LSTM 与 RNN 在torch里亲自试用一下， LSTM与 ResNet 的相似性，为什么用 LSTM 不用 RNN等。
4.


1. Code base
https://github.com/karpathy/neuraltalk2
2. denseCap
https://github.com/jcjohnson/densecap
3. For other resources, please refer to the detailed slides







## REF

- 七月在线 opencv计算机视觉
