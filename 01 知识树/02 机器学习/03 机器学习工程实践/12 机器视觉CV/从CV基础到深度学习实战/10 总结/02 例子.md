

## 例子：Soft Attention for Captioning

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180817/icHHK9A2FI.png?imageslim)

我们已经有了 CNN、RNN 工具

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180817/d4ALLAai8g.png?imageslim)

CNN 把一个图像变成了一个 tensor 的表示，会比变成一个 4096 的向量，他的 multi instance 的信息就包含进去了，就是说里面的每一个小柱子代表了图像中一个区域，这个是它的核心，这个事情是需要从机器学习的角度来看的，我们这个 attention 其实就是利用了这个表示，他把tansor 拿出来了，这个每一个框框![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180817/40hJf0Ij9f.png?imageslim)代表的是每一个小柱子，而这个框框是能够回溯到原图像中的具体的区域的，然后，我再针对于这些 instance 利用 RNN 我每次做一个 softmax，softmax 回归的时候，我需要 attention 的 instance 的 id。所以，一个是这些 instance 的一个线性叠加，一个是我的 caption 的 word，我就能每次预测出一个需要 attention  attend 到的一个 instance 的位置。<span style="color:red;">还是没理解，要弄明白，并且要弄清楚我对于这些知识的掌握还有哪些不足？</span>

所以，如果你回到这篇论文之前，有人让你帮他做一个attention，那么如果你对 CNN 的真正的背后比较了解，又懂一些 RNN，那么你需要能够自己做出来。<span style="color:red;">现在还不能够，看来没看一篇论文都要达到这样的程度才行，只看他提出的问题，然后自己想出解决方案，并真正实现。然后与这个论文进行对比。</span>


另一个例子：

## Learn a shared space for both images and texts

就是我们想做一个隐空间，shared space，以前我们对label 的编码是 one-hot encoder 比如 00010 ，其实我们的每一个 label 是一个英文词。我们的 NLP 里面是有一个东西叫做 word2vec ，这种表示比 one-hot 的表示要好非常多，所以，如果我们要做一个分类问题，把这个label 背后的语义信息忽视了的话，直接强行回归到不包含任何语义信息的这么一个 one-hot label 里面去，肯定是不够圆满的。

有没有可能我们把这些label 当做一些词，然后用一种 embadding 的方式嵌入成一个向量，然后，我们做的是一个回归任务？


![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180817/5ach50chAi.png?imageslim)


就是，图像的一种 embadding 和 label 的一种 embadding，label 在共享的空间中的嵌入是这么样的，然后，图像在空间中的嵌入是这样的。然后我们通过监督学习的方式，尽可能让标注有 cat 的label 的图像都跟 cat 这个label 比较近。

这个事情也有人做

比如说，我们的图像输入 VGG，然后，输出，然后输出成 word2vec，那么这一层就是我们的 shared space。

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180817/chl77bmGfg.png?imageslim)


<span style="color:red;">第一次听到这种 shared space ，真的是非常好，感觉图像和文字就有了某种关系。再理解下。</span>

在这个shared space 中就可以做一些事情了，这个关注一下。



## Kaggle Whale Challenge

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180817/dKBD4hDdmk.png?imageslim)


4237 张鲸鱼的照片，有 427 个类别，对鲸鱼进行分类。

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180817/Ilci4AiJKb.png?imageslim)


有的类别只有一张图片。


我们最基本的方法就是：

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180817/fbg48J6i5A.png?imageslim)

做机器学习还是这样迭代开发比较好，先从最简单的开始。

当你把它卷积后的一些图像输出看的时候，你会发现，海浪上的一些波纹也成为了一些特征，这个是不想发生的。

OK，那么怎么解决呢？

一种方式是我们可以把图像中鲸鱼头部的地方切出来，然后放到 VGG 里面

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180817/labIEE4C4a.png?imageslim)

那么怎么找到这个鲸鱼头部的框呢？

我们可以标注一些 bounding box ，然后做回归，因此我们可以做 RCNN 或者 Faster-RCNN。

OK，现在还需要做什么吗？

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180817/87gCAHdH3k.png?imageslim)


我们发现鲸鱼的头部的指向是随机的，而神经网络会把这个角度作为一个特征。

所以，我们需要找到他的头和脖子，然后做一个旋转，把头的方向扭成这个方向。

那么我们怎么找关键点呢？

我们只要标注足够多的数据，然后回归这两个坐标就行。回归完之后，我们计算一下这个坐标与平面的夹角，然后旋转一下。



## 车型识别

做工程化的CV 项目的时候，一定要遵循我们的思路，我们想要什么，我们现在有什么工具。然后分步骤解决。

我们就把神经网络看做一个分类和回归的工具，而且我能够生成一些东西，等。

因此，我们要把 problem fit 成 ML 的一个问题，然后用 ML 的 tools 来解决他。
就是把想做的东西变成机器学习的一个问题，然后用机器学习的工具来解决他。<span style="color:red;">真的是厉害。</span>

至于机器学习中的工具要怎么选呢？这个要结合具体的场景和工具的特点，这个是专业知识范围，但是我们之前的思考的思路是不需要什么专业知识的。不用慌。迭代的问自己：你想干什么，你能干什么。

对搞科研的，老师强调一点：提出问题比解决问题要重要的多。真正区分出牛人和不牛人的就是，你是否能提出具有重要意义的问题。一般只要问题提出来了，没有解决不了的。<span style="color:red;">厉害。为什么我感觉这个冯老师这么厉害。讲课也非常清晰。</span>





后面是提问环节：

### VGG ，部署之后，运行不会很慢的，实时要看需求是多实时。
- 首先，可以对网络进行压缩，能够大幅的加快你的训练时间和运算时间。<span style="color:red;">怎么压缩的？model compression 要总结下。</span>
- 然后，买个好一点的显卡就行，一般来说问题不大。

然后，这个同学还是说实测不行，说已经使用了 titanx。

老师说：这个 titanX 很好，但是，你是否装了一些比较好的加速库，这个是决定你神经网络运行时间的关键性因素，就是比如 cudnn 和 底层的什么MKL库，这些比较好的数学运算库，这个的提升效果是比你从 1080 升到 titanX 所能得到的性能的增益要来的更多的。 cudnn 有和没有的影响是数量级的。

还有一个方式就是，一般你做一个 前向运算是 30ms 左右，如果还想加速，就只能进行模型的压缩。如果你已经是 titanX了，那么也没什么更好的方法了。

同学说他装得是 opencmblas ，老师说肯定没有 intel 给的 blas 好。一定不要小看 intel 的那些库，也是要装的。
