

假设我有这样的一个传感器，可以是1个也可以是2个，然后我又两个 lence ，一个是广角，一个是长焦，他同时在 一个 ccd 也好，2个也好做成像。

大家最这样的硬件的设备做什么 application 比较好？

iphone 7 plus 是两个摄像头，两个传感器。

给大家看一下 AR 的例子


AR 现在越来越火了，以前是 VR 虚拟现实，现在是 AR 增强现实。

我们相用 VR 的时候就要提到 openGL 进行画图的工具，一个库，这个时候就需要把 opencv 的源代码重新编译。

Set up OpenGL in OpenCV with CMake
- 下载cmake： http://www.cmake.org/download/
- 路径： sources文件夹；勾选advanced，然后
configure； Generate
    - 检查 ‘CMAKE_LINKER’, 保证是 Visual Studio 12.0 （vs2013）
    选上 ‘WITH_OPENGL’
    - 取消 ‘BUILD_DOCS’ and ‘BUILD_EXAMPLES’

重新编译可能出错的地方很多：这里提一下比较重要的地方。远吗可以在opencv 的官网上编译。generate 之后就会出现一个 opencv 的工程 opencv.sln 。

这两个就是老师自己编译的，一个是3.1 的一个是 2.4 的。

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180811/7C5KJ85d10.png?imageslim)



Example: Simple AR

Mastering OpenCV with Practical Computer Vision Projects 这本书可以看下 simple AR 这个例子就是这本书里的。

- 相机标定
- 提取模板图像的特征与描述子
    - ORB + FREAK
- 图像（实时）匹配
    - 特征检测，描述子提取， 离群值过滤
- 单应性变换
- 姿态估计并画图


我们简单说一下这个例子的过程：


首先要进行相机的标定，需要把相机的内参拿到S_x S_y C_x C_y 。这个主要是后面做投影的时候考虑的。后面我们找到原图像的位置之后，想在现实的场景那种画图的时候，需要用到这个参数。

我们有一个模板图像 pattern ，在真实的画面中，pattern 出现在这，![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180811/gAF94Kif3e.png?imageslim)
我们需要对这个pattern 在整幅图像中进行寻找，这就用到了提取特征这个问题，在这个项目中我们用到了 ORB 的检测方法，ORB既是一个detector 又是一个discriptor，这里它只用它做 detector，描述子用的是 FREAK。

接下来是拿到一副实时的图像，可以是 video ，也可以是 image。在这幅图像中进行匹配，先对pattern 做特征的抽取和描述子，然后匹配，然后把训练的这幅图像进行特征检测和描述子抽取。两个描述子都抽取之后，就可以进行match ，match常用的有暴力搜索 BF 和 FLANN。特征值好不好不能只看他检测出的特征点的个数，应该只看他好点的个数，因此一定要做离群值的过滤。比如说我们两边都检测出5个点，但是这5个点都是乱的，这种方法及不能用。

找到匹配之后，进行单应性变换，就得到了从 pattern 到实时图像的单应性变换。

在真实场景中找到pattern 之后，我们下一步做得就是在真实场景中画图，画图部分就是 openGL的问题。


下面这个就是老师使用这个例子跑出来的效果：

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180811/C2clK0AF0m.png?imageslim)


简单的过一下代码：
