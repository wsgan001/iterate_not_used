
# 近似最近邻

一点基础： 近似最近邻

- Google/Baidu 每天有海量的⽹页， 怎么判断内容是否和之前的⽹页相近？
- 论⽂查重的时候如何快速定位是否剽窃？
- 推荐的时候， 如何快速找到接近的用户/商品？
- 图像检索的时候， 如何比对海量图片找相近？
- 指纹匹配
- 在⾼维空间， 线性比对效率太太太低…
- 我们需要近似最近邻（ANN）

现在要根据一个连衣裙找到500万个连衣裙中比较相似的，如果是一个线性搜索的方式，如果使用的是集群或者非常强大的计算资源，那么 OK，但是这只是一个用户的一次搜索请求，而淘宝每天的请求量是非常大的。

所以这样的线性搜索去找最近的 n 个，也就是 knn ，这个是不可行的。

比如baidu、google 的类似的海量网页的搜索的问题。

这是一个很通用的数据挖掘中一类的问题，ANN。

这个东西不仅仅用在图像上，只要是任何高维度的vector，不管是文本、还是图像、还是视频，只要你有办法把它整理成一个高维度的vector来保证他的内容，而且，你又有非常大的数据量，比如几百万、一千万、亿级别的来做这个检索，想要比较快的时间内检索出比较接近的成员，那么怎么办呢？

在工业界，基本上都是使用的 ANN 近似最近邻。

- 比如google baidu 每天的网页去重、查重，因为每天的新闻很多人会转载，每天的blog 也有很多人转载，所以几乎都是重复的内容。

- 论文查重的时候也是这样。

- 推荐的时候也是这样，也会找一些相近的邻居，比如淘宝的用户体量这么大，因此也会使用 ANN。

- 图像检索也是这样。

- 指纹匹配也是这样。


那么这个 ANN 近似最近邻 算法到底是什么样的呢？

我们先看一下这个 LSH：

### 一点基础： 局部敏感度哈希

传统 Hash 与 Local Sensitive Hash 区别 LSH

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180814/1mcJ3E5f98.png?imageslim)

他与一般的 hash 有区别，一般的 hash 要避免冲突，不能同时落在同一个位置上，

这个 LSH 是这样：

原本是 4096 维的空间中的一个 vector，如果现在这个空间中有两个点很接近的话，我会取一个hash 函数，把它hash 到一个 128 bit 的空间中，我希望原本在 4096维空间中的比较接近的两个点在我现在的128 bit 的空间中也是接近的。

这个 LSH 做得是从高纬度到低纬度的时候保持相对距离，比如上图中 绿色和红色点在高维空间中比较近，在地位中也是比较近的。

所以，LSH 是怎么做这样的事情的呢？

- 把原始的样本点映射成长度为N的⼀个2进制串
- 其中每个位次可以理解为在空间取了⼀个超平面去做划分

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180814/75ChHljGiH.png?imageslim)


从上图可以看出，我们是选择一些超平面对这个高维空间进行切分，需要多少bit就选多少个超平面进行切分。由于有些样本被划分到同一个区域了，所以这些点所对应的01串是相同的。

这些超平面怎么得来的？在Github 上有一个最简单的实现 ：Lshash  这个，它用一个文件就实现了，它做的时候就是随机取的超平面。老师推荐看下源码的实现。<span style="color:red;">这也行？随机的超平面？为什么不用一些算法去找到一些超平面？而且这样随机取，如果把很大部分的样本都划分到一个空间里怎么办？老师说随机取超平面是 OK 的，只要你保证你超平面的个数不是特别少。有约束的超平面选择的方法也是有的，老师说这个与 CV 的关系不是很大，因此没有讲。嗯，也要看下，顺便看下它的使用场景。</span>

有同学说：a和c 这个点的划分不是很合理把？因为a 和 d 更远但是分在一起了。是的，这个的确是一个问题，那么为了平衡精准度和速度，我们要怎么办呢？

首先，这个 ANN 的方法的确是牺牲了一部分的准确度的，超平面的划分不一定是合理的。

但是，在这个前提下怎么提升精确度呢？

- 一个办法是再多分几个超平面，没准 a 和 d 就分开了。但是，如果我们取了很多的超平面，这样会带来一个问题，最后的每个 n bit 的数对应的样本非常的少。我就找不到某个样本最近的样本了。<snpan style="color:red;">这个地方有点疑惑，这个为甚不行？不是说高维的相对距离到低维不会变的吗？我直接从这个 hash 值周围找不行吗？还是说这个 hash 是没有排序的？</span>
- 另外一个处理方式是什么呢？比如我刚随机取了3个超平面，得到了 3 bit 的一些数，这时候我另外再随机取三个超平面，又得到了一组数。这样，我就有了两组 hash 函数，那么我找 a 最近的邻居的时候，我会在 hash1 中取出同样的 hash 值的样本，然后在 hash2 中取出同样 hash 值的样本，再取并集，然后，我们在这个并集中找到谁是最接近的。<span style="color:red;">是个好方法。只是计算量大一些，需要算两个hash。</span>

那么还有个问题，n 的大小多少合适呢？

这个要根据你的维度和你的样本量，比如你的维度是 4096*1 样本量是 50万，你可能就会用一个大概的经验值以大概 2 的倍数去调。<span style="color:red;">这个 2 的倍数并不是强制的，只是老师说大部分人喜用 2 的倍数。</span>没有说有明确的公式去判断什么样的 n 最合适，因为你的样本点在你的空间中可能并不是很均匀分布的，如果是均匀分布的，可能我切了几刀就有比较好的结果，但是如果聚成了一团，那么这几刀可能就不够，需要更多的切分。


下面是  LSH 的简单的示意图：

Local Sensitive Hash示意图

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180814/i01a5kCCKd.png?imageslim)

上图可以看出，在不同的 hash 方式下，hash1 里面这个图找到的相似图是这个鸭子，然后 hash2 中找到的是另外一个鸭子。最后我们根据几个 hash 找到了4张图，然后我们就可以用 4096*1 的vector 与这几张图的 vector 求距离来确定谁最接近，可以使用 cos 距离或者欧氏距离。

嗯，老师最后说了下，对这个空间进行划分，就是对这个空间进行分桶，接近的图像放在一个桶里面。

<span style="color:red;">的确是个好办法呀。</span>

<span style="color:red;">我这里想到一个问题，因为淘宝的商品一直在更新，也就是，样本一直在增加的，这个模型是不是就直接把新增加的样本放到对应的 hash 值里面就行了？还是说也要进行某种更新？比如随着样本的增加而增加一些超平面什么的。</span>

有的同学说：

为什么不用聚类分桶？聚类分桶的效果会不会更好？老师说：聚类是非常耗时的事情，因为这个 LSH 只需要切一下，我就知道一个 bit 的0还是1了，而聚类的 k-means 、谱聚类 这个是非常耗时的，因为是一个迭代的算法。即使准确度比 LSH 要好一些，但是工业界应该不会接受。因为太慢。

老师说他之前带过实习生，给了 80w 张图片，用能想到的方法来进行聚类，结果把图像特征抽出来了，图像的文本描述也抽出来了一起做了个聚类，大概聚了8个小时。而对 80w 的图片进行聚类用了 8个小时这个工业界是没办法接受的。而 LSH 和用神经网络学习出一个分桶更好。用神经网络学习出一个分桶电商在用。<span style="color:red;">用神经网络学习出分桶这个怎么做的？</span>

ANN 的算法还是很多的，除了 LSH 之外还有K-Means  Tree 和 K-D Tree。

不管何种算法， 都是尽量预先对数据做⼀些划分和索引。这样我就能预先的知道这些图像可能和那些图像是接近的。而不需要去全局的过一遍。会损失掉一些准确度。但是会换取搜索速度的极⼤提升。从原来的需要比对空间中所有的点，到只需要比对我区域里面的点就行了。

⼯程上常用算法：

- LSH（Local Sensitive Hash / 局部敏感度哈希）
- K-Means Tree
- K-D Tree


K-Means Tree 是这样的：如果我平面上有些样本点的分布，我取 k=3 ，我就把平面画出了这 3个区域，然后每个区域再做k-means ，我们再取 k=3，这样就有了一些小区域，像这样一层一层的下去。

K-D Tree 是类似的。这个老师没有讲。 <span style="color:red;">K-D Tree 好像在算法中经常能看到，还是要看下的。</span>


说明： ANN的算法帮助我们缩小范围和提速， 严格的距离排序依旧需要依托于前面的距离准则。<span style="color:red;">是的。比如前面的额到底那只鸭子最近还是要靠 vector 之间的距离来决定的。</span>



### OK，下面说几个 ANN 的库：

只说有 python 接口的。不管它底层的实现是用什么。


#### ANNOY

建索引与最近邻查找， 可以直接⽤list作为向量输⼊

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180814/bGL9Ffae8A.png?imageslim)

做索引的时候：我针对我现在的 vector v来找到最近的 n 个向量。

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180814/a49dK87f7C.png?imageslim)


#### FLANN

这个是老师推荐的，虽然比较老，但是速度和对内存的消耗都优化的比较好，而且，他有一点比较好的是，可以指定准确率，比如说希望我快速检索出的最近邻的准确度达到 90% ，他会根据这个区权衡我需要建立的这个索引需要消耗多大内存。

这个之前老师用的时候，不确定 anaconda 里面有没有集成，他是自己 down 下来编译的。

- 实现多种最近邻检索⽅式， 可以指定准确率
- 可以选择⾃动模式， ⾃动选最合适的模型和⽅式
- 数据量⼤的时候载⼊模型稍微有点慢

使用方式如下：

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180814/e2gbCfJjBJ.png?imageslim)

我会生成一个集合，1w 个，每个都是 128 维的，然后给 1000 个向量，我希望每个向量都可以检索回来他最近的5个向量。

autotuned 是不指定他是 LSH 还是 K-means Tree 什么的，让他帮我们找一个合适的算法。

检索的时候，会得到 1000*128 的向量。


#### Kgrapth

这个差不多。

- 可并⾏化地建索引和检索近似最近邻
- 建完的索引⽂件⼤⼩稍微⼩⼀些

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180814/ll5lDKA7Dj.png?imageslim)

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180814/HJ7LCCkImg.png?imageslim)

#### Nearpy

这个是很经典的一个，支持 redis 的存储。

- 构建在Numpy， Scipy和 redis 之上
- 因为cache在redis之上， 可以增量式补充数据， 增加索引

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180814/K191faKCf4.png?imageslim)

#### Lshash

这个之前老师提过，非常精简，可以直接看到他的超平面是怎么生成的，他是怎么做这个运算的

- 超级精简！！
- 也⽀持redis存储索引

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180814/8AH4egfJ9e.png?imageslim)

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180814/kbbfahCmbm.png?imageslim)
