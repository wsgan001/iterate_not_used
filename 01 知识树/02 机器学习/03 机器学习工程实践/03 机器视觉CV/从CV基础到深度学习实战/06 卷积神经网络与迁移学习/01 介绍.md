

主要讲卷积神经网络和一些迁移学习的内容

- 卷积神经网络快速回顾
    1.层级结构 2.数据处理 3.训练算法 4.优缺点
- 典型CNN
    1.AlexNet 2.GoogLeNet 3.VGG Net 4.ResNet
- 物体定位
    1.回归的思路
- 物体检测
    1.早期做法 2.RCNN/Fast-RCNN/Faster_RCNN 3.R-FCN
- 文艺绘画与Neural Style
    1.风格描述 2.主体对调与损失最小化


从物体定位到物体检测到Neural Style


我们先回顾一下卷积神经网络

卷积神经网络层级结构

不同层次结构有不同形式(运算)与功能

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180811/lJ0GaGmbCd.png?imageslim)


这是一个非常典型的卷积神经网络，现在的有些变更，但是差不多。


主要是以下层次

- 数据输入层/ Input layer
- 卷积计算层/ CONV layer
- ReLU激励层 / ReLU layer  activation layer
- 池化层 / Pooling layer 有时候会说叫下采样层。
- 全连接层 / FC layer
- Batch Normalization层(可能有)

FC 可以在一定程度上完成小部分的信息还原。因为前面做了大量的下采样，大量的参数共享，捕捉到了大的图片信息，比较detal 的信息可能在这个途中有所损失，因此接一个 全连接层可以对信息有一定程度的还原。<span style="color:red;">真的是这样吗？为什么可以有一定程度的还原？为什么detail 的信息会损失？</span>

这个 Batch Normalization 是 15年的时候 google 的一篇paper，现在看各种各样的开源的package，包括 caffee tensorflow，等现在都有这个 Batch Normalization 。

我们分别过一下：

### 数据输入层/ Input layer

有3种常见的图像数据处理方式

- 去均值
    - 把输入数据各个维度都中心化到0
- 归一化
    - 幅度归一化到同样的范围
- PCA/白化
    - 用PCA降维
    - 白化是对数据每个特征轴上的幅度归一化

基本上在我们的 image classification 或 object detection 里面，我们对数据做得处理只会有一个去均值，我会把训练集上的图片的均值求出来，然后做训练的时候，把训练集上减去这个均值，预测的时候，也都要减去这个训练集上的均值。

均值的求法有两种，

- 看早期的 AlexNet，它会求出一幅图 在 scale 为同一幅度比如 225*225*3 之后，它把整个训练集的 100万张图片的225*225*3 的矩阵求和，然后除以100万，拿到的均值矩阵是 225*225*3 的维度的。
- VGG 是14年在ImageNet上提出来的，在 transferLearning 上非常好用，它只求了三个颜色通道的均值。所以，相当于 100万*255*255 个像素的平均 。所以这是不同的求均值的方法，任何一种都OK。<span style="color:red;">有什么优劣的区别吗？</span>

所以一般情况下只会做去均值。下面的 归一化和PCA、白化其实只是在其他的场景中可能会用到，在图像中基本不会使用，因为 RGB本身就在同样的范围内，因为不用做 scaling 归一化。



### 卷积计算层/ CONV layer

- 局部关联。每个神经元看做一个filter。
- 窗口(receptive field)滑动，filter对局部数据计算
- 涉及概念：
    - 深度/depth
    - 步长/stride demo
    - 填充值/zero-padding

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180811/5CdAme5CBJ.png?imageslim)

cs231n.github.io/assets/conv-demo/index.html

进入到 CONV layer 层的数据已经是经过 resize 到一个尺寸之后再减去均值会后的数据。

卷积层

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180811/d314di11EF.png?imageslim)

最左边的三个矩阵标识的是三个图像 7*7 大小 ，之所以是三个矩阵，是因为有三个颜色通道。卷积层这一层有很多个神经元，每个神经元可以看做一个滤波器，对原来的数据进行卷积处理。
