# 机器学习算法、 工具与流程概述

机器学习解决实际问题的流程，包括建模的方式和优化的方式

和我们要用到的工具和模板来看一下。


在之后的每一节案例课都要能找到对这节课中的一些东西的使用，要对应上来。

这节课会提到完整的工作流程。实际的应用中不一定会对应所有的环节。

## 主要内容

- 机器学习应用领域
- 机器学习常用算法
- 常用工具
- 建模与问题解决流程。涉及到的每个环节对应的库 都会介绍一下。
    1. 数据处理
    2. 特征工程
    3. 模型选择
    4. 寻找最佳超参数： 交叉验证
    5. 模型分析与模型融合
- Kaggle wiki
- 简单案例讲解

比如说大家都是用了 GBDT， xgBoost，基本上都是使用这些模型，然后使用的是一样的数据集和一样的特征，那么这个时候结果的不同就与超参数的选择有关。比如说有多少棵树，比如说树的深度是多少，比如说boosting 的轮数到底是多少轮，这些超参数会直接影响你的结果。因为是在这些超参数形成的框架下对模型进行训练的，模型最后的参数也是在这个框架下得到的。

至于模型融合，因为参加比赛的话很少有一个模型会达到 top3 的，大部分都会使用model resample。

所有，我们会顺着 1,2,3,4,5 这5个步骤来使用 sklearn 对应的那些函数，

Kaggle wiki 可以了解下历史上有没有与当前这个问题比较类似的问题。这个比较类似的问题有几重含义：

1.评判的标准，比如说你的优化是针对准确率的，但是任务是关于的AUC，那么即使你的准确率做得很好，但是AUC并不一定是很好，这些评判的标准在kaggle wiki 里面都有：

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180716/F9IAL2B2b9.png?imageslim)
![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180716/7la8gdBh90.png?imageslim)

<span style="color:red;">这个kaggle 的wiki 现在是不是没有了？这个kaggle 的wiki 还是要看的。</span>

比如说滴滴打车的一个比赛的，评价的标准和大家的标准就不一样，它是要评估每块地区对于车的需求量。第一名对于loss function 进行了修正，它是使用的xgboost，它支持设置自己的cost function。因此你要知道你评判的目标是什么，然后才能针对这个目标进行优化。




## ML 在工业界是有很多的应用的

- 经济相关： 股市、 房价等。
- 能源相关： 产能预测、 分配与合理利用。比如传统的电力公司会举办比赛来预测这个用户是不是会偷电。
- NLP相关： 检索、 分类、 主题、 相似度。互联网公司会需要的。
- 互联网用户行为： CTR预测。广告的CRT预测。
- 销量预测： 电商、 连锁店、 超市。 他们希望能做到销量的预测，可以帮助库存成本。
- 深度学习应用： 图像内容理解。图像是DL落地比较多的领域。
- 推荐系统相关： 电商推荐。比如电商的推荐系统，这个是切实有效的。
- 其他预测： 气候、 社交网络分析。从大量的数据上产生一些可以辅助我们决策的信息。

基本上你所做的工作都会划分到上面这些领域里面。

## ML 常用的算法：

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180716/gDI7kKiK73.png?imageslim)


RL 目前在工业界主要应用在机器人里面。
实际上工业级监督学习是比较关键的，这类算法使用的比较多，非监督学习主要作为辅助。

可以把算法大致的分到这四类里面。

对于右上角：都是经常用的。
对于右下角：KNN 用的比较少了，工业界大量用的是LR，朴素贝叶斯是很简单的，数据如果处理和比较均匀，那么用朴素贝叶斯也不错，很多公司的NLP还是用的朴素贝叶斯的。SVM 在中小型数据量上的使用还是比较好的，在DL出现之前是垄断了大部分的分类问题。

对于左上角：发部分是用作辅助用的，比如SVD和PCA，在数据的维度很高的时候，可以先做这两个来降维。实际工业界很少用到谱聚类的算法，还是会用K-means这种算法，基本上K-means 大部分是做辅助，比如说推荐系统和CRT预估，我们可以根据用户的行为先做一个聚类，先看看那一部分用户属于什么cluster里面，这个class 的id 可以在最后送到我的监督学习模型里面，作为一个feature。


对于左下角，HMM用的比较少了，因为RNN很大部分会替代HMM。关联规则还是会用的。

## 机器学习常用算法

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180716/AEAHfG37g9.png?imageslim)

这个只是给大家一个大致的参考。可以去把我对于算法的选择约束到某些算法里面。
如果你的数据量非常少，那么你甚至只需要创建一个简单的规则就行。

如果确定是一个分类问题，这个地方根据样本的大小，如果样本非常多，那么我们可能无法把所有的样本全部放到内存中，那么我们可以使用SGD，<span style="color:red;">这个地方的SGD 是怎么使用的？</span>


## 机器学习常用工具

- scikit-learn 非常全，非常好用，但是不是速度最快的，基本上可能会用到的ml 的算法这里面都有，封装的非常好。直接mldel.fit(x,y) 就行。
- gensim 如果是做NLP，这个就是一个topic model，生成 word vec doc vec
- numpy 是一个比较底层的，实际上用到的比较少
- matplotlib
- pandas 会频繁的在数据清洗的时候使用，也就是数据的预处理，比如说产出特征，
- xgboost 专门boosting 的一个库，可以用作分类，也可以用做回归。
- Natural Language Toolkit 这个是英文的NLP，但是中文由于有分词，因此用的比较多的是 jieba。
- Tensorflow 对显存的占用有些高，而且速度也不是太快，
- Caffe 图像用Caffe 用的比较多
- MxNet 与 XGBoost 是一家的。
- Keras 接口非常简单，后端可以接 Tensorflow

我们这个课的 DL 部分应该会用Keras 做。



## 解决问题流程

- 了解场景和目标
- 了解评估准则，比如说ranking的评估就比较特殊。<span style="color:red;">怎么特殊？</span>
- 认识数据。比如说数据是不平衡的，比如广告的点击比不点击少很多。
- 数据预处理(清洗，调权)。以你对数据的认识，进行清洗，比如离群点要清洗掉，
- 特征工程。百度的模型也是一般，但是feature做得非常好，它直接决定了模型的好与坏。
- 模型调参。
- 模型状态分析
- 模型融合

在真实的问题上，你想提升效果，那么数据上的提升一定是大于模型的。如果数据非常好，你用一个简单的模型也能达到很好的效果。一些很高级的模型，很高级的模型融合的算法，调参等大概只占 30% 的时间。而数据特征对于最后的结果的决定性是非常高的，模型相对而言没有那么重要，实际工业中和比赛中也是这样。


解决问题流程：<span style="color:red;">这两个里面的内容一定要掌握。要整理进来 下面都是这个blog 的内容</span>

http://blog.csdn.net/han_xiaoyang/article/details/50469334 http://blog.csdn.net/han_xiaoyang/article/details/52910022


上面带着代价走马观花过了一遍机器学习的若干算法，下面我们试着总结总结在拿到一个实际问题的时候，如果着手使用机器学习算法去解决问题，其中的一些注意点以及核心思路。主要包括以下内容：

- 拿到数据后怎么了解数据(可视化)。高维的可能没法可视化，但是有 t-SNE 的可视化方式，也可以降维然后可视化。做不了可视化也可以看每一个维度的波动的情况，如果是一个分类问题，如果一个 feature 波动非常大，那么这个feature可能作用比较大
- 选择最贴切的机器学习算法
- 定位模型状态(过/欠拟合)以及解决方法
- 大量极的数据的特征分析与可视化
- 各种损失函数(loss function)的优缺点及如何选择。有不同的目标，因此要定义不同的损失函数。


多说一句，这里写的这个小教程，主要是作为一个通用的建议和指导方案，你不一定要严格按照这个流程解决机器学习问题。

关于可视化，可视化不一定是针对全局的数据的，最起码要肉眼看一下数据。读取 pandas 之后，可以通过 head 来查看。可以对这里面的feature 计算一下相关性有多高。可以拿出几个维度做一个scactter plot




机器学习算法选择

最后怎么去评判哪个模型好？选哪个模型呢？要做一个交叉验证。
这部分blog 里面举了一个例子 讲的是 learning curve <span style="color:red;">这个之前不知道。</span>

过拟合和欠拟合都要总结进来。blog里面都有。

减少特征的量非常不推荐使用，如果不能增加样本的量，可以增加正则化作用。

大数据样本集和高维特征空间 这个blog 里面也有。可以用 SDGClassifier 有些地方也会说成 online Learning，一个意思

t-SNE 就是把高维的数据在二维的平面上可视化。







## 数据预处理

没有自动化的东西来帮助你清洗干净的，这个都要各自结合各自的场景来进行清洗。这个基本上就是人 review 数据

数据清洗
- 不可信的样本丢掉。
- 缺省值极多的字段考虑不用


数据采样
- 下/上采样 upsampling downsampling
- 保证样本均衡。为什么要保证均衡呢？因为比如说1:100 的正负样本，那么我全估计为负样本的时候，这个时候的正确率已经很高了。那么怎么办呢？<span style="color:red;">样本不均衡时候的对应方法还是要总结下的。</span>



工具
- pandas 如果数据能够载到内存里就用pandas 来清洗，也可以一个维度一个维度看。
- hive sql/spark sql 如果数据量还是很大，那么要用mapreduce 或者各种 sql 来处理。<span style="color:red;">这个也是要掌握的</span>



## 特征工程

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180718/k3ALldHFHI.png?imageslim)

<span style="color:red;">离散化的时候的段怎么界定？</span>
如果缺省值很少，那么可以填充；如果缺的很多，那么看一下这个特征要不要使用；如果缺的数量适中，那么可以把这个缺省值当做一个值：缺失来对待，比如说有三个类别123 那么如果30% 的值缺失了，那么可以把缺失值当做 4。<span style="color:red;">没想到还可以这样做。</span>
数据变换，如果在当前数据域可能没有什么变动，但是变动到log域可能就很有规律，<span style="color:red;">但是这样的变换是不是都要尝试一下？然后作为特征？</span>

如果特征的分布非常长尾而且值的差距很大，这种情况说明你这个特征可能对最后的影响不是那么的大。


特征处理


- 数值型
- 类别型
- 时间类。这个比较特殊，
- 文本型
- 统计型
- 组合特征

时间类的处理：
1. 不仅看是几月几号，还可能要看前后有什么节日？比如说双11之前只加购物车不买。
2. 也可以看这一周内发生了多少次。这周内搜索的次数。
3. 离散化，比如饿了么可以把一天的时间切分成几块。也可以


文本类型的：
n-gram ，bag of words，TF-IDF


统计型：
这个他举的例子是：开机3分钟，击败了全国30% 的人，那么这个30% 就是统计型，比开机3分钟这个数据可能能更好的与业务想结合。<span style="color:red;">有没有更确切的例子？</span>



## 特征工程

- 课程提供特征工程PDFl
- http://scikit-learn.org/stable/modules/preprocessing.html
- http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction

preprocessing 和 feature_extraction 模块 里面有很多特征抽取的方法。


  七月在线Kaggle案例班 julyedu.com 12/54 特征工程 o  特征选择 http://scikit-learn.org/stable/modules/feature_selection.html   过滤型 Ø  sklearn.feature_selection.SelectKBest   包裹型 Ø  sklearn.feature_selection.RFE   嵌入型 Ø  feature_selection.SelectFromModel Ø  Linear model， L1正则化 七月在线Kaggle案例班 julyedu.com 13/54 模型选择 o  sklearn cheetsheet提供的候选 o  课程案例经验 o  交叉验证（ cross validation） l  K折交叉验证（ K-fold cross validation） l  http://scikit-learn.org/stable/modules/cross_validation.html 七月在线Kaggle案例班 julyedu.com 14/54 模型参数选择 o  交叉验证（ cross validation） l  http://scikit-learn.org/stable/modules/grid_search.html l  http://scikit-learn.org/stable/modules/generated/ sklearn.model_selection.GridSearchCV.html 七月在线Kaggle案例班 julyedu.com 15/54 模型状态评估 o  模型状态 过拟合(overfitting/high variance) 欠拟合(underfitting/high bias) 七月在线Kaggle案例班 julyedu.com 16/54 模型状态评估 o  Learning curve:学习曲线 七月在线Kaggle案例班 julyedu.com 17/54 模型状态评估 o  plot learning curve:绘制学习曲线 https://www.zybuluo.com/hanxiaoyang/note/545131 七月在线Kaggle案例班 julyedu.com 18/54 模型融合 ü  简单说来， 我们信奉几条信条   群众的力量是伟大的， 集体智慧是惊人的 Ø  Bagging Ø  随机森林/Random forest   站在巨人的肩膀上， 能看得更远 Ø  模型stacking   一万小时定律 Ø  Adaboost Ø  逐步增强树/Gradient Boosting Tree 七月在线Kaggle案例班 julyedu.com 19/54 模型融合： Bagging   模型很多时候效果不好的原因是什么？ Ø  过拟合啦！！ ！   如何缓解？ Ø  少给点题， 别让它死记硬背这么多东西 Ø  多找几个同学来做题， 综合一下他们的答案 七月在线Kaggle案例班 julyedu.com 20/54 模型融合： Bagging o  http://scikit-learn.org/stable/modules/generated/ sklearn.ensemble.BaggingClassifier.html   用一个算法 Ø  不用全部的数据集， 每次取一个子集训练一个模型 Ø  分类： 用这些模型的结果做vote Ø  回归： 对这些模型的结果取平均   用不同的算法 Ø  用这些模型的结果做vote 或 求平均 七月在线Kaggle案例班 julyedu.com 21/54 模型融合： Bagging 七月在线Kaggle案例班 julyedu.com 22/54 模型融合： Stacking Ø  用多种predictor结果作为特征训练 七月在线Kaggle案例班 julyedu.com 23/54 模型融合： Stacking Ø  用多种predictor结果作为特征训练 七月在线Kaggle案例班 julyedu.com 24/54 模型融合： Boosting o  Adaboost   考得不好的原因是什么？ Ø  还不够努力， 练习题要多次学习 l  重复迭代和训练 Ø  时间分配要合理， 要多练习之前做错的题 l  每次分配给分错的样本更高的权重 Ø  我不聪明， 但是脚踏实地， 用最简单的知识不断积累， 成为专家 l  最简单的分类器的叠加 http://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble 七月在线Kaggle案例班 julyedu.com 25/54 o  Adaboost 模型融合： Boosting http://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble 七月在线Kaggle案例班 julyedu.com 26/54 o  Adaboost 模型融合： Boosting http://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble 七月在线Kaggle案例班 julyedu.com 27/54 机器学习完整案例 详见课堂案例分析 七月在线Kaggle案例班 julyedu.com 28/54 感谢大家！ 恳请大家批评指正！ 七月在线Kaggle案例班 julyedu.com
