TODO:
- 为什么[kaggle wiki ](https://www.kaggle.com/wiki/Metrics)没有找到？里面有一些评判的标准 Error Metrics <span style="color:red;">这个 kaggle 的wiki 现在是不是没有了？这个 kaggle 的 wiki 还是要看的。 评判的标准还是要了然于胸的</span>
-


# 机器学习解决实际问题的流程

这节课会提到完整的工作流程。实际的应用中不一定会对应所有的环节。


## 解决问题流程

流程如下：

- 了解场景和目标
- 了解评估准则，比如说ranking的评估就比较特殊。<span style="color:red;">怎么特殊？</span>
- 认识数据。比如说数据是不平衡的，比如广告的点击比不点击少很多。
- 数据预处理(清洗，调权)。以你对数据的认识，进行清洗，比如离群点要清洗掉。<span style="colosr:red;">什么是调权？</span>
- 特征工程。百度的模型也是一般，但是feature做得非常好，它直接决定了模型的好与坏。
- 选择贴切的机器学习算法
- 模型调参
- 模型状态分析
- 模型融合



OK，我们会顺着 1,2,3,4,5 这5个步骤来使用 sklearn 对应的那些函数，












## 主要内容

1. 数据处理
2. 特征工程
3. 模型选择
4. 寻找最佳超参数： 交叉验证
5. 模型分析与模型融合


### 简单的说明一下

特征工程：

在真实的问题上，你想提升效果，那么数据上的提升一定是大于模型的。如果数据非常好，你用一个简单的模型也能达到很好的效果。一些很高级的模型，很高级的模型融合的算法，调参等大概只占 30% 的时间。而数据特征对于最后的结果的决定性是非常高的，模型相对而言没有那么重要，实际工业中和比赛中也是这样。

超参数：

比如说比赛中大家基本上都是使用 GBDT，xgBoost，这些模型，然后使用的是一样的数据集。不同的地方一个是特征，一个是模型的超参数。比如说有多少棵树，比如说树的深度是多少，比如说boosting 的轮数到底是多少轮，这些超参数会直接影响你的结果。因为模型是在这些超参数形成的框架下进行训练的，模型最后的参数也是在这个框架下得到的。

模型融合：

参加比赛的话很少有一个模型会达到 top3 的，大部分都会使用 model resample。

Loss function：

比如说滴滴打车的一个比赛的，评价的标准和大家的标准就不一样，它是要评估每块地区对于车的需求量。第一名对于 loss function 进行了修正，它是使用的xgboost，它支持设置自己的cost function。因此你要知道你评判的目标是什么，然后才能针对这个目标进行优化。
