针对特殊的问题，特殊的场景， 的时候对工具进行修改，比如 修改 xgboost 的loss_function  来提高最后的结果。


Event Recommendation Engine Challenge


项目地址：https://www.kaggle.com/c/event-recommendation-engine-challenge

predict what events our users will be interested in based on user actions , event metadata,and demographic information.

这是一个把大的活动推荐给潜在的客户的比赛。

基于用户行为、活动描述、社交关系 来预测他们会对哪些活动感兴趣，

着三类信息不是一直都有的，比如阿里就没有社交活动的信息。



We (the competition hosts) are excited to sponsor the Event Recommendation Engine Challenge, which asks you to predict what events our users will be interested in based on events they’ve responded to in the past, user demographic information, and what events they’ve seen and clicked on in our app. The insights you discover from this data, and the algorithms the winners create, will allow us to improve our event recommendation algorithm, a core part of our applications and a key element in improving user experience.

This is the first competition launching under the Kaggle Startup Program!


可见，用户的停留时间和浏览轨迹也是可以作为特征进行处理的。



## 对于数据的描述：



[**Benchmark Code**](https://github.com/benhamner/EventRecommendationChallenge/tree/master/Benchmark)

There are six files in all: **train.csv**, **test.csv**, **users.csv**, **user_friends.csv**, **events.csv**, and **event_attendees.csv**.

**train.csv** has six columns:  **user, event**, **invited, timestamp, interested**, and **not_interested**.  **Test.csv** contains the same columns as train.csv, except for interested and not_interested. Each row corresponds to an event that was shown to a user in our application.  **event** is an id identifying an event in a our system.  **user** is an id representing a user in our system.  **invited** is a binary variable indicated whether the user has been invited to the event. **timestamp** is a ISO-8601 UTC time string representing the approximate time (+/- 2 hours) when the user saw the event in our application. **interested** is a binary variable indicating whether a user clicked on the "Interested" button for this event; it is 1 if the user clicked Interested and 0 if the user did not click the button.  Similarly,**not_interested** is a binary variable indicating whether a user clicked on the "Not Interested" button for this event; it is 1 if the user clicked the button and 0 if not.  It is possible that the user saw an event and clicked neither Interested nor Not Interested, and hence there are rows that contain 0,0 as values for **interested,not_interested**.

**users.csv** contains demographic data about our some of our users (including all of the users appearing in the train and test files), and it has the following columns: **user_id**, **locale**, **birthyear**, **gender**, **joinedAt**, **location**, and **timezone**. **user_id** is the id of the user in our system.  **locale** is a string representing the user's locale, which should be of the form *language*_*territory*. **birthyear** is a 4-digit integer representing the year when the user was born. **gender** is either male or female, depending on the user's gender.  **joinedAt** is an ISO-8601 UTC time string representing when the user first used our application.  **location** is a string representing the user's location (if known).  timezone is a signed integer representing the user's UTC offset (in minutes).

**user_friends.csv** contains social data about this user, and contains two columns:  user and friends.  **user** is the user's id in our system, and **friends** is a space-delimited list of the user's friends' ids.

**events.csv** contains data about events in our system, and has 110 columns.  The first nine columns are **event_id**, **user_id**, **start_time**,**city**, **state**, **zip**, **country**, **lat**, and **lng.**  **event_id** is the id of the event, and **user_id** is the id of the user who created the event.  **city**,**state**, **zip**, and **country** represent more details about the location of the venue (if known).  **lat** and **lng** are floats representing the latitude and longitude coordinates of the venue, rounded to three decimal places.  **start_time** is the ISO-8601 UTC time string representing when the event is scheduled to begin.  The last 101 columns require a bit more explanation; first, we determined the 100 most common word stems (obtained via Porter Stemming) occuring in the name or description of a large random subset of our events.  The last 101 columns are **count_1**, **count_2**, ..., **count_100**, **count_other**, where **count_N** is an integer representing the number of times the Nth most common word stem appears in the name or description of this event.  **count_other** is a count of the rest of the words whose stem wasn't one of the 100 most common stems.嗯，为了脱敏，只给了top100 个词的词频，也没有告诉词是什么。

**event_attendees.csv** contains information about which users attended various events, and has the following columns: **event_id**, **yes**,**maybe**, **invited,** and **no. event_id** identifies the event. **yes**, **maybe**, **invited**, and **no** are space-delimited lists of user id's representing users who indicated that they were going, maybe going, invited to, or not going to the event.



看到这么多种信息，有点麻爪，不知道要怎么处理，嗯，明确一下麻爪的地方：
- 怎么处理朋友这种信息？朋友的朋友呢？
- 怎么处理这种可以人与 event 的对应
- 怎么处理interested 和not_interested 这种信息
- 要怎么写，用干什么，pandas 可以吗？还是要用sql？




## 评估的方式


For each user in the test set, you are submitting a list of events. These events should be ordered from the ones in which you predict the user will be most interested to those in which the user will be least be interested.

The evaluation metric for this competition is **Mean Average Precision at 200** (the maximum number of events for any one user is 116, so 200 doesn't create a meaningful limit). You can find more information about this evaluation metric on the Kaggle wiki.

Sample submission files can be downloaded from the data page. Submission files should be formatted as follows:

- Have a header: "User,Events"
- Contain two columns
    - **User**: user ids in sorted order
    - **Events**: space-delimited list of recommended events, from those the user would be most-interested in to those the user would be least-interested in


**First couple lines of a sample submission:**

User,Events
1776192,2877501688 1024025121 4078218285 2972428928 3025444328 1823369186 2514143386
3044012,2529072432 1532377761 1390707377 1502284248 3072478280 1918771225
4236494,152418051 4203627753 2790605371 799782433 823015621 2352676247 110357109


在推荐这种业务场景中，我们给的是一个列表。比如淘宝中，会给你一列推荐品。这里就是会对每个人推荐一个 活动的 list，按照他感兴趣的程度排序。

嗯，小说推荐网站也应该做成这样。


实际上评估的方式很多是不一样的，有些是关注准确率的，有些关注推荐这个商品的收益，比如a 商品90%推荐，但是只卖5元，b 商品 50% 会买，但是价格 1000，因此，不同的场景，关注的评估标准也是不同的。要注意。

我们第二个案例的评估标准在 xgboost 里面是没有的，不能直接优化，要自己写 loss function 。

现在工业推荐系统中常用的模型是什么？现在推荐系统 base line 一般是 协同过滤（collaborative filtering） 或者是隐语义模型 lfm 。

什么实际问题会关心 recall？有一些信息分享的平台而言，我们希望我大部分的大部分的用户感兴趣的信息都会找回来。
<span style="color:red;">嗯，关于实际场景中一般会应用哪些评估标准还是要总结下的。</span>





### 问题简单分析

- 首先这是一个推荐的问题
- 我们有下面这样几类数据
    1. 用户的历史数据 => 对event是否感兴趣/是否参加
    2. 用户社交数据 => 朋友圈
    3. event相关的数据 => event相关的信息
- 简单思考
    1. 要把更多维度的信息纳入考量
    2. 协同过滤是基于 用户-event 历史交互数据
    3. 需要把社交数据 和 event相关信息 作为影响最后结果的因素纳入考量
- 对于label 与feature 来说：
    1. 视作分类模型， 每一个人 感兴趣/不感兴趣 是target， 其他影响结果的是feature
    2. 影响结果的feature包括由协同过滤产出的推荐度


数据的维度非常多，协同过滤就是两个用户的历史数据展现出来的偏好是不是接近，协同过滤是baseline 一定要用，但是在这个案例中是不够的。我们需要把更多的信息考量进来。

你可能会对你的朋友感兴趣的东西感兴趣，所以，如果你的几个朋友都去这个演唱会，你有可能也会去，

event 的描述信息这个文本，实际上你是看不到明文的，你只知道使用频率最高的一些词汇。

为什么要把 协同过滤产生的推荐度作为feature呢？

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180726/Ce0db85Jda.png?imageslim)

我们知道在推荐这个场景中，y 可以就是 是否感兴趣，或者感兴趣的程度，那么现在就是来看如何构建 x，

协同过滤可以判定用户与用户之间的相似度，根据他们在历史的 event 上面的 action 。那么相似度这个东西本身就可以判断他对某个 event 是否感兴趣，但是这样很明显没有充分使用比赛给我们的信息。


所以我们把协同过滤的推荐度放在预测模型的 x 里面。

协同过滤模型会面临数据稀疏和冷启动的问题，冷启动是所有的推荐算法都会面临的问题。

数据稀疏这块，mllib 实现的协同过滤是用 lfm做的，相比于传统的协同过滤，这种协同过滤对于稀疏的问题要好一些，

协同过滤是一个 baseline，一般电商刚开始做推荐系统的时候可能拿到协同过滤的结果就直接用了。


这个地方我们的信息没有完全用到，转成了一个分类的问题，但是我们希望这个分类的问题最后能给一个概率值。

分类的问题很多都可以做：LR，svm， gbdt，rf，CNN

sdgclassifier 是一批一批数据训练的，有点像 online


X3 朋友参加用户的频繁度。<span style="color:red;">这个感觉没有充分使用数据吧？</span>

x1 活动本身的信息，比如周杰伦的演唱会与普通的酒吧的演唱会之间热度还是差别很大的，有多少人对这个活动感兴趣，就是热度。

x2、x3 是由

x6 是否被邀请也是很重要的，比如可能会包机票什么的，
