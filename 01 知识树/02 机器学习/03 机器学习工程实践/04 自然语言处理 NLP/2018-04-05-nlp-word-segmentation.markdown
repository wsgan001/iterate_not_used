---
author: evo
comments: true
date: 2018-04-05 06:41:13+00:00
layout: post
link: http://106.15.37.116/2018/04/05/nlp-word-segmentation/
slug: nlp-word-segmentation
title: nlp 怎么进行分词
wordpress_id: 3348
categories:
- 随想与反思
tags:
- '@todo'
- '@want_to_know'
---

<!-- more -->

[mathjax]


# 缘由：


视频中讲到了，在中文中，如何让机器阅读一篇文章，然后列出分辨处的词汇？分词就是判断连续的几个字是不是一个词汇。比如”葡萄“。


# 要点：




## 怎么分辨出几个字连在一起是不是词汇？


某个字或几个字的出现的次数称为频数，如：\(Count(”小明“)\)。那么可以考虑从凝固程度和自由程度两方面判断连续的几个字是不是一个词，比如对于两个字A，B来说：

A="小"，B="明"，X=A+B="小明"

则：



 	
  * 凝固程度就是考虑：   P(A)P(B)  vs  P(X)

 	
  * 自由程度就是考虑：   信息熵H(A)、H(B) **怎么通过概率计算信息熵？**


凝固程度和自由程度缺一不可：

 	
  * 只考虑凝固程度，会照出“巧克“等一半的词。

 	
  * 只考虑自由程度，会将”走了一趟“，”吃了一顿“等的”了一“提取出来。




根据上面的原理，怎么做出一个可行的算法来对一段文本进行词语的提取？而且怎样才能降低这个算法的空间复杂度和时间复杂度？**需要自己动手做一下**

比如可能用到Trie树来存储这个频度，然后有向前统计和向后统计等等。而且虽然Trie树的时间复杂度与字数线性相关的，但是空间复杂度比较高，因此可能还会使用双数组Trie树。**什么是Trie树？什么是向前统计和向后统计？什么是双数组Trie树？这个在算法里面有，那边总结好之后，这边补充一下。而且要自己要手动实现下。**





**还需要补充，这个地方只是大概讲了一下。**




# COMMENT：


**后续补充一下，对于中文的分词，不知道实际是怎么做的？将实际的做法总结进来。**


# REF：





 	
  1. 七月在线 机器学习


