---
author: evo
comments: true
date: 2018-03-31 07:34:57+00:00
layout: post
link: http://106.15.37.116/2018/03/31/ai-convex-optimization-dual-problem-and-kkt-condition/
slug: ai-convex-optimization-dual-problem-and-kkt-condition
title:
wordpress_id: 2176
categories:
- 随想与反思
tags:
- '@todo'
- '@want_to_know'
---

<!-- more -->

[mathjax]


# REF：






  1. 七月在线 机器学习

********************************************************************************


# 缘由：


对对偶问题和KKT条件进行总结。






# 共轭函数 基本没怎么讲


这个概念不是这么的重要，主要跟对偶函数有点关联，因此提了下。


## 定义：


原函数：\(f:R^n\rightarrow R\)共轭函数定义：**为什么是从\(R^n\rightarrow R\)？而且\(y^T\)是什么意思？怎么计算的？**

\[f^*(y)=\underset{x\in dom \,f }{sup}(y^Tx-f(x)\]

如果把定义式的右端看作是关于y的函数，那么就是一个关于y的仿射函数Ax+b，它们逐点求上确界，得到的函数\(f^*(y)\)一定是凸函数。也就是说不管原来的f(x)是什么函数，它的共轭函数一定是一个凸函数。

之所以叫共轭函数的原因：凸函数的共轭函数的共轭函数是其本身。


## 对共轭函数的理解




![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180727/H1c3kE4cGa.png?imageslim)

例：求共轭函数


![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180727/Dik94DAG6G.png?imageslim)

Fenchel不等式


![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180727/GFEBhmb590.png?imageslim)

Fenchel不等式的应用


![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180727/76GhcB84hH.png?imageslim)








# 凸优化




## 优化问题的基本形式：


\[\begin{align*}minimize\;&f_0(x),x\in R^n\\subject\, to \;&f_i(x)\leq 0,i=1,\cdots ,m\\&h_i(x)=0,j=1,\cdots ,p\end{align*}\]

其中：




  * 优化变量：\(x\in R^n\)

  * 不等式约束：\(f_i(x)\leq 0\)

  * 等式约束：\h_j(x)=0

  * 无约束优化：m=p=0

  * 优化问题的域：\(D=\bigcap_{i=0}^m dom \,f_i \cap \bigcap_{j=1}^{p} dom\,h_i\) 答案不会出这个问题域。

  * 可行点（解）feasible：\(x\in D\) 且满足约束条件。可行的，不一定是最优的

  * 可行域（可行解）:所有可行点的集合

  * 最优化值：\(p^*=inf\{f_0(x)\mid f_i(x)\leq 0,i=1,\cdots ,m,h_j(x)=0,j=1,\cdots p\}\) 可行域里面肯定有一个最优的。**inf 指的是下确界，sup 指的是上确界。比如\(y=x^2\)的下确界是0。**

  * 最优化解：\(p^*=f_0(x^*)\)




## 局部最优问题


实践中中往往限定一个局部，来求局部最优问题。范数可以理解为一个范围。

\[\begin{align*}minimize\;&f_0(x),x\in R^n\\subject\, to \;&f_i(x)\leq 0,i=1,\cdots ,m\\&h_i(x)=0,j=1,\cdots ,p\\ &\left \|x-z\right\|_2\leq R,R>0\end{align*}\]


## 凸优化问题的基本形式


\[\begin{align*}minimize\;&f_0(x),x\in R^n\\subject\, to \;&f_i(x)\leq 0,i=1,\cdots ,m\\&h_i(x)=0,j=1,\cdots ,p\end{align*}\]


如果其中的 \(f_i(x)\) 为凸函数，\(h_j(x)\)为仿射函数。那么我们把这样的优化问题叫做凸优化问题。比如后面会遇到一个SVM的优化问题，可能就能化成这种凸优化的问题。**遇到之后补充一下。**


凸优化问题的重要性质：




  * 凸优化问题的可行域为凸集。

  * 凸优化问题的局部最优解记为全局最优解。**为什么？**




非凸优化问题的变形


\[\begin{align*}minimize\;&f_0(x)=x_1^2+x_2^2\\subject\, to \;&f_1(x)=\frac{x_1}{1+x_2^2}\leq 0\\&h_1(x)=(x_1+x_2)^2=0\end{align*}\]

等价于凸优化问题：

\[\begin{align*}minimize\;&f_0(x)=x_1^2+x_2^2\\subject\, to \;&\widetilde{f_1(x)}=x_1\leq 0\\&\widetilde{h_1(x)}=x_1+x_2=0\end{align*}\]












# 对偶问题


可以用对偶问题的凸性，对原问题进行估计


## 一般优化问题的Lagrange乘子法：


考虑\(\mathbb{R}^n\)上的优化问题：


### 优化问题：


\[\begin{align*}最小化&:f_0(x)\\不等式条件&:f_i(x)\leq 0,i=1,\cdots ,m\\等式条件&:h_i(x)=0,i=1,\cdots ,p\\定义域&:D=\bigcap_{i=0}^{m}domf_i\cap \bigcap_{i=1}^{p}domh_i\end{align*}\]

请注意定义域\(D\)指的是使得所有函数\(f_i,h_i\)有定义的区域，而可行域值得是定义域中满足不等条件与等式条件的那些点，本课中把这个优化问题称为原问题，优化点称为\(x^*\)，最优值为\(p^*\)。

**这个定义域是什么意思？里面的符号是什么意思？还有\(h_i(x)\)是什么？**

根据原函数与限制条件我们定义拉格朗日函数\(L(x,\lambda ,v):\mathbb{R}^{n+m+p}\rightarrow \mathbb{R}\)

可以写成这样的Lagrange函数：

\[L(x,\lambda,v)=f_0(x)=\sum_{i=1}{m}\lambda_if_i(x)+\sum_{j=1}{p}v_jh_j(x)\]

其中：\(\lambda\geq 0\)，\(v\in R\)。对固定的\(x\)，不管 \(f\) 和 \(h\) 是什么，Lagrange函数 \(L(x,\lambda,v)\) 可以看作为关于 \(\lambda\) 和 \(v\) 的仿射函数。

因为\(\lambda\) 和 \(v\) 叫做乘子，因此这样的方法叫做 Lagrange 乘子法。


由于\(\lambda\geq 0\)，\(v\in R\)，而且\(f\leq 0\)，\(g=0\)，因此\(L(x,\lambda,v)<f_0(x)\)。





## Lagrange对偶函数(dual function)


那么对于这个Lagrange函数，我们可以对x在D域上的所有的值取下界。那么这个时候的x就被消掉了。这个时候我们就得到了对偶函数 \(g(\lambda,v)\)：

\[g(\lambda,v)=\underset{x\in D}{inf} L(x,\lambda,v)=\underset{x\in D}{inf}(f_0(x)+\sum_{i=1}^{m}\lambda_if_i(x)+\sum_{i=1}^{p}v_ih_i(x))\]

如果没有下确界，定义：\(g(\lambda,v)=-\infty\)。

注意，之前的原函数可行域比较复杂，而现在的这个地方的\(x\)的定义域虽然还是D了，但是可行域没有了限制了，所以，这就是我们可以求出拉格朗日函数的下确界却无法直接求出原来的函数的最小值的原因。

那么，由于\(L(x,\lambda,v)<f_0(x)\)，而 \(g(\lambda,v)\) 又是下确界，因此下确界的值一定比\(f(x)\)要小，所以，对\(\forall \lambda>0,\forall v\)，若原优化问题有最优值\(p^*\)，则：\(g(\lambda,v)\leq p^*\)。所以Lagrange对偶函数的函数值是小于等于我们函数的最优值的。

而且，由于求得是下确界，而 \(\lambda\) ， \(v\) 是一些线，因此这些线的下确界就是一个凹函数，因此，Lagrange对偶函数为凹函数。

左侧为原函数，右侧为对偶函数


![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180727/hJgHDJ7d1g.png?imageslim)

上面这个左图种，\(f_0(x)\)就是这个黑色的函数，最下面的这个虚线就是一个约束函数\(f_1(x)<0\)，然后这里没有仿射函数，也就是说m=1，p=0。

此时的Lagrange函数为：\(g(\lambda,v)=f_0(x)+\lambda_1f_1(x)\)，左侧图的上面的几条曲线就是这个g取不同的 \(\lambda\)的时候对应的曲线。其中黑色的那个就是(\lambda=0\) 的时候即f_0。

根据\(f_1(x)\)的约束函数，也就是\(f_1(x)<0\)，得到x的范围为 -0.46~0.46

那么当\(\lambda=0.1\)的时候，就得到了最贴近黑色线的那个棕色线。对于这个曲线来说，我总可以求它的最小值，那么\(\lambda\)取不同的值就对应了上面的不同的线，我们都进行各个线的最小值，这些最小值就是\(\lambda\)取不同的值的时候的下确界。**为什么这个最小值不是限定在-0.46~0.46 范围内的？不是要满足\(f_1(x)\)的限制条件吗？**

这样我们就可以画出右边的图，即不同的\(\lambda\)的时候的Lagrange函数的下确界的值，也即Lagrange对偶函数的值。右边的图上面的虚线是：在-0.46~0.46的范围内的f_0的最小值1.53，**？为什么这个时候把边界对应的黑点的值作为原优化问题的最优值？如果是这样的话，那么前面也应该考虑x的范围吧？**

对于有些时候，是可以取等号的，即原函数的最小值等于对偶函数的极大值。如果有这样的好的条件的话，你会发现虽然f_0也不是凸的也不是凹的，f_i 和g_i也都是数学性质比较差的，但是我们求完对偶函数的时候，我们研究\lambda和v对应的g函数的时候，这个函数是一个凹函数，也就是说，负的-g(x)是一个凸函数，对于这个凸函数来说，它的极大值我们就可以把它一定意义上表示原函数的极小值，因为我们想求原函数的极小值，但是求不出来。我们就可以求对偶函数的极大值。而这个对偶函数的极大值，有些时候就是原函数的极小值，有些时候不是，但是也不错，起码是它的一个下界，这个下界往往跟原值相差不大。这个是我们研究凸优化的一个重要的思路。

即原函数求极小值，转化为Lagrange函数，再转化为Lagrange函数的对偶函数，再求对偶函数的极大值。

往往不直接用原函数求极小值，因为它是带约束的，**但是Lagrange对偶函数其实是一个无约束的函数。住要求\(\lambda>0\)，这个约束条件其实是很弱的。因此可以求对偶函数的极大值。由于对偶函数是一个凹函数，可以给他加一个负号变成凸函数，然后就可以求它的极小值。**

高等数学中一般忽略不等式约束，只讲等式约束，那个时候对偶函数的极值正好能对上原函数的极值。


## Lagrange对偶函数极大值小于原函数极小值


鞍点解释：

为表达方便，假设没有等式约束，只考虑不等式约束，结论可方便的扩展到等式约束。




  * 假设x_0不可行，即存在某些i，使得\(f_i(x)>0\)，则选择\(\lambda_i\rightarrow \infty\)，对于其他乘子，\(\lambda_j=0,j\neq i\)

  * 假设\(x_0\)可行，则有\(f_i(x)\leq 0,(i=1,2,\cdots, m)\)，选择\(\lambda_i=0,i=1,2,\cdots ,m\)


因此有：

\[\underset{\lambda\geq 0}{sup}L(x,\lambda)=\underset{\lambda\geq 0}{sup}(f_0(x)+\sum_{i=1}^{m}\lambda_if_i(x))=\{\begin{matrix}f_0(x)&f_i(x)\leq 0,i=1,2,\cdots ,m\\ \infty & otherwise\end{matrix}\]


而原问题是：\(\underset{x}{inf}\,f_0(x)\)


从而，原问题的本质为：\(\underset{x}{inf}\,\underset{\lambda\geq 0}{sup}L(x,\lambda)\)

而对偶问题，是求对偶函数的最大值，即：\(\underset{\lambda\geq 0}{sup}\,\underset{x}{inf}L(x,\lambda)\)

而：

\[\underset{\lambda\geq 0}{sup} \,\underset{x}{inf}L(x,\lambda)\leq \underset{x}{inf}\,\underset{\lambda\geq 0}{sup}L(x,\lambda)\]

接下来，证明：\(\underset{x}{max}\,\underset{y}{min}f(x,y)\leq \underset{y}{min}\,\underset{x}{max}f(x,y)\)

对于任意的 \((x,y)\in dom\, f\)：

\[\begin{align*}f(x,y)\leq \underset{x}{max}f(x,y)&\Rightarrow \underset{y}{min}f(x,y)\leq \underset{y}{min}\,\underset{x}{max}f(x,y)\\ &\Rightarrow  \underset{x}{max}\,\underset{y}{min}f(x,y)\leq \underset{y}{min}\,\underset{x}{max}f(x,y)\end{align*}\]

上面的第二步推理之所以成立，是因为右边是一个定值，而左边是一个关于x的函数，而函数始终是小于定值的，那么这个函数的极大值也是小于定值的。


##  对偶问题一般形式：


根据对偶函数，定义对偶问题的一般形式：

\[\begin{align*}最大化&:g(\lambda,v)\\不等条件&:\lambda_i\geq 0,i=1,\cdots ,m\end{align*}\]

我们把对偶问题的最大值称为：\((\lambda^*,v^*)\)，相应的最大值称为\(d^*\)，这里面的对偶函数\(g\)定义域为\(domg=\{(\lambda,v):g(\lambda,v)>-\infty \}\)。在\(g\)的定义域总满足\(\lambda_i\geq 0\)的那些\((\lambda ,v)\)全体，叫做对偶可行域，也就是对偶问题的可行域。


## 对偶函数与原函数的关系：对偶性：


根据对偶函数的性质我们已经知道在对偶可行域中，\(g(\lambda,v)\)总是不大于\(p^*\)，所以有：

弱对偶性：

\[d^*\leq p^*\]

若对偶性总是对的，相对而言的强对偶性是指一部分优化问题来说，有更好的结论

强对偶性：

\[d^*=p^*\]

强对偶性不总成立。








# 强对偶条件


第一个强对偶性的条件, 几乎所有的凸优化问题都满足强对偶性.

Slater 条件

对于一个凸优化问题：

\[\begin{align*}最小化&:f_0(x)\\不等式条件&:f_i(x)\leq 0,i=1,\cdots ,m\\等式条件&:h_i(x)=0,i=1,\cdots ,p\end{align*}\]

如果存在一个可行域中的点\(x\)使得\(f_i(x)<0,i=1,\cdots ,m\)。那么这个凸优化问题就满足强对偶条件。**为什么？**

若要对偶函数的最大值即为原问题的最小值，考察需要满足的条件：

这个求法就是根据定义求Lagrange函数的下确界。


![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180727/DdciAhJicB.png?imageslim)




##




##




##




# 凸优化问题求解  (KKT) 条件


Karush-Kuhn-Tucker


## 如果强对偶性满足的话，这些最优化点应该满足何种条件？


我们来看一下，如果强对偶性满足的话，这些最优化点应该满足何种条件？这一部分中我们假定所有的函数都是可微函数。

如果 \(x^*,(\lambda^*,v^*)\)分别是原问题与对偶问题的最优解，那么首先这些点应该满足可行域条件：




  * \(f_i(x^*)\leq 0\)

  * \(h_i(x^*)=0\)

  * \(\lambda_i^*\geq 0\)


而且我们已经知道


![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180727/LILHBj3Dkj.png?imageslim)

对于上面这个式子的解释：




  * 第一个小于等于号的解释：随便取一个 x ，肯定是大于等于 g 的，因为 g 是下确界。

  * 第二个小于等于号的解释：由于 \(\lambda\) 大于等于 0，\(f(x)\) 是小于等于 0 的，因此成立。


所以，根据这个式子，无论\(\lambda\) 和\(v\)取什么值都小于等于\(p^*\)

于是\(d^*=p^*\)意味着上述不等式全部是等式。


## 那么我们可以总结出这些条件：




![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180727/8fKgL30jFl.png?imageslim)

我们总结出KKT条件如下：




  * 前三个比较简单，就是可行域的那些不等式

  * 第四个条件是从上面的第二个小于等于 得出的。

  * 第五个条件是从上面的第一个小于等于得出的，因为小于等于变成等于，所以相当于\(x^*\)是那个拉格朗日函数的极值点，所以对x求偏导是0。


这五个条件加在一起就是KKT条件。


# 怎么使用这些条件使用：


对于凸优化问题，KKT条件是\(x^*,(\lambda^*,v^*)\)分别作为原问题和对偶问题的最优解的充分必要条件。

对于非凸优化问题，KKT条件仅仅只必要而非充分。

应用举例：

支持向量机最简单形式：


![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180727/FlfaL32GmJ.png?imageslim)



![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180727/Cjg49I9AF5.png?imageslim)

**看来这个对偶问题与SVM的关系还是很密切的，要深挖一下。**






# 附：线性方程的最小二乘问题  这个是重点 没讲




![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180727/2Ka8mh56b7.png?imageslim)




### 求L的对偶函数




![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180727/FhA5cF64bm.png?imageslim)




### 求对偶函数的极大值




![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180727/Bg44EgAe3d.png?imageslim)




### 极小值点




![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180727/FkBLaA8EKl.png?imageslim)


















## 对偶问题：拉格朗日对偶函数













# COMMENT：


**要重新整理一下，笔记还是有些乱的**

参考资料

非常清晰完整的经典教材：凸优化，Stephen Boyd, Lieven Vandenberghe 各章节之间比较独立的，所以从那一章开始看都行。

作业  教材：凸优化 (英文版页码与题号)




  * p60:2.32.10,2.12,2.16,2.23,2.26;

  * p113:3.1,3.2,3.12,3.21,3.36,3.39;

  * p189:4.2,4.8,4.10,4.21

  * p273:5.1,5.4,5.11,5.225.24
