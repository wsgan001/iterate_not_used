# O(n)

TODO

- 他是从 O(n) 来讲起的。不过完全没看出从这个 O(n) 来引出极限有什么特殊的意义？而且，这种引出太生硬了把？毕竟 O(n) 与极限好像没有特别大的联系？
- 而且，这个 O(n) 的阶的概念，在机器学习中会用到吗？在哪里有用到？






从 O(n) 和 o(n) 的定义讲起，将直觉转化为数学定义，引出极限的概念。


我们使用 O 这个记号的时候，我们通常这样：

f(x)=O(g(x))

这个说的是 f(x) 和 g(x) 的量级差不多，O 即使英文的 order，是多项式的阶的意思。但是，这里把多项式的阶推广了。


$\exists X_0,M$ ，使得 $X\geq X_0$ 时，$f(x)\leq Mg(x)$

就是 当 x足够大的时候，有一个g(x)的常熟倍，可以把 f(x) 限制住。

比如 $2x^2=O(x^2)$ ，这里只要取 M=2 x_0 任意
$x^2+x+1=O(x^2)$ ，这里我们如果 M取 2，那么x_0就不能像上面这个是任意了。下面这个 x_0 比如说我们可以取10 ，


那么 o 的意思是什么？

$\forall \Sigma $ $\exists X_0$ ，使得  $X\geq X_0$ 时，$f(x)\leq \Sigmag(x)$

就是 X 足够大的时候，f(x) 可以任意比 g(x) 的常数倍要小

也就是： X=o(X^2)  比如 把 $\Sigma=10^{-2}$ ，那我只要把 x_0=100，那我 $x\geq 100$ 的时候，显然有 ： X\leq \Sigma X^2


我们再看一个复杂的例子：

x^2+x+1=o(x^3)

也就是说，x^3 只要足够大，那么我可以把左边的以任意的方式限制住。

也就是说， $\Sigma=10^{-2}$ ，然后我的 x_0 仍然可以取 x_0=1000 ，然后这样的话右边的 x^3 是大于等于 $\Sigma 1000x^2$

左边的 阶 是 2，右边的阶是3，o 的意思是 2 是严格比 3 小的。


然后，上面这个

从 O(n) 和 o(n) 我们可以看出它描述的是说 O(g(x)) 是 x 趋近于无穷时候的状态。这个趋近就涉及到了我们之后要讲到的极限。



## REF

- [SIGAI 人工智能的数学基础](http://sigai.cn/index.php?r=front)
