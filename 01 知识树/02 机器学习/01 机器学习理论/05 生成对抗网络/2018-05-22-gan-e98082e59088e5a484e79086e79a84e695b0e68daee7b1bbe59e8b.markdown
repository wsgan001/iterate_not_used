---
author: evo
comments: true
date: 2018-05-22 07:05:01+00:00
layout: post
link: http://106.15.37.116/2018/05/22/gan-%e9%80%82%e5%90%88%e5%a4%84%e7%90%86%e7%9a%84%e6%95%b0%e6%8d%ae%e7%b1%bb%e5%9e%8b/
slug: gan-%e9%80%82%e5%90%88%e5%a4%84%e7%90%86%e7%9a%84%e6%95%b0%e6%8d%ae%e7%b1%bb%e5%9e%8b
title: GAN 适合处理的数据类型
wordpress_id: 6261
categories:
- 人工智能学习
tags:
- GAN
---

<!-- more -->

[mathjax]

**注：非原创，只是按照自己的思路做了整合，修改。推荐直接看 ORIGINAL 中所列的原文。**


# ORIGINAL





 	
  1. aaa




# TODO





 	
  * **补齐对于所有的数据类型的处理**

 	
  * **之前我看到过一篇说GAN是怎么用到NLP上面的，是我看错了吗？不是说不适合处理文本数据吗？要确认下。**

 	
  * **要拆开，对哪种数据是怎么处理的，都要清楚，实现。**





* * *





# INTRODUCTION





 	
  * aaa





# **为什么 GAN 不适合处理文本数据？**


1. 文本数据相比较图片数据来说是离散的，因为对于文本来说，通常需要将一个词映射为一个高维的向量，最终预测的输出是一个one-hot向量，假设softmax的输出是（0.2， 0.3， 0.1，0.2，0.15，0.05）那么变为onehot是（0，1，0，0，0，0），如果softmax输出是（0.2， 0.25， 0.2， 0.1，0.15，0.1 ），one-hot仍然是（0， 1， 0， 0， 0， 0），所以对于生成器来说，G输出了不同的结果但是D给出了同样的判别结果，并不能将梯度更新信息很好的传递到G中去，所以D最终输出的判别没有意义。

2. 另外就是GAN的损失函数是JS散度，JS散度不适合衡量不想交分布之间的距离。

（WGAN虽然使用wassertein距离代替了JS散度，但是在生成文本上能力还是有限，GAN在生成文本上的应用有seq-GAN,和强化学习结合的产物）





















* * *





# COMMENT



