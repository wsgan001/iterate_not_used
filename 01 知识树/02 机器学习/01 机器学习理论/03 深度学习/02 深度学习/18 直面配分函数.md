---
author: evo
comments: true
date: 2018-05-27 06:20:51+00:00
layout: post
link: http://106.15.37.116/2018/05/27/dl-%e7%9b%b4%e9%9d%a2%e9%85%8d%e5%88%86%e5%87%bd%e6%95%b0/
slug: dl-%e7%9b%b4%e9%9d%a2%e9%85%8d%e5%88%86%e5%87%bd%e6%95%b0
title: 
wordpress_id: 6843
categories:
- 机器学习相关理论
tags:
- Deep Learning
---

<!-- more -->

[mathjax]

**注：非原创，只是按照自己的思路做了整合，修改。推荐直接看 ORIGINAL 中所列的原文。**


# ORIGINAL






  1. 《深度学习》Ian Goodfellow




# TODO






  * aaa





* * *





# INTRODUCTION






  * aaa












第十八章 直面配分函数
在第16.2.2节中，我们看到许多概率模型(通常是无向图模型)由一个未归一 化的概率分布p(x,0)定义。我们必须通过除以配分函数Z(0)来归一化p，以获得 一个有效的概率分布：

p(x； = Z^yp(X;0). (18-1)

配分函数是未归一化概率所有状态的积分(对于连续变量)或求和(对于离散变量) j p(x)dx (18.2)

或者

5Zp(x) - (18.3)

x
对于很多有趣的模型而言，以上积分或求和难以计算。

正如我们将在第二十章看到的，有些深度学习模型被设计成具有一个易于处理 的归一化常数，或被设计成能够在不涉及计算p(x)的情况下使用。然而，其他一些 模型会直接面对难以计算的配分函数的挑战。在本章中，我们会介绍用于训练和评 估那些具有难以处理的配分函数的模型的技术。

18.1 对数似然梯度
通过最大似然学习无向模型特别困难的原因在于配分函数依赖于参数。对数似

然相对于参数的梯度具有一项对应于配分函数的梯度：

▽0 logp(x; d) = V0 logp(x; d) - V0 log Z(0). (18.4)

516

这是机器学习中非常著名的正相(positive phase )和负相(negative phase )的 分解。

对于大多数感兴趣的无向模型而言，负相是困难的。没有潜变量或潜变量之间 很少相互作用的模型通常会有一个易于计算的正相。 RBM 的隐藏单元在给定可见单 元的情况下彼此条件独立，是一个典型的具有简单正相和困难负相的模型。正相计

算困难，潜变量之间具有复杂相互作用的情况将主要在第十九章中讨论。本章主要

探讨负相计算中的难点。

让我们进一步分析 log Z 的梯度：

Ve log Z

(18.5)

=Ve Z =Z WRP(x)

Z

R^p(x)

Z .

(18.6)

(18.7)

(18.8)

对于保证所有的 x 都有 p(x) >0 的模型，我们可以用 exp(logp(x)) 代替 p(x)： Ex exp(logp(x))

(18.9)

Ex exp(logp(x))V0 logp(x)

(18.10)

(18.11)

Z

=Ex p(x)Velog p(x)

= Z

=^3 P(x)Ve log p(x) (18.12)

x

=Ex_p(x)Ve logp(x). (18.13)

上述推导对离散的 x 进行求和，对连续的 x 进行积分也可以得到类似结果。在

连续版本的推导中，使用在积分符号内取微分的莱布尼兹法则可以得到等式

Ve

p( x) dx =

J" Vep(x)dx.

(18.14)

该等式只适用于P和VW(x)上的一些特定规范条件。在测度论术语中，这些条件 是：(1)对每一个0而言，未归一化分布P必须是x的勒贝格可积函数。(2)对于所 有的0和几乎所有X，梯度p(x)必须存在。(3)对于所有的0和几乎所有的X， 必须存在一个可积函数R(x)使得maxi |是p(x)| < R(x)。幸运的是，大多数感兴趣

的机器学习模型都具有这些性质。

等式

log Z = Ex^p(x)Ve logp(x) (18.15)

是使用各种蒙特卡罗方法近似最大化(具有难计算配分函数模型的)似然的基础。

蒙特卡罗方法为学习无向模型提供了直观的框架，我们能够在其中考虑正相和负

相。在正相中，我们增大从数据中采样得到的logp(x)。在负相中，我们通过降低从 模型分布中采样的 log p(x) 来降低配分函数。

在深度学习文献中，经常会看到用能量函数(式(16.7))来参数化logp。在这 种情况下，正相可以解释为压低训练样本的能量，负相可以解释为提高模型抽出的 样本的能量，如图18.1所示。

18.2 随机最大似然和对比散度
实现式(18.15)的一个朴素方法是，每次需要计算梯度时，磨合随机初始化的一

组马尔可夫链。当使用随机梯度下降进行学习时，这意味着马尔可夫链必须在每次

梯度步骤中磨合。这种方法引导下的训练过程如算法18.1所示。内循环中磨合马尔

可夫链的计算代价过高，导致这个过程在实际中是不可行的，但是这个过程是其他

更加实际的近似算法的基础。

我们可以将最大化似然的MCMC方法视为在两种力之间平衡，一种力拉高数据

出现时的模型分布，一种拉低模型采样出现时的模型分布。图18.1展示了这个过程。

这两种力分别对应最大化logp和最小化log Z。对于负相会有一些近似方法。这些

近似都可以被理解为使负相更容易计算，但是也可能将其推向错误的位置。

因为负相涉及到从模型分布中抽样，所以我们可以认为它在找模型信任度很高

的点。因为负相减少了这些点的概率，它们一般被认为代表了模型不正确的信念。在 文献中，它们经常被称为‘‘幻觉''或‘‘幻想粒子''。事实上，负相已经被作为人类和其 他动物做梦的一种可能解释 (Crick and Mitchison, 1983)。这个想法是说，大脑维持

着世界的概率模型，并且在醒着经历真实事件时会遵循logp的梯度，在睡觉时会遵 循logp的负梯度最小化logZ，其经历的样本采样自当前的模型。这个视角解释了 具有正相和负相的大多数算法，但是它还没有被神经科学实验证明是正确的。在机

算法18.1 —种朴素的MCMC算法，使用梯度上升最大化具有难以计算配分函数的 对数似然。_

设步长e为一个小正数。

设吉布斯步数k大到足以允许磨合。在小图像集上训练一个RBM大致设为100。

while 不收敛 do

从训练集中采包含m个样本｛x⑴,...，x(m)｝的小批量。

g m £™i ▽g log p(x(i);0).

初始化m个样本｛x(1),...,x(m)｝为随机值(例如，从均匀或正态分布中采，或 大致与模型边缘分布匹配的分布)。

for i = 1 to k do for j = 1 to m do

x(j) gibbs_update(x(j)).

end for end for

g g - m £™i ▽g log p(x⑴；0).

0 0 + eg.

end while

器学习模型中，通常有必要同时使用正相和负相，而不是按不同时间阶段分为清醒 和 REM 睡眠时期。正如我们将在第19.5节中看到的，一些其他机器学习算法出于 其他原因从模型分布中采样，这些算法也能提供睡觉做梦的解释。

这样理解学习正相和负相的作用之后，我们设计了一个比算法18.1计算代价更 低的替代算法。简单的MCMC算法的计算成本主要来自每一步的随机初始化磨合马 尔可夫链。一个自然的解决方法是初始化马尔可夫链为一个非常接近模型分布的分 布，从而大大减少磨合步骤。

对比散度(CD，或者是具有k个Gibbs步骤的CD-k)算法在每个步骤中初始 化马尔可夫链为采样自数据分布中的样本 (Hinton, 2000, 2010)，如算法18.2所示。 从数据分布中获取样本是计算代价最小的，因为它们已经在数据集中了。初始时，数 据分布并不接近模型分布，因此负相不是非常准确。幸运的是，正相仍然可以准确 地增加数据的模型概率。进行正相阶段一段时间之后，模型分布会更接近于数据分 布，并且负相开始变得准确。

当然，CD仍然是真实负相的一个近似。CD未能定性地实现真实负相的主要原

图 18.1: 算法18.1角度的 “正相'' 和 “负相''。 (左) 在正相中，我们从数据分布中采样，然后推高 它们未归一化的概率。这意味着概率越高的数据点未归一化的概率被推高得越多。 (右) 在负相中 我们从模型分布中采样，然后压低它们未归一化的概率。这与正相的倾向相反，给未归一化的概 率处处添加了一个大常数。当数据分布和模型分布相等时，正相推高数据点和负相压低数据点的 机会相等。此时，不再有任何的梯度(期望上说)，训练也必须停止。

因是，它不能抑制远离真实训练样本的高概率区域。这些区域在模型上具有高概率， 但是在数据生成区域上具有低概率，被称为虚假模态(spurious modes )。图18.2解 释了这种现象发生的原因。基本上，除非 k 非常大，模型分布中远离数据分布的峰 值不会被使用训练数据初始化的马尔可夫链访问到。

Carreira-Perpinan and Hinton (2005)实验上证明CD估计偏向于RBM和完全 可见的玻尔兹曼机，因为它会收敛到与最大似然估计不同的点。他们认为，由于偏 差较小，CD可以作为一种计算代价低的方式来初始化模型，之后可以通过计算代价 高的MCMC方法进行精调。Bengio and Delalleau (2009)表明，CD可以被理解为去 掉了正确MCMC梯度更新中的最小项，这解释了偏差的由来。

在训练诸如RBM的浅层网络时CD是很有用的。反过来，这些可以堆叠起来初 始化更深的模型，如DBN或DBM。但是CD并不直接有助于训练更深的模型。这是

因为在给定可见单元样本的情况下，很难获得隐藏单元的样本。由于隐藏单元不包

括在数据中，所以使用训练点初始化无法解决这个问题。即使我们使用数据初始化

可见单元，我们仍然需要磨合在给定这些可见单元的隐藏单元条件分布上采样的马

尔可夫链。

CD算法可以被理解为惩罚某类模型，这类模型的马尔可夫链会快速改变来自数

算法18.2对比散度算法，使用梯度上升作为优化过程。

设步长e为一个小正数。

设吉布斯步数 k 大到足以让从 pdata 初始化并从 p(x; 0) 采样的马尔可夫链混合 在小图像集上训练一个 RBM 大致设为 1-20。 while 不收敛 do

从训练集中采包含m个样本｛x(1),...,x(m)｝的小批量。 g m £™1 ve logp(x(i); 0).

for i = 1 to m do

x⑴x⑴.

end for

for i = 1 to k do for j = 1 to m do

x(j) gibbs_update(x(j)).

end for end for

g g - m £；=1 Ve logp(X⑴;0).

0 0 + eg.

end while

据的输人。这意味着使用CD训练从某种程度上说类似于训练自编码器。即使CD估

计比一些其他训练方法具有更大偏差，但是它有助于预训练之后会堆叠起来的浅层

模型。这是因为堆栈中最早的模型会受激励复制更多的信息到其潜变量，使其可用

于随后的模型。这应该更多地被认为是CD训练中经常可利用的副产品，而不是主要 的设计优势。

Sutskever and Tieleman (2010)表明，CD的更新方向不是任何函数的梯度。这 使得CD可能存在永久循环的情况，但在实践中这并不是一个严重的问题。

另一个解决CD中许多问题的不同策略是，在每个梯度步骤中初始化马尔可夫 链为先前梯度步骤的状态值。这个方法首先被应用数学和统计学社群发现，命名 为随机最大似然(SML) (Younes, 1998)，后来又在深度学习社群中以名称持续性对 比散度(PCD，或者每个更新中具有k个Gibbs步骤的PCD-k)独立地被重新发 现 (Tieleman, 2008)。具体可以参考算法18.3。这种方法的基本思想是，只要随机梯 度算法得到的步长很小，那么前一步骤的模型将类似于当前步骤的模型。因此，来

图 18.2: 一个虚假模态。说明对比散度(算法18.2)的负相为何无法抑制虚假模态的例子。一个虚 假模态指的是一个在模型分布中出现数据分布中却不存在的模式。由于对比散度从数据点中初始 化它的马尔可夫链然后仅仅运行了几步马尔可夫链，不太可能到达模型中离数据点较远的模式。这 意味着从模型中采样时，我们有时候会得到一些与数据并不相似的样本。这也意味着由于在这些 模式上浪费了一些概率质量，模型很难把较高的概率质量集中于正确的模式上。出于可视化的目 的，这个图使用了某种程度上说更加简单的距离的概念——在 R 的数轴上虚假模态与正确的模式 有很大的距离。这对应着基于局部移动 R 上的单个变量 x 的马尔可夫链。对于大部分深度概率模 型来说，马尔可夫链是基于Gibbs采样的，并且对于单个变量产生非局部的移动但是无法同时移 动所有的变量。对于这些问题来说，考虑编辑距离比欧式距离通常更好。然而，高维空间的编辑距 离很难在二维空间作图展示。

自先前模型分布的样本将非常接近来自当前模型分布的客观样本，用这些样本初始

化的马尔可夫链将不需要花费很多时间来完成混合。

因为每个马尔可夫链在整个学习过程中不断更新，而不是在每个梯度步骤中重 新开始，马尔可夫链可以自由探索很远，以找到模型的所有峰值。因此，SML比CD更 不容易形成具有虚假模态的模型。此外，因为可以存储所有采样变量的状态，无论 是可见的还是潜在的，SML为隐藏单元和可见单元都提供了初始值。CD只能为可 见单元提供初始化，因此深度模型需要进行磨合步骤。SML能够高效地训练深度模 型。Marlin et al. (2010)将SML与本章中提出的许多其他标准方法进行比较。他们 发现，SML在RBM上得到了最佳的测试集对数似然，并且如果RBM的隐藏单元被 用作SVM分类器的特征，那么SML会得到最好的分类精度。

在k太小或e太大时，随机梯度算法移动模型的速率比马尔可夫链在迭代步 中混合更快，此时SML容易变得不准确。不幸的是，这些值的容许范围高度依赖

算法18.3随机最大似然/持续性对比散度算法，使用梯度上升作为优化过程。 设步长e为一个小正数。

设吉布斯步数 k 大到足以让从 p(x; 0+eg) 采样的马尔可夫链磨合(从采自 p(x; 0) 的样本开始)。在小图像集上训练一个RBM大致设为1,对于更复杂的模型如深度 玻尔兹曼机可能要设为 5 到 50。

初始化 m 个样本 {x(1), .. . , x(m)} 为随机值(例如，从均匀或正态分布中采，或大

致与模型边缘分布匹配的分布)。 while 不收敛 do

从训练集中采包含m个样本{x(1),...,x(m)}的小批量。 g m £™i ve logp(x⑷;0).

for i = 1 to k do for j = 1 to m do

x(j) gibbs_update(x(j)).

end for end for

g g - m £™i ve log p(x⑴;0).

0 0 + eg.

end while

于具体问题。现在还没有方法能够正式地测试马尔可夫链是否能够在迭代步骤之间 成功混合。主观地，如果对于 Gibbs 步骤数目而言学习率太大的话，那么梯度步骤 中负相采样的方差会比不同马尔可夫链中负相采样的方差更大。例如，一个 MNIST 模型在一个步骤中只采样得到了 7。然后学习过程将会极大降低 7对应的峰值，在 下一个步骤中，模型可能会只采样得到 9。

从使用SML训练的模型中评估采样必须非常小心。在模型训练完之后，有必要 从一个随机起点初始化的新马尔可夫链抽取样本。用于训练的连续负相链中的样本 受到了模型最近几个版本的影响，会使模型看起来具有比其实际更大的容量。

Berglund and Raiko (2013)进行了实验来检验由CD和SML进行梯度估计带来 的偏差和方差。结果证明CD比基于精确采样的估计具有更低的方差。而SML有更 高的方差。CD方差低的原因是，其在正相和负相中使用了相同的训练点。如果从不 同的训练点来初始化负相，那么方差会比基于精确采样的估计的方差更大。

所有基于MCMC从模型中抽取样本的方法在原则上几乎可以与MCMC的任何 变体一起使用。这意味着诸如SML这样的技术可以使用第十七章中描述的任何增 强MCMC的技术(例如并行回火)来加以改进(Desjardins et al., 2010; Cho et al., 2010b)。

一种在学习期间加速混合的方法是，不改变蒙特卡罗采样技术，而是改变模型的 参数化和代价函数。 快速持续性对比散度( fast persistent contrastive divergence)， 或者 FPCD (Tieleman and Hinton, 2009) 使用如下表达式去替换传统模型的参数 0

0=0(slow)+0(fast). (18.16)

现在的参数是以前的两倍多，将其逐个相加以定义原始模型的参数。快速复制参数

可以使用更大的学习率来训练，从而使其快速响应学习的负相，并促使马尔可夫链探

索新的区域。这能够使马尔可夫链快速混合，尽管这种效应只会发生在学习期间快

速权重可以自由改变的时候。通常，在短时间地将快速权重设为大值并保持足够长

时间，使马尔可夫链改变峰值之后，我们会对快速权重使用显著的权重衰减，促使

它们收敛到较小的值。

本节介绍的基于MCMC的方法的一个关键优点是它们提供了 log Z梯度的估 计，因此我们可以从本质上将问题分解为logp和logZ两块。然后我们可以使用任 何其他的方法来处理logp(x)，只需将我们的负相梯度加到其他方法的梯度中。特别 地，这意味着正相可以使用那些仅提供P下限的方法。然而，本章介绍处理log Z的 大多数其他方法都和基于边界的正相方法是不兼容的。

18.3 伪似然
蒙特卡罗近似配分函数及其梯度需要直接处理配分函数。有些其他方法通过训

练不需要计算配分函数的模型来绕开这个问题。这些方法大多数都基于以下观察

无向概率模型中很容易计算概率的比率。这是因为配分函数同时出现在比率的分子

和分母中，互相抵消：

p(x) = 1 p(x) = p(x) p(y) Z1 p(y) p(y)

(18.17)

伪似然正是基于条件概率可以采用这种基于比率的形式，因此可以在没有配分 函数的情况下进行计算。假设我们将x分为a，b和c，其中a包含我们想要的条

件分布的变量， b 包含我们想要条件化的变量， c 包含除此之外的变量： (| b) = P(a, b) = p(a, b) = p(a, b)

(18.18)

則卜 3bT= Ea,c P(a, b, c) = Ea,c P(a, b, c)-

以上计算需要边缘化a，假设a和c包含的变量并不多，那么这将是非常高效的操 作。在极端情况下，a可以是单个变量，c可以为空，那么该计算仅需要估计与单 个随机变量值一样多的 p。

不幸的是，为了计算对数似然，我们需要边缘化很多变量。如果总共有 n 个变 量，那么我们必须边缘化 n-1 个变量。根据概率的链式法则，我们有

logp(x) = logp(xi) + logP(X2 | Xi) +-----+ logp(xn | Xhn-1). (18.19)

在这种情况下，我们已经使a尽可能小，但是c可以大到X2:n。如果我们简单地将c移 到b中以减少计算代价，那么会发生什么呢？这便产生了伪似然(pseudolikelihood ) (Besag, 1975)目标函数，给定所有其他特征，预测特征々的值：

n

log p(xi | a-i). (18.20)

i=1

如果每个随机变量有k个不同的值，那么计算p需要k X n次估计，而计算配 分函数需要 kn 次估计。

这看起来似乎是一个没有道理的策略，但可以证明最大化伪似然的估计是渐近 一致的 (Mase, 1995)。当然，在数据集不趋近于大采样极限的情况下，伪似然可能表 现出与最大似然估计不同的结果。

我们可以使用广义伪似然估计(generalized pseudolikelihood estimator )来权 衡计算复杂度和最大似然表现的偏差 (Huang and Ogata, 2002)。广义伪似然估计使 用m个不同的集合S(i)，i = 1,...,m作为变量的指标出现在条件棒的左侧。在 m = 1和S⑴=1,..., n的极端情况下，广义伪似然估计会变为对数似然。在m = n 和 S(i) = {i} 的极端情况下，广义伪似然会恢复为伪似然。广义伪似然估计目标函 数如下所示

m

logp(xS(i) | x-S(i)). (18.21)

i=1

基于伪似然的方法的性能在很大程度上取决于模型是如何使用的。对于完全联 合分布 p(x) 模型的任务(例如密度估计和采样)，伪似然通常效果不好。对于在训 练期间只需要使用条件分布的任务而言，它的效果比最大似然更好，例如填充少量 的缺失值。如果数据具有规则结构，使得 S 索引集可以被设计为表现最重要的相关 性质，同时略去相关性可忽略的变量，那么广义伪似然策略将会非常有效。例如，在

自然图像中，空间中相隔很远的像素也具有弱相关性，因此广义伪似然可以应用于

每个 S 集是小的局部空间窗口的情况。

伪似然估计的一个弱点是它不能与仅在 p(x) 上提供下界的其他近似一起使用

例如第十九章中介绍的变分推断。这是因为 p 出现在了分母中。分母的下界仅提供 了整个表达式的上界，然而最大化上界没有什么意义。这使得我们难以将伪似然方

法应用于诸如深度玻尔兹曼机的深度模型，因为变分方法是近似边缘化互相作用的

多层隐藏变量的主要方法之一。尽管如此，伪似然仍然可以用在深度学习中，它可

以用于单层模型，或使用不基于下界的近似推断方法的深度模型中。

伪似然比SML在每个梯度步骤中的计算代价要大得多，这是由于其对所有条 件进行显式计算。但是，如果每个样本只计算一个随机选择的条件，那么广义伪 似然和类似标准仍然可以很好地运行，从而使计算代价降低到和SML差不多的程 度 (Goodfellow et al., 2013d)。

虽然伪似然估计没有显式地最小化log Z，但是我们仍然认为它具有类似负相的 效果。每个条件分布的分母会使得学习算法降低所有仅具有一个变量不同于训练样

本的状态的概率。

读者可以参考 Marlin and de Freitas (2011) 了解伪似然渐近效率的理论分析，。

18.4 得分匹配和比率匹配
得分匹配(Hyvarinen, 2005b)提供了另一种训练模型而不需要估计Z或其导数 的一致性方法。对数密度关于参数的导数VUogp(x)，被称为其得分(score)，得分 匹配这个名称正是来自这样的术语。得分匹配采用的策略是，最小化模型对数密度 和数据对数密度关于输入的导数之间的平方差期望：

L(x, 0) = 1 ^Vx log Pmodel(x;0) - Vx log Pdata(X)||2, (18.22)

J(0) = 2EPdata(X)L(X, 0), (18.23)

0* = min J(0). (18.24)

该目标函数避免了微分配分函数Z带来的难题，因为Z不是x的函数，所以 ▽xZ = 0。最初，得分匹配似乎有一个新的困难：计算数据分布的得分需要知道生成 训练数据的真实分布Pdata。幸运的是，最小化1(^,0)的期望等价于最小化下式的

期望

/ d2 1

I dX^ logpmodel(x; 0) + 2

log pmodel(x; 0)

(18.25)

L(x, 0)=

j=1

其中 n 是 x 的维度。

因为得分匹配需要关于X的导数，所以它不适用于具有离散数据的模型，但是 模型中的潜变量可以是离散的。

类似于伪似然，得分匹配只有在我们能够直接估计logP(x)及其导数的时候才 有效。它与对logp(x)仅提供下界的方法不兼容，因为得分匹配需要logp(x)的导 数和二阶导数，而下限不能传达关于导数的任何信息。这意味着得分匹配不能应用 于隐藏单元之间具有复杂相互作用的模型估计，例如稀疏编码模型或深度玻尔兹曼 机。虽然得分匹配可以用于预训练较大模型的第一个隐藏层，但是它没有被用于预 训练较大模型的较深层网络。这可能是因为这些模型的隐藏层通常包含一些离散变 量。

虽然得分匹配没有明确显示具有负相信息，但是它可以被视为使用特定类型马 尔可夫链的对比散度的变种(Hyvarinen, 2007a)。在这种情况下，马尔可夫链并没有 采用Gibbs采样，而是采用一种由梯度引导局部更新的不同方法。当局部更新的大 小接近于零时，得分匹配等价于具有这种马尔可夫链的对比散度。

Lyu (2009) 将得分匹配推广到离散的情况(但是推导有误，后由 Marlin et al. (2010) 修正)。 Marlin et al. (2010) 发现， 广义得分匹配( generalized score match-ing，GSM )在许多样本观测概率为0的高维离散空间中不起作用。

一种更成功地将得分匹配的基本想法扩展到离散数据的方法是比率匹配( ratio matching) (Hyvarinen, 2007b)。比率匹配特别适用于二值数据。比率匹配最小化以 下目标函数在样本上的均值：

L(咧(X，0) = E C, PmL(X；./| - (18.26)

j=l \ 1 + Pmodelf(X),j；0) /

其中f(xj)返回j处位值取反的X。比率匹配使用了与伪似然估计相同的策略来绕 开配分函数：配分函数会在两个概率的比率中抵消掉。 Marlin et al. (2010) 发现，训

练模型给测试集图像去噪时，比率匹配的效果要优于SML、伪似然和GSM。

类似于伪似然估计，比率匹配对每个数据点都需要n个p的估计，因此每次更 新的计算代价大约比 SML 的计算代价高出 n 倍。

与伪似然估计一样，我们可以认为比率匹配减小了所有只有一个变量不同于训 练样本的状态的概率。由于比率匹配特别适用于二值数据，这意味着在与数据的汉 明距离为 1 内的所有状态上，比率匹配都是有效的。

比率匹配还可以作为处理高维稀疏数据(例如词计数向量)的基础。这类稀疏 数据对基于MCMC的方法提出了挑战，因为以密集格式表示数据是非常消耗计算资 源的，而只有在模型学会表示数据分布的稀疏性之后，MCMC采样才会产生稀疏值。 Dauphin and Bengio (2013) 设计了比率匹配的无偏随机近似来解决这个问题。该近 似只估计随机选择的目标子集，不需要模型生成完整的样本。

读者可以参考 Marlin and de Freitas (2011) 了解比率匹配渐近效率的理论分

析，。

18.5 去噪得分匹配
某些情况下，我们希望拟合以下分布来正则化得分匹配

psmoothed(a) = pdata(y)q(a | y)dy (18.27)

而不是拟合真实分布Pdata。分布q(a | y)是一个损坏过程，通常在形成a的过程中

会向 y 中添加少量噪声。

去噪得分匹配非常有用，因为在实践中，通常我们不能获取真实的Pdata，而只 能得到其样本确定的经验分布。给定足够容量，任何一致估计都会使 pmodel 成为一 组以训练点为中心的Dirac分布。考虑在第5.4.5节介绍的渐近一致性上的损失，通 过q来平滑有助于缓解这个问题。Kingma and LeCun (2010b)介绍了平滑分布q为 正态分布噪声的正则化得分匹配。

回顾第14.5.1节，有一些自编码器训练算法等价于得分匹配或去噪得分匹配。因

此，这些自编码器训练算法也是解决配分函数问题的一种方式。

18.6 噪声对比估计
具有难求解的配分函数的大多数模型估计都没有估计配分函数。SML和CD只 估计对数配分函数的梯度，而不是估计配分函数本身。得分匹配和伪似然避免了和配 分函数相关的计算。

噪声对比估计( noise-contrastive estimation， NCE)(Gutmann and Hyvari-nen, 2010) 采取了一种不同的策略。在这种方法中，模型估计的概率分布被明确表示 为

logpmodel(x) =logpmodel(x;0)+c, (18.28)

其中 c 是 -logZ(0) 的近似。噪声对比估计过程将 c 视为另一参数，使用相同的算 法同时估计0和C，而不是仅仅估计0，。因此，所得到的logPmodel(X)可能并不完 全对应有效的概率分布，但随着C估计的改进，它将变得越来越接近有效值\

这种方法不可能使用最大似然作为估计的标准。最大似然标准可以设置c为任 意大的值，而不是设置 c 以创建一个有效的概率分布。

NCE 将估计 p(x) 的无监督学习问题转化为学习一个概率二元分类器，其中一 个类别对应模型生成的数据。该监督学习问题中的最大似然估计定义了原始问题的 渐近一致估计。

具体地说，我们引人第二个分布，噪声分布(noise distribution ) Pnoise(x)。噪 声分布应该易于估计和从中采样。我们现在可以构造一个联合x和新二值变量y的 模型。在新的联合模型中，我们指定

Pjoint(y =1) = 2， (18.29)

pjoint(x | y = 1) = pmodel(x), (18.30)

和

pjoint(x | y = 0) = pnoise(x). (18.31)

换言之，y是一个决定我们从模型还是从噪声分布中生成x的开关变量。

我们可以在训练数据上构造一个类似的联合模型。在这种情况下，开关变量决定 是从数据还是从噪声分布中抽取X。正式地，Ptrain(y = 1) = 1，Ptrain(x | y = 1)= pdata(x)，和 pt rain (x| y=0)=pn oise(x) 。

现在我们可以应用标淮的最大似然学习拟合Pjoint到Ptrain的监督学习问题：

0,c = arg maxEx,y_ptrain logPjoint(y | X). (18.32)

Q,c

分布 pjoint 本质上是将逻辑回归模型应用于模型和噪声分布之间的对数概率之

差：

pjoint(y = 1 | X)

pmodel(X)

pmodel (X) , pn oise(X)

1

1 _i pnoise(x)

pmodel (x)

i+(exp (log

pnoise(X)

-V og Pmodel (X)J

CT(log Pmodel (X) - log Pn oise (X)).

(18.33)

(18.34)

(18.35)

(18.36)

(18.37)

因此，只要log Pmodel易于反向传播，并且如上所述，Pnoise应易于估计(以便 评估Pjoint )和采样(以生成训练数据)，那么NCE就易于使用。

NCE能够非常成功地应用于随机变量较少的问题，但即使随机变量有很多可以 取的值时，它也很有效。例如，它已经成功地应用于给定单词上下文建模单词的条 件分布 (Mnih and Kavukcuoglu, 2013)。虽然单词可以采样自一个很大的词汇表，但 是只能采样一个单词。

当NCE应用于具有许多随机变量的问题时，其效率会变得较低。当逻辑回归分 类器发现某个变量的取值不大可能时，它会拒绝这个噪声样本。这意味着在 Pmodel 学习了基本的边缘统计之后，学习进程会大大减慢。想象一个使用非结构化高斯噪 声作为Pnoise来学习面部图像的模型。如果Pmodel学会了眼睛，就算没有学习任何 其他面部特征，比如嘴，它也会拒绝几乎所有的非结构化噪声样本。

噪声分布 Pnoise 必须是易于估计和采样的约束可能是过于严格的限制。当 Pnoise 比较简单时，大多数采样可能与数据有着明显不同，而不会迫使Pmodel进行显著改 进。

类似于得分匹配和伪似然，如果P只有下界，那么NCE不会有效。这样的下界 能够用于构建Pjoint (y = 1 | X)的下界，但是它只能用于构建Pjoint(y = 0 | X)(出现

在一半的NCE对象中)的上界。同样地，Pnoise的下界也没有用，因为它只提供了 pjoint(y = 1 | x) 的上界。

在每个梯度步骤之前，模型分布被复制来定义新的噪声分布时，NCE定义了一 个被称为自对比估计(self-contrastive estimation )的过程，其梯度期望等价于最大 似然的梯度期望(Goodfellow, 2014)。特殊情况的NCE (噪声采样由模型生成)表 明最大似然可以被解释为使模型不断学习以将现实与自身发展的信念区分的过程 而噪声对比估计通过让模型区分现实和固定的基准(噪声模型)，我们降低了计算成 本。

在训练样本和生成样本(使用模型能量函数定义分类器)之间进行分类以得 到模型的梯度的方法，已经在更早的时候以各种形式提出来(Welling et al., 2003b; Bengio, 2009)。

噪声对比估计是基于良好生成模型应该能够区分数据和噪声的想法。一个密切

相关的想法是，良好的生成模型能够生成分类器无法将其与数据区分的样本。这个

想法诞生了生成式对抗网络(第20.10.4节)。

1

NCE也适用于具有易于处理的，不需要引人额外参数c的配分函数的问题。它已经是最令人感兴趣的，估计具

有复杂配分函数模型的方法。









18.7 估计配分函数
尽管本章中的大部分内容都在避免计算与无向图模型相关的难以计算的配分函 数Z(0)，但在本节中我们将会讨论几种直接估计配分函数的方法。

估计配分函数可能会很重要，当我们希望计算数据的归一化似然时，我们会需

要它。在评估模型，监控训练性能，和比较模型时，这通常是很重要的。

例如，假设我们有两个模型：概率分布为pa(x; 0a) = ZAPa(x; 0a)的模型Ma 和概率分布为PB(x;0B) = ZBPb(x;0b)的模型Mb。比较模型的常用方法是评估 和比较两个模型分配给独立同分布测试数据集的似然。假设测试集含 m 个样本 {a ⑴，…，a(m)}。如果 njA (x(i)； 0 a) > Hi Pb (x(i)； 0b )，或等价地，如果

logpA(x(i); 0A) - logpB(x(i);0B) > 0, (18.38)

ii

那么我们说 MA 是一个比 MB 更好的模型(或者，至少可以说，它在测试集上是 一个更好的模型)，这是指它有一个更好的测试对数似然。不幸的是，测试这个条件 是否成立需要知道配分函数。式(18.38)看起来需要估计模型分配给每个点的对数概 率，因而需要估计配分函数。我们可以通过将式(18.38)重新转化为另一种形式来简 化情况，在该形式中我们只需要知道两个模型的配分函数的比率：

Elog pA(x(i)； 0A)- Elog pB(x(i)； 0b ) = E (log pA(X(i); 0B)))- mlog Z^ -

(18.39)

因此，我们可以在不知道任一模型的配分函数，而只知道它们比率的情况下，判断 模型 MA 是否比模型 MB 更优。正如我们将很快看到的，在两个模型相似的情况 下，我们可以使用重要采样来估计比率。

然而，如果我们想要计算测试数据在 MA 或 MB 上的真实概率，我们需要计 算配分函数的真实值。如果我们知道两个配分函数的比率，r = Z(g，并且我们知 道两者中一个的实际值，比如说Z(0A)，那么我们可以计算另一个的值：

Z (0B )= rZ (0a) = Z (0A). (18.40)

一种估计配分函数的简单方法是使用蒙特卡罗方法，例如简单重要采样。以下 用连续变量积分来表示该方法，也可以替换积分为求和，很容易将其应用到离散变 量的情况。我们使用提议分布Po(x)=去Po(x)，其在配分函数Zo和未归一化分布 p0(x) 上易于采样和估计。

Z1

p1( x) dx p0(x)

p0(x)

p1( x) dx

Z0

P0(X) p^ dX

s.t. : x⑷〜p0

(18.41)

(18.42)

(18.43)

(18.44)

在最后一行，我们使用蒙特卡罗估计，使用从po(x)中抽取的采样计算积分么， 然后用未归一化的 p1 和提议分布 p0 的比率对每个采样加权。

这种方法使得我们可以估计配分函数之间的比率：

k=1

Pl (X(k))

Po (x(k))

s.t. : x(k)

po.

(18.45)

然后该值可以直接比较式(18.39)中的两个模型

如果分布P0接近P1，那么式（18.44）能够有效地估计配分函数（Minka, 2005）。 不幸的是，大多数时候 P1 都很复杂（通常是多峰值的），并且定义在高维空间中。 很难拢到一个易求解的Po，既能易于评估，又能充分接近Pi以保持高质量的近似。 如果 P0 和 P1 不接近，那么 P0 的大多数采样将在 P1 中具有较低的概率，从而在 式（18.44）的求和中产生（相对的）可忽略的贡献。

如果求和中只有少数几个具有显著权重的样本，那么将会由于高方差而导致估 计的效果很差。这可以通过估计么的方差来定量地理解：

Va

(k)

Po(X(k))

"O'

(18.46)

当重要性权重pog（k））存在显著偏差时，上式的值是最大的。

我们现在关注两个解决高维空间复杂分布上估计配分函数的方法：退火重要采 样和桥式采样。两者都始于上面介绍的简单重要采样方法，并且都试图通过引入缩 小 P0 和 P1 之间差距的中间分布，来解决 P0 远离 P1 的问题。

18.7.1 退火重要采样
在Dkl（Po||pi）很大的情况下（即Po和Pi之间几乎没有重叠），一种称为退火 重要采样（annealed importance sampling， AIS ）的方法试图通过引人中间分 布来缩小这种差距（Jarzynski, 1997; Neal, 2001）。考虑分布序列Pn。，…，Pnn，其中 0 = no < ni < ••• < nn-i < nn = 1，分布序列中的第一个和最后一个分别是po和

Pi 。

这种方法使我们能够估计定义在高维空间多峰分布（例如训练 RBM 时定义 的分布）上的配分函数。我们从一个已知配分函数的简单模型（例如，权重为零 的RBM）开始，估计两个模型配分函数之间的比率。该比率的估计基于许多个相似 分布的比率估计，例如在零和学习到的权重之间插值一组权重不同的RBM。

现在我们可以将比率Zo写作

Z1 Z Z

Z0 =

Z Z Zn

(18.47)

(18.48)

(18.49)

如果对于所有的0 S j S n - 1,分布p%和p%+i足够接近，那么我们能够使用简 单的重要采样来估计每个因子j，然后使用这些得到f的估计。

Znj Zo

这些中间分布是从哪里来的呢？正如最先的提议分布P0是一种设计选择，分布 序列Pm ...Pnn-i也是如此。也就是说，它们可以被特别设计为特定的问题领域。中 间分布的一个通用和流行选择是使用目标分布 P1 的加权几何平均，起始分布(其配 分函数是已知的)为 P0：

Pnj P?P1—j-

(18.50)

为了从这些中间分布中采样，我们定义了一组马尔可夫链转移函数a)， 定义了给定a转移到a/的条件概率分布。转移算子Tj(a/ | a)定义如下，保持 Pnj (a)不变：

Pnj (a) = Pnj a’)da’.

(18.51)

这些转移可以被构造为任何马尔可夫链蒙特卡罗方法(例如， Metropolis-Hastings， Gibbs)，包括涉及多次遍历所有随机变量或其他迭代的方法。

然后，AIS采样方法从po开始生成样本，并使用转移算子从中间分布顺序地生 成采样，直到我们得到目标分布 P1 的采样：

• 对于 k = 1 . . . K -采样 a(k)〜po(x)

-采样 a(k)〜Ta (x(k) | a(k))

-采样 a(n-i Tn- (x(n-i i a(n-2)

-采样 a(fcn)〜Tnn-I(x(kn) 1 必-1)

• 结束

对于采样 k ，通过连接式(18.49)给出的中间分布之间的重要性权重，我们可以

导出目标重要性权重：

w(k) = pni (41)) pn2 (4k)) pi(4k))

(18.52)

po(xk)) pni(xk)) pnn-i(xnn))

为了避免诸如上溢的数值问题，最佳方法可能是通过加法或减法计算log w(k)，而不 是通过概率乘法和除法计算 w(k)。

利用由此定义的采样过程和式(18.52)中给出的重要性权重，配分函数的比率估

计如下所示：

Z1

Z0

K

k=1

(18.53)

为了验证该过程定义的重要采样方案是否有效， 我们可以展示 (Neal, 2001) AIS 过程对应着扩展状态空间上的简单重要采样， 其中数据点采样自乘 积空间［XmXnn-i, xi ］。为此，我们将扩展空间上的分布定义为

P(xni，…，Xnn-i, xi) (18.54)

=pi (Xi)Tnn-i (xnn-i 1 Xi)Tnn-2 (xnn-2 1 xnn-i)…Tni (xni 1 xn2)， (18-55)

其中 Ta 是由 Ta 定义的转移算子的逆(应用贝叶斯规则)：

Ta(X’ I X) = pa((X)) Ta(x | X) = pa((X)) Ta(x | X’). (18.56)

将以上代入到式(18.55)给出的扩展状态空间上的联合分布中，我们得到：

P(Xm，…，Xnn-i, xi) (18.57)

n-2

=Pi(xi))-1 HTnn-i(xi | Xu) ft '(x*i I、) (18.58)

n-2

=pPi XX、Tnn—1 (xi 1 xnn—1 )pni (xni) II Tn (x%+i 1 XnJ. (18.59)

pnn—i i) i_i pni(a:ni+i)

通过上面给定的采样方案，现在我们可以从扩展样本上的联合提议分布 q 上生成采 样，联合分布如下

q(Xni, Xnn—i，Xi) = po(Xni )Tni (Xn2 1 Xni)... Tnn—1 (Xi 1 Xnn—1 )• (18.60)

式(18.59)给出了扩展空间上的联合分布。将q(xmXnn-i, xi)作为扩展状态空间 上的提议分布(我们会从中抽样)，重要性权重如下

(k) = p(xni，…，xnn-i, xi) = pi(xi )) pn2 (xn2) pni (Xn1) (1Q61)

W —q(xni，...，xnn-i，xi)- 心厂•P^^W

这些权重和AIS上的权重相同。因此，我们可以将AIS解释为应用于扩展状态上的 简单重要采样，其有效性直接来源于重要采样的有效性。

退火重要采样首先由Jarzynski (1997)发现，然后由Neal (2001)再次独立发现。 目前它是估计无向概率模型的配分函数的最常用方法。其原因可能与一篇有影响力 的论文 (Salakhutdinov and Murray, 2008) 有关，该论文并没有讨论该方法相对于其 他方法的优点，而是介绍了将其应用于估计受限玻尔兹曼机和深度信念网络的配分 函数。

关于AIS估计性质(例如，方差和效率)的讨论，请参看Neal (2001)。

18.7.2 桥式采样
类似于AIS，桥式采样(Bennett, 1976)是另一种处理重要采样缺点的方法。并 非将一系列中间分布连接在一起，桥式采样依赖于单个分布P，(被称为桥)，在已 知配分函数的分布Po和分布Pi (我们试图估计其配分函数Zi)之间插值。

桥式采样估计比率Zi/Zo: Po和艮之间重要性权重期望与Pi和艮之间重要 性权重的比率，

P±X^/£ Pl^- (18.62)

Zo Po(xo))/ Pi(x(i ))

如果仔细选择桥式采样P,，使其与Po和Pi都有很大重合的话，那么桥式采样能够 允许两个分布(或更正式地，Dkl(Po||pi))之间有较大差距(相对标准重要采样而

言)。

可以表明，最优的桥式采样是p,opt)(X)« rp0g)+(X)，其中r = Zi/Zo。这似乎 是一个不可行的解决方案，因为它似乎需要我们估计数值Zi/Zo。然而，可以从粗 糙的r开始估计，然后使用得到的桥式采样逐步迭代以改进估计(Neal, 2005)。也就 是说，我们会迭代地重新估计比率，并使用每次迭代更新r的值。

链接重要采样AIS和桥式采样各有优点。如果DKL(PollPi)不太大(由于P0和P1 足够接近)的话，那么桥式采样能比AIS更高效地估计配分函数比率。然而，如果 对于单个分布p,而言，两个分布相距太远难以桥接差距，那么AIS至少可以使用许 多潜在中间分布来跨越Po和Pi之间的差距。Neal (2005)展示链接重要采样方法如 何利用桥式采样的优点，桥接AIS中使用的中间分布，并且显著改进了整个配分函 数的估计。

在训练期间估计配分函数虽然AIS已经被认为是用于估计许多无向模型配分函 数的标准方法，但是它在计算上代价很高，以致其在训练期间仍然不很实用。研究 者探索了一些在训练过程中估计配分函数的替代方法。

使用桥式采样、短链AIS和并行回火的组合，Desjardins et al. (2011)设计了一 种在训练过程中追踪RBM配分函数的方法。该策略的基础是，在并行回火方法操作 的每个温度下，RBM配分函数的独立估计会一直保持。作者将相邻链(来自并行回 火)的配分函数比率的桥式采样估计和跨越时间的AIS估计组合起来，提出一个在 每次迭代学习时估计配分函数的(且方差较小的)方法。

本章中描述的工具提供了许多不同的方法，以解决难处理的配分函数问题，但

是在训练和使用生成模型时，可能会存在一些其他问题。其中最重要的是我们接下

来会遇到的难以推断的问题。







* * *





# COMMENT



