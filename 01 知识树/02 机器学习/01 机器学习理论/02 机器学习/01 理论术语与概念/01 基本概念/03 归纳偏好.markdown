---
author: evo
comments: true
date: 2018-05-23 09:45:33+00:00
layout: post
link: http://106.15.37.116/2018/05/23/ml-%e5%bd%92%e7%ba%b3%e5%81%8f%e5%a5%bd/
slug: ml-%e5%bd%92%e7%ba%b3%e5%81%8f%e5%a5%bd
title: 
wordpress_id: 6321
categories:
- 人工智能学习
tags:
- Machine Learning
---

<!-- more -->

[mathjax]

**注：非原创，只是按照自己的思路做了整合，修改。推荐直接看 ORIGINAL 中所列的原文。**


# ORIGINAL






  1. 《机器学习》周志华




# TODO






  * **这个一定要进行切分，说实话，这样写的这么长的一段很难让人彻底明确那些是重点，因为左一句右一句。**

  * **而且，统一用这个西瓜例子，有好处，也有坏处，就是讲的时候要带入太多东西。**

  * **为什么别的书上好像都没有看到过讲归纳偏好的呢？这个到底最关键的是什么呢？要搜集一下，整理一下。**

  * **而且，为什么在开始的时候讲归纳偏好？关于模型的好坏的对比应该放在模型的开始讲吧？**





* * *





# INTRODUCTION






  * aaa







# 归纳偏好


我们知道，通过学习得到的模型实际上是对应着假设空间中的某一个假设：


![](http://106.15.37.116/wp-content/uploads/2018/05/img_5b0529741c2d1.png)


但是，看着上面的图，我们就有一个疑问了：

比如说：对于（色泽=青绿; 根蒂=蜷缩；敲声=沉闷）这个新的瓜，如果我们采用的是 “好瓜 ↔ （色泽=*） ∧ （根蒂=蜷缩）∧（敲声=*）”，那么将会把新瓜判断为好瓜，但是如果我们采用的是另外两个假设，那么判断的结果就不是好瓜。

也就是说：这三个与在训练集上一致的假设，在面临新样本的时候，却有可能会产生不同的输出。

那么，我们应该采用哪一个模型（或假设）呢？

实际上，如果只是根据之前的训练样本，由于这些假设在训练集上是一致的，因此我们是判断不出上面的三个假设哪一个是 “更好” 的。

那么怎么办呢？我们必须要产生一个模型啊。

OK，这个时候，学习算法本身的 “偏好” 就会起起作用：**什么是学习算法本身的偏好？**

例如：**没明白这个例子？**




  * 如果我们的算法喜欢 “尽可能特殊” 的模型，则它会选择 “ 好瓜 ↔ （色泽=*）∧（根蒂=蜷缩）∧（敲声=浊响）”。（尽可能特殊即 “适用情形尽可能少”）

  * 如果我们的算法喜欢 “尽可能一般” 的模型，并且由于某种原因它更 “相信” 根蒂，则它会选择 “好瓜↔ （色泽=*） ∧ （根蒂=蜷缩）∧（敲声=*）。（尽可能一 般即 “适用情形尽可能多”）


注意：这里的的对 “根蒂” 还是对 “敲声” 更重视，虽然看起来是和 “特征选择” （feature selection）有关的，但是实际上并不是。我们的特征选择是基于对训练样本的分析进行的，而这里我们之所以对 “根蒂” 更加重视，是因为基于某种领域知识。关于特征选择方面的内容 参见第11章。**嗯，这里的信赖是基于某种领域知识的，而不是特征选择。**

机器学习算法在学习过程中对某种类型假设的偏好，称为“归纳偏好”（inductive bias）， 或简称为 “偏好”。**归纳偏好。为什么有归纳两个字？**

实际上任何一个有效的机器学习算法必有其归纳偏好，否则的话它就没有办法产生一个确定的学习结果。比如说：如果没有偏好，那么我们的西瓜学习算法产生的模型每次在进行预测时随机抽选训练集上的等效假设，那么我们对一个新瓜会时而判断它是好的、时而判断它是不好的，这样的学习结果显然是没有意义的。**真的没有意义吗？**

归纳偏好的作用在下图这个回归学习图示中可能更加直观：


![](http://106.15.37.116/wp-content/uploads/2018/05/img_5b052e054b0b1.png)


这里的每个训练样本是图中的一个点 \(x,y\) ，要学得一个与训练集一致的模型，相当于找到一 条穿过所有训练样本点的曲线。显然，对有限个样本点组成的训练集，是存在着很多条曲线可以穿过这些店的。

因此，我们的学习算法必须有某种偏好，才能产出它认为 “正确” 的模型。

比如：如果算法认为相似的样本应有相似的输出（例如，在各种属性上都很相像的西瓜，成熟程度应该比较接近），那么对应的学习算法可能偏好上图中比较 “平滑” 的曲线 A 而不是比较 “崎岖” 的曲线 B 。

实际上，归纳偏好可看作学习算法自身在一个可能很庞大的假设空间中对假设进行选择的启发式或 “价值观”。

OK，那么，有没有一般性的原则来引导算法确立 “正确的” 偏好呢？而且什么是正确的偏好？

还是有的： “奥卡姆剃刀”（Occam’s razor）就是一种常用的、自然科学 研究中最基本的原则，即 “若有多个假设与观察一致，则选最简单的那个”。如果采用这个原则，并且假设我们认为 “更平滑” 意味着 “更简单” （例如曲线 A 更易于描述，其方程式是 \(y=-x^2+6x+1\) ，而曲线B则要复杂得多），则在 上图中我们会自然地偏好 “平滑” 的曲线A。**还有什么原则吗？类似这样的？而且，我们怎么知道我们认为的更平滑是真的更平滑？这个奥卡姆剃刀原则真的有用吗？这种偏好简单的东西是真的正确的吗？**

然而，奥卡姆剃刀并不是唯一可行的原则。 例如古希腊哲学家伊壁坞鲁(公元前341年一前270年)提出的 "多释原则" (principle of multiple explanations)，主张保留与经验观察一致的所有假设，这与集成
学习 (ensemble learning)方面的研究更加吻合。**还有吗？这个在集成学习的时候再总结一下。**

退一步说，即便假定我们是奥卡姆剃刀的铁杆拥趸，也需注意到，奥卡姆剃刀本身存在着不同的诠释，使用奥卡姆剃刀原则并不平凡。

例如：




  * 假设1:好瓜（色泽=*） ∧（根蒂=蜷缩）∧ （敲声=浊响）

  * 假设2:好瓜（色泽=*）∧ （根蒂=蜷缩）∧ （敲声=*）


这两个假设，哪一个更为 “简单” 呢？这个问题就并不 简单，需借助其他机制才能解决。**什么机制？熵吗？**

事实上，归纳偏好对应了学习算法本身所做出的关于 “什么样的模型更好” 的假设。

在具体的现实问题中，这个假设是否成立，即算法的归纳偏好是否与问题本身匹配，大多数时候直接决定了算法能否取得好的性能。**嗯，是的但是我们怎么算法的归纳偏好与问题本身是否匹配呢？**



让我们再回头看看上图，我们假设：




  * 学习算法 \(\pounds_a\) 基于某种归纳偏好产生了对应于曲线 A 的模型

  * 学习算法 \(\pounds_b\) 基于另一种归纳偏好产生了对应于曲线 B 的模型


OK，那么基于前面讨论的平滑曲线的某种 “描述简单性”，我们满杯信心地期待算方法 \(\pounds_a\) 比 \(\pounds_b\) 更好。

确实，对于上图 (a) 来说，可以很明显的看出，与 B 相比， A 与测试样本更加一致，也就是说：A 的泛化能力的确比 B 强。


![](http://106.15.37.116/wp-content/uploads/2018/05/img_5b0530e41a884.png)


但是，且慢！

虽然我们希望并相信比更好，但会不会出现上图 (b) 的情况呢？

事实上，这种情况是完全有可能出现的。也就是说，对于一个学习算法 \(\pounds_a\) ，如果它在某 些问题上比学习算法 \(\pounds_b\) 好，那么则必然存在着另外一些问题，在那些问题上， \(\pounds_b\) 要比 \(\pounds_a\) 好。有趣的是，这个结论对于任何算法均是成立的，哪怕是把本书后面将要介绍的一些聪明算法作为 \(\pounds_a\) 而将 “随机胡猜” 这样的笨拙算法作为 \(\pounds_b\) 。

哈哈，惊讶吗？让我们看看下面这个简短的讨论：

这里只用到一些非常基 础的数学知识，只准备读 第1章且有“数学恐惧” 的读者可以跳过这个部分 而不会影响理解，只需相 信，上面这个看起来“匪 夷所思”的结论确实是成 立的.

为了简单起见，假设样本空间 \(\mathcal{X}\) 和假设空间 \(\mathcal{H}\) 都是离散的。我们：




  * 令 \(P(h|X,\pounds_a)\) 代表算法 \(\pounds_a\) 基于训练数据 \(X\) 产生假设 \(h\) 的概率

  * 令 \(f\) 代表我们希望学习的真实目标函数。


那么 \(\pounds_a\) 的 “训练集外误差”，即 \(\pounds_a\) 在训练集之外的所有样本上的误差为：


![](http://106.15.37.116/wp-content/uploads/2018/05/img_5b0533006578e.png)


其中 \(\mathbb{I}(\cdot )\) 是指示函数，若 • 为真则取值 1，否则取值0。

OK，我们以二分类问题为例：

真实目标函数可以是任何函数\(\mathcal{X}\mapsto \{0,1\}\)，函数空间

为 \(\{0,1\}^{|\mathcal{X}|}\) ，对所有可能的 \(f\) 按均匀分布对误差求和，有


![](http://106.15.37.116/wp-content/uploads/2018/05/img_5b0534484f351.png)


上式显示出，总误差竟然与学习算法无关！对于任意两个学习算法  \(\pounds_a\) 和  \(\pounds_b\) ，我们都有：


![](http://106.15.37.116/wp-content/uploads/2018/05/img_5b0534d499c15.png)


也就是说，无论学习算法 \(\pounds_a\) 多聪明、学习算法 \(\pounds_b\) 多笨拙，它们的期望性能竟 然相同！这就是 “没有兔费的午餐” 定理（No Free Lunch Theorem，简称 NFL 定理）。（实际上严格的NFL定理证明比 这里的简化论述繁难得多）。

OK，那么大家会问了：既然所有学习算法的期望性能都跟随机胡猜的差不多，那还有什么好学的？

嗯，我们要注意到，NFL 定理实际上是有一个重要的前提的：所有的 “问题” 出现的机会相同、或所有问题同等重要。

但是实际情形并不是这样，很多时候我们只关注自己正在试图解决的问题（例如某个具体应用任务），希望为它找到一个解决方案， 至于这个解决方案在别的问题、甚至在相似的问题上是否为好方案，我们并不关心。

比如说：如果我们单单考虑从南京鼓楼到南京新街口，那么 “骑自行车” 就是一个很好的方案，而如果把南京新街口换成北京新街口，那么骑自行车就肯定不是一个好的方案。

事实上，上面 NFL 定理的简短论述过程中假设了 \(f\) 的均匀分布，而实际情形并非如此。

例如，回到我们熟悉的西瓜问题，考虑




  * ｛假设1：好瓜 ↔ （色泽=*）∧（根蒂=蜷缩）∧ （敲声=浊响）｝

  * ｛假设2：好瓜 ↔ （色泽=*）∧（根蒂=硬挺）∧ （敲声=清脆）}


由 NFL 定理可知，这两个假设本身是同样好的。我们立即会想到符合条件的例子，比如说，对好瓜（色泽=青绿；根蒂=蜷缩；敲声=浊响）是假设 1 更好，而对好瓜（色泽=乌黑；根蒂=硬挺；敲声=清脆）则是假设2更好。

看上去的确是这样，然而，需注意到，“（根蒂=蜷缩；敲声=浊响）” 的好瓜很常见，而 “（根 蒂=硬挺；敲声=清脆）”的好瓜很罕见，甚至不存在。



所以，NFL 定理最重要的寓意，是让我们清楚地认识到，脱离具体问题，空泛地谈论 “什么学习算法更好” 是毫无意义的，因为若考虑所有潜在的问题，则所有学习算法都一样好。

我们要想谈论算法的相对优劣，就必须针对具体的学习问题。在某些问题上表现好的学习算法，在另一些问题上却可能不尽如人意，学习算法自身的归纳偏好与问题是否相配，往往会起到决定性的作用。





















* * *





# COMMENT



