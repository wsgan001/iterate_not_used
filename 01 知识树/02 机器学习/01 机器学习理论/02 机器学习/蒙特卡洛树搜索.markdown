# 蒙特卡洛树搜索

# REF

1. [蒙特卡洛树搜索 wiki](https://zh.wikipedia.org/wiki/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%A0%91%E6%90%9C%E7%B4%A2)




# TODO

* **wiki上提到了蒙特卡洛树在很多棋盘游戏上的应用，要总结进来。**

* **Alphago 是怎么把蒙特卡洛树应用起来的？**

* **使用代码怎么实现？需要补充**




# MOTIVE

* 看书的时候提到了：Alphago验证了深度学习和蒙特卡洛搜索算法的实践性。才想起来，这个蒙特卡洛搜索算法好像没有总结，到底是什么？为什么这么利害？是基于什么的？

* 没怎么理解




# 蒙特卡洛树搜索是什么？


蒙特卡洛树搜索（英语：Monte Carlo tree search；简称：MCTS）是一种用于某些决策过程的启发式搜索算法，最引人注目的是在游戏中的使用。一个主要例子是电脑围棋程序[1]，它也用于其他棋盘游戏、即时电子游戏以及不确定性游戏。


# 蒙特卡洛树的搜索原理：


蒙特卡洛树搜索的每个循环包括四个步骤：


* 选择（Selection）：从根结点R开始，选择连续的子结点向下至叶子结点L。后面给出了一种选择子结点的方法，让游戏树向最优的方向扩展，这是蒙特卡洛树搜索的精要所在。

* 扩展（Expansion）：除非任意一方的输赢使得游戏在L结束，否则创建一个或多个子结点并选取其中一个结点C。

* 仿真（Simulation）：在从结点C开始，用随机策略进行游戏，又称为playout或者rollout。

* 反向传播（Backpropagation）：使用随机游戏的结果，更新从C到R的路径上的结点信息。


每一个节点的内容代表胜利次数/游戏次数


![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180728/j9e53IeAjh.png?imageslim)




# 探索与利用


选择子结点的主要困难是在较高平均胜率的移动后对深层次变型的利用和对少数模拟移动的探索二者中保持某种平衡。

第一个在游戏中平衡利用与探索的公式被称为UCT（Upper Confidence Bound 1 applied to trees，上限置信区间算法 ），由匈牙利国家科学院计算机与自动化研究所高级研究员列文特·科奇什与阿尔伯塔大学全职教授乔鲍·塞派什瓦里提出[6]。UCT基于奥尔（Auer）、西萨-比安奇（Cesa-Bianchi）和费舍尔（Fischer）提出的UCB1公式[25]，并首次由马库斯等人应用于多级决策模型（具体为马尔可夫决策过程）[26]。科奇什和塞派什瓦里建议选择游戏树中的每个结点移动，从而使表达式 \( {\frac {w_{i}}{n_{i}}}+c{\sqrt {\frac {\ln t}{n_{i}}}}\) 具有最大值。在该式中：

\( w_{i}\) 代表第\( i\) 次移动后取胜的次数；
\( n_{i}\)代表第\( i\) 次移动后仿真的次数；
\( c\) 为探索参数—理论上等于\( {\sqrt {2}}\) ；在实际中通常可凭经验选择；
\( t\) 代表仿真总次数，等于所有\( n_{i}\) 的和。
大多数当代蒙特卡洛树搜索的实现都是基于UCT的一些变形。
