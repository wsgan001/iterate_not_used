# 剪枝处理


TODO

* **实际上，我一直决定剪枝很神秘的，看了这一节之后才觉得，嗯，原来是这样。**
* **为什么我之前有看到说，剪枝的时候要涉及到树的重新排列呢？看错了吗？**







## 什么是剪枝？


剪枝 (priming) 是决策树学习算法对付 “过拟合” 的主要手段。

在决策树学习的时候中，不断的分支，可能会造成过拟合，这个时候就可以通过主动去掉一些分支来降低过拟合的风险。这就是剪枝。<span style="color:red;">是的，好像是有道理的。</span>


## 两种剪枝策略

决策树剪枝的基本策略有两种：

- 预剪枝 (prepruning)
- 后剪枝 (post-pruning)


- 预剪枝是指在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前结点标记为叶结点。<span style="color:red;">怎么知道这个划分不能带来决策树泛化性能提升？</span>
- 后剪枝则是先从训练集生成一棵完整的决策树， 然后自底向上地对非叶结点进行考察，若将该结点对应的子树替换为叶结点能够带来决策树泛化性能提升，那么将该子树替换为叶结点。<span style="color:red;">嗯，这个倒是好理解，但是怎么做呢？</span>

<span style="color:red;">这两种剪枝的方法听着还是很清楚的。</span>


## 剪枝前的准备，划分出验证集

上面的两种方法都说了要提升决策树的泛化性能，要怎么衡量这个泛化性能呢？

我们可以划分出一个验证集 。然后，看看划分前后，验证集上测试结果的精度变化。<span style="color:red;">一定要是精度变化吗？我是看后面的额例子用的是精度这里才这么写的，要确认下怎么衡量这个性能的。还是说一定是以精度来衡量的？</span>

OK，我们这里使用的是留出法，即预留一部分数据用作 “验证集” 以进行性能评估。

我们现在的数据集如下：

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180626/cib75L00df.png?imageslim)

现在，我们把它随机划分为两部分：

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180626/6hm6IBbcim.png?imageslim)


嗯，如上图所示：

* 训练集为 {1,2,3,6,7,10,14,15,16,17}
* 验证集为 {4,5,8,9,11,12,13}


OK，现在假定我们采用信息增益来做属性划分，那么我们从上表中的训练集中会产生这样一棵决策树：

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180626/mLGFgC43Ca.png?imageslim)

为便于讨论，我们对图中的部分结点做了编号。

OK，准备已经做好了，下面重点讲一下两种剪枝方法：




## 预剪枝策略

### 预剪枝过程

预剪枝是指在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前结点标记为叶结点。

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180626/43eE2Ig7G0.png?imageslim)

我们从头开始看，首先，基于信息増益准则，我们会选取属性 “脐部” 来对训练集进行划分。

那么，这个时候，我们就要来判断了，要不要进行这个划分呢？

我们就要看下划分前后的泛化性能怎么样：

* 如果不进行划分，也就是说这个结点将被标记为叶结点，那么这个结点的类别将被标记为训练样本数最多的类别，即 “好瓜” 类， OK，然后，我们用验证集对这个单结点的决策树进行评估，样本 {4,5,8} 分类正确，另外 4 个样本分类错误，那么，这个时候的验证集的精度为 $\frac{3}{7}\times 100\% = 42.9\%$。
* 如果用属性 “脐部” 进行划分，那么划分之后，分成了 ②、③、④ 三类，分别包含编号为 {1,2,3,14}、{6,7,15,17}、{10,16} 的训练样本，每个结点的类别就是这个结点的样本最多的类别，即： “好瓜”、“好瓜”、“坏瓜”。OK，然后，我们用验证集对这个决策树进行评估，验证集中编号为 {4,5,8,11,12} 的样例被分类正确，验证集精度为 $\frac{5}{7}\times  100\% =71.4\%$ 。

$71.4\% > 42.9\%$ ，说明我们可以用 “脐部” 进行划分。

<span style="color:red;">注意上面这个过程与决策树的生成时候的区别。决策树的生成的时候，他实际上是验证的很多的特征，然后看那个特征可以把信息增益做到最大，然后就用哪个特征进行划分。然后才是预剪枝的过程。而且，这个预剪枝并不会干涉到特征的选择，只会来看这个已经确定的特征是不是真的要分。</span>

OK，决策树算法继续对结点 ② 进行划分，基于信息增益准则，我们挑选出属性 “色泽” 。然而，在使用 “色泽” 划分后，计算出的验证集的精度为 57.1% ，相对于 71.4% 下降了，因此这个结点 ② 不能被。<span style="color:red;">解释一下：首先，这个色泽的特征是通过信息增益准则挑选出来的，也就是说，使用这个特征进行划分，对于结点 ② 来说已经是最好的选择了，但是，随后的验证却发现这个特征虽然是最好的，但是它却使整个树的泛化性能变差了，所以直接否掉这个特征。而别的特征因为连信息增益这一关都没有过去，也不会到这里来了。这个节点已经不会往下划分了。</span>

类似的，对于结点 ③ ，最优划分属性为 "根蒂"，划分后验证集精度还是 71.4%。也就是说这个划分不能提升验证集精度，因此，这个结点 ③ 也被禁止划分。<span style="color:red;">不能提升验证集精度的也会被禁止划分。</span>

对于结点 ④，它所含的训练样例已属于同一类，没法找到一个特征进行划分了，因此自然也是不用划分的。

OK，到这里，我们就从表 4.2 的数据中生成了这个已经被剪枝好的树图 4.6 。它的验证集精度为 71.4%。<span style="color:red;">总的来说还是很清晰的。</span>

这是一棵仅有一层划分的决策树，也被称为决策树桩 (decision stump)。<span style="color:red;">注：决策树桩在随机森林中经常会用到。</span>


### 预剪枝策略的优缺点

我们可以对比一下图4.6 和图 4.5，可以看到，预剪枝使得决策树的很多分支都没有 “展开”。<span style="color:red;">是的，这种没有展开会造成什么后果呢？</span>

我们很容易就能列出这样的剪枝的优点：

* 降低了过拟合的风险。
* 减少了决策树的训练时间开销和测试时间开销。而且是显著的降低。因为很多枝连展开都没有展开，后面的划分计算自然就没有了。

OK，那么这样的预剪枝是十全十美的吗？

实际上，还是有点问题的：


* 有些分支的当前划分虽然这次不能提升泛化性能、甚至可能导致泛化性能的暂时下降，但是在它基础上进行的后续划分却是有可能导致性能显著提高的。而预剪枝策略基于 “贪心” 的本质禁止了这些分支展开，这就给预剪枝决策树带来了欠拟合的风险。<span style="color:red;">是呀，听起来好像是这么回事。不过还是没有很理解？能不能举个例子？而且为什么会出现这种情况？这种方法的本质上有问题了吗？</span>

<span style="color:red;">上面这个缺点现在有什么说法吗？比如有什么降低欠拟合的风险的方法？怎么就提了一下就没有然后了？</span>


## 后剪枝策略

### 后剪枝过程

OK，现在我们介绍一下后剪枝。

后剪枝它与预剪枝还是不一样的，它先从训练集生成一棵完整的决策树，如图4.5。这个时候，这个决策树的验证集精度为 42.9%。

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180626/GE4bCh919E.png?imageslim)

OK，现在开始后剪枝：

我们先考察图4.5 中的结点 ⑥，如果我们将以它为父节点的分支剪除，也就是说把 ⑥ 替换为一个叶结点，由于替换后的叶结点包含着编号为 {7,15} 的训练样本，于是，这个叶结点的类别被标记为 “好瓜”，OK，这时我们看一下此时的决策树在验证集上的精度，为 57.1%。57.1% > 42.9%，因此我们决定剪枝。


![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180626/h44A5GEmDg.png?imageslim)


接着我们考察图4.5 中的结点 ⑤，如果把以它为父节点的子树替换为一个叶结点，替换后的叶结点包含编号为 {6,7,15} 的训练样例，这个叶结点类别被标记为 “好瓜” ，此时的决策树验证集精度仍为57.1%。于是，我们可以不进行剪枝。<span style="color:red;">注意：此种情形下检证集精度虽然没有提高，但是根据奥卡姆剃刀准则，剪枝后的模型更好。因此，实际的决策树算法在此种情形下通常要进行剪枝，本书为绘图的方便，采取了不剪枝的保守策略。实际上一般都是要剪的。这里图方便没减而已。好吧。</span>

类似的，我们对应结点 ②、结点 ③、结点 ①。

最终，我们就得到了图4.7 所示的决策树，其验证集精度为 71.4%。

<span style="color:red;">整体过程还是很清晰的。</span>



## 后剪枝与预剪枝的对比

OK，对比一下图4.7 和图4.6 ，我们可以看出：后剪枝决策树通常比预剪枝决策树保留了更多的分支。是的，因为比如有些分支，划分的时候验证集精度没有提升，然后就被预剪枝否决了，但是，实际上完全展开的时候，可以展的很深，展的过程中可能存在验证集精度的提高，而后剪枝来对完全展开的决策树进行剪枝的时候，他遇到这种情况就停下来了。所以后剪枝决策树通常比预剪枝决策树保留了更多的分支。

一般情形下：

* 欠拟合方面：后剪枝决策树的欠拟合风险很小，泛化性能往往优于预剪枝决策树。是的，毕竟后剪枝展开了更多的分支。欠拟合风险会更小。
* 时间开销方面：后剪枝过程是在生成完全决策树之后进行的，并且要自底向上地对树中的所有非叶结点进行逐一考察，因此其训练时间开销比未剪枝决策树和预剪枝决策树都要大得多。 <span style="color:red;">是的，而且要注意：是大得多。</span>


<span style="color:red;">那么一般的类库里面都是用的后剪枝还是预剪枝？默认使用什么？而且，好像我看 kaggle 的课程中使用到 sklearn 中的 rf 的时候，好像没有配置剪枝的参数？确认下。</span>



# REF
1. 《机器学习》周志华
