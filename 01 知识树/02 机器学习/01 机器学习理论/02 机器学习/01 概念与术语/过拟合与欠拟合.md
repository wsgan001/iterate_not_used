# 过拟合与欠拟合




TODO

* 文中的几个问题要对应下
* 将深度学习的过拟合的对应文章合并进来




## MOTIVE

* 对过拟合总结下。





## 什么是过拟合？欠拟合？


模型在训练集上的误差通常称为 “训练误差” 或 “经验误差”，而在新样本上的误差称为 “泛化误差”。显然，机器学习的目的是得到泛化误差小的学习器。然而，在实际应用中，新样本是未知的，所以只能使训练误差尽量小。

当模型在训练集上表现很好而在新样本上误差很大时，称为 “过拟合”；反之，模型在训练集上误差就很大时，称为 “欠拟合”。

欠拟合通常容易解决，过拟合则很难解决。


# 什么原因导致了欠拟合？


**需补充，是模型的复杂性不够吗？**


# 怎么解决欠拟合问题？


欠拟合通常容易解决，如 **增加数据、增大训练次数、增大学习率或使用更复杂的模型** 等。**增大学习率也能解决欠拟合问题吗？**






# 什么原因导致了过拟合？






  * 样本数量太少，且样本较为单一，比如训练样本中只有白色鸭子的数据，我们拿生成的模型去预测黑色鸭子，这肯定是部队的。所以在做训练的时候，要求训练样本一定要尽可能的全面，覆盖到所有数据类型。**如果就是不全面怎么办？**


  * 训练样本噪音数据干扰过大，噪音数据是指样本中的干扰数据。过多的噪音数据会导致模型记录了很多噪音特征，忽略了输入和输出的关系。


  * 模型过于复杂，模型参数太多。深度学习的模型经常会过拟合。所以，实际上，一个成熟的模型不一定是非常复杂的，而是要求模型对于不同的数据集都有稳定的输出表现。**嗯，感觉好像是这样，但是，按理说利害的人，来解决简单的事情，肯定是可以解决的，那么利害的模型为什么就不能解决简单的事情，而是会发生过拟合呢？这之间有什么区别呢？**


  * 抽样方法错误，抽出的样本数据不能有效足够代表业务逻辑或业务场景。比如样本符合正态分布，却按均分分布抽样，或者样本数据不能代表整体数据的分布；


  * 决策树模型没有剪枝


  * 权值学习迭代次数足够多（即过训练，Overtraining），拟合了训练数据中的噪声和训练样例中没有代表性的特征。** 什么是过训练？**




# 怎么预防和解决过拟合问题？


数据层面：




  * 更多的数据。尽可能的扩大 training dataset 才是王道。这个是对于神经网络等大数据量模型来说是最佳方法，可以从本质上解决（减少）过拟合。包括采集真实数据，或者在已有的数据上做各种仿射变化（如旋转，缩放 等），毕竟过拟合产生的根本原因是模型参数相对训练数据量太多。


  * 数据的采样，一定要尽可能的覆盖全部数据种类。**如果你的样本分布的方差比较大，且样本分布比较均匀，那么对于深度学习模型来说，数据可以不用那么多。**


模型与算法层面：


  * 简化模型：在训练和建立模型的时候，一定要从相对简单的模型开始，不要一上来就把模型调的非常复杂，特征非常多，这样很容易造成过拟合。而且，当模型过于复杂而造成过拟合时，也较难排查具体的问题出现在那一部分特征。**那么当模型过于复杂而过拟合时，怎么排查呢？**


  * 减少特征：**为什么？**


  * 数据要经过清晰之后再进行算法训练，否则如果混入了大量噪声数据，会加大过拟合问题发生的概率。**如果就是采不到均匀覆盖的数据呢？**


  * 交叉验证：cross validation ，当数据量较小的时候，应该是用来减轻过拟合的最好的方式了吧。**是什么？**


  * early stop：结合cross validation使用。**是什么？**


  * 正则化：可以在算法中添加惩罚函数来预防过拟合。比如L1、L2 规范。L2用的最多，L1也有用的。**惩罚函数为什么是起作用的？难道惩罚函数与模型的复杂度有关？可以衡量模型的复杂度吗？**


  * Dropout：这个是一大利器。在算法层面去减少过拟合，之前也有叫weight decay的另一技术都是为了使某些神经元值为0，减少相互依赖，可以看成是一种正则化。**这个只能在深度学习中使用吗？普通的机器学习算法可以使用这个吗？使用了后效果怎么样？**


  * Shuffling ：在训练之前记得 shuffle 一下数据集，一般是每次训练一个 epoch（就是把 training dataset 训练了一遍）后就 shuffle 一次，但是对于较大的数据集可以只 shuffle 一次，虽然这样会使得训练在第二个 epoch 就变得 biased，但是带来的好处可以 overcome 这种缺陷。**这个到底是什么？怎么做的？**


  * 加入噪声：可以将噪声加入数据或参数中


  * 使用 Bagging 等集成，好吧厉害了。


  * 可以在构建机器模型时，将数据集拆分为相互独立的训练数据集、验证数据集和测试数据集等，而在训练过程中使用验证数据集来评估模型并据此更新超参数，训练结束中使用测试数据集评估训练好的最终模型的性能。**在训练过程中使用验证数据集来评估模型并据此更新超参数是怎么做到的？**


**还是有些问题需要解决的。**





## REF

1. 《机器学习 实践应用》
2. [怎样消除机器学习中的过度拟合？](https://www.zhihu.com/question/26898675)
3. [模型评估](https://feisky.xyz/machine-learning/basic/evaluation.html)
