# 模型评估

TODO

* **重要的指标要单独拿出来，比如到底是什么意义？与别的指标的关系？正常情况下大概是多少？对模型的参数有什么指导意义？怎么画？怎么编程实现求这个指标？对于不同的模型这个指标分别应该怎么求？等等，还是有很多要清楚的，不是单单几句话就结束了**
* **再看看，用自己的话复述一遍。**
* **有些问题需要查找解决掉，并总结。**
* **为什么将比较检验和偏差方差单独拿出来了？**
* **我看Tensorflow里面好像有很多的评价指标，要看看那个是重要的。想知道指标冲突的时候选那个？**



# MOTIVE

* 我看Tensorflow里面好像有很多的评价指标，要看看那个是重要的。想知道指标冲突的时候选那个？







# 评价指标


机器学习算法那的最终目的是为了生成一个模型，模型的好坏需要一些指标来评估。

评价指标（也称性能度量）是评估机器学习泛化能力的标准，不同的指标往往会导致不同的评判结果。并且，不同的机器学习任务也有着不同的评价指标。




# 常用的评价指标有






  * 错误率：分类错误的样本数占样本总数的比例。


  * 准确率（精度）：分类正确的样本数占样本总数的比例。在很多情况下，准确率是一个欠佳或具有误导性的指标，比如在不同类型错误具有不同代价时（典型为分类不平衡，即正类别或负类别极其罕见）。


  * 对数损失函数（置信度）：\(log\_loss=-\frac{1}{N}\sum_{i=1}^{N}y_i log p_i + (1-y_i)log(1-p_i)\)，其中 y_iy​i​​ 是指第 ii 个样本所属的真实类别（0 或者 1），而\( p_i\)表示第 \(i\)个样本属于类别 1 的概率。


  * 查准率和查全率：查准率是指分类器分类正确的正样本（True Positive，TP）的个数占该分类器所有分类为正样本个数（TP+FP (false positive)）的比例；而查全率是指分类器分类正确的正样本个数（TP）占所有的正样本个数（TP+FN (false negative)）的比例。这两者通常是一对矛盾的变量，查准率高时，查全率往往偏低。


  * F1 度量：基于查准率和查全率的调和平均定义， \(F1=\frac{2PR}{P+R}\)，\(F1_\beta=\frac{(1+\beta^2)PR}{\beta^2P+R}\)，其中\( \beta\)是查全率对查准率的相对重要性。


  * 受试者工作特征（Receiver Operating Characteristic，ROC）：ROC 曲线描述真正例率（TPR）与假正例率（FPR）的关系。在比较 ROC 时，需要比较 ROC 曲线下面的面积（Area Under ROC Curve，AUC），**AUC 越大，分类效果越好。没怎么理解ROC和AUC，AUC会与F1冲突吗？ROC只能用在二分类场景里面吗？需要补充下。单纯的罗列跟本知不知道在说什么。**


  * 代价敏感错误率：用于非均等代价的情景，根据任务的领域知识设定代价矩阵，计算的错误率称为代价敏感错误率；而对应的 ROC 曲线叫代价曲线。





# 比较检验


机器学习中，性能比较是比较复杂的




  * 我们希望比较的是泛化性能，而实际中只能得到测试集上的性能，两者的结果未必相同


  * 测试集上的性能跟测试集本身的选择有很大关系


  * 很多机器学习算法本身有一定的随机性，即便用相同参数运行在同一个测试集上，多次的运行的结果也有可能不同


所以，我们需要运用统计假设检验（hypothesis test）得到模型的泛化性能是否在统计意义上较优。常用的方法包括：**什么是统计假设检验？这些方法又是什么？**




  * 二项检验


  * t 检验


  * 交叉验证 t 检验


  * McNemar 检验


  * Friedman 检验


  * Nemenyi 后续检验





# 偏差与方差


泛化误差可以分解为偏差、方差与噪声之和，偏差-方差分解（bias-variance decomposition）是解释泛化性能的重要工具。**怎么分解的？**




  * 偏差度量了算法的期望预测与真实结果的偏离程度。


  * 方差度量了同样大小训练集变动导致的性能变化。


  * 噪声涉及问题本身的难度。


所以，泛化性能是由学习算法的能力、数据的充分性以及学习任务本身的难度共同决定的。

但偏差与方差是有冲突的，即偏差-方差窘境（bias-variance dilemma）。在训练程度不足时，学习器拟合程度不强，训练数据的扰动不足以产生显著变化，此时偏差主导泛化错误率。随着训练程度加深，学习器拟合能力增强，训练数据的扰动逐渐可以被学习器学到，方差逐渐主导泛化错误率。如果继续加深训练，则有可能发生过拟合。







# REF

1. [模型评估](https://feisky.xyz/machine-learning/basic/evaluation.html)
