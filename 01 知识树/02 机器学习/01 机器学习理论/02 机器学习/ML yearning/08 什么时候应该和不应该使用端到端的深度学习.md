## Chapter 47、The rise of end-to-end learning

**端到端学习的兴起**

假设你想构建一个系统来检查在线产品评论，并自动告诉你作者是否喜欢该产品。例如，你希望识别以下评论为非常正面的：

```
这是一把极好的拖把！
```

而以下为非常负面的：

```
该拖把质量差——我后悔买它。
```

识别正面和负面观点的问题被称为“情感分类”。为了构建该系统，你可以构建两个组件的“流水线”：

1. 语法分析器：一个用标识最重要词语的信息来注释文本的系统【1】。例如，你可以使用语法分析器去标注所有的形容词和名词。因此，你可以得到如下带注释的文本：

   ```
   这是一把极好的（形容词）拖把（名词）！
   ```

2. 情感分类：一个将注释的文本作为输入并预测总体情感的学习算法。语法分析器的注释可以极大地帮助学习算法：通过给形容词更高的权重，算法那可以快速磨炼出重要的词汇，如“great”，并忽略不太重要的词汇，如“this”。

我们可以将两个组件的“流水线”可视化如下：

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180812/dkH92BgEAi.png?imageslim)

最近有一种趋势是使用单一学习算法来取代流水线系统。对于该任务的**端到端(end-to-end)学习算法**将简单的将原始数据作为输入，原始文本是“这是一把极好的拖把！”，并尝试直接识别情感：

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180812/mLjK1Cc968.png?imageslim)

神经网络通常用于端到端学习算法。术语“端到端”指的是我们要求学习算法直接从输入到期望输出。即，学习算法直接将系统的“输入端”连接到“输出端”。

在数据丰富的问题中，端到端系统非常成功。但它并不总是一个好的选择。接下来几章将给出更多端到端系统的例子，并给出何时该使用和何时不该使用它们的建议。



## Chapter 48、More end-to-end learning examples

**更多端到端学习示例**

假设你想构建一个语音识别系统。你可以用三个组件构建一个系统：

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180812/CgA6g0BIm5.png?imageslim)

这些组件工作如下：

1. 计算特征：提取手动设计的特征，例如MFCC(梅尔频率倒谱系数)特征，该特征尝试捕获说话的内容同时忽略不太相关的特性，比如说话者的音高。
2. 音素识别器：一些语言学家认为有基本的声音单元成为“音素”。例如，“keep”中开头的“k”音和“cake”中的“c”音音素相同。该系统试图识别音频剪辑中的音素。
3. 最终识别器：取出识别的音素序列，并尝试将它们串成一个输出转录：

相反，端到端系统可以输入一个音频剪辑，并试图直接输出转录:

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180812/HjLG8Fla2F.png?imageslim)

到目前为止，我们只描述了完全线性的机器学习“流水线”：输出从一个阶段顺序传递到下一个阶段。流水线可以更加复杂。例如，这是一个自动驾驶汽车的简单架构：

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180812/K8FF1cBdbH.png?imageslim)

它有三个组件：一个使用摄像机图像检车其他车辆；一个检测行人；然后最后一个组件为我们自己的汽车规划一条避免汽车和行人路线。

并非每个流水线中的组件都需要学习。例如，“机器人运动规划”相关文献中有大量关于汽车最终路径规划步骤的算法。这些算法中很多并不涉及学习。

相反，端到端的方法可能会试图接收传感器输入并直接输出转向方向：

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180812/F5jDgdHeBE.png?imageslim)

尽管端到端学习取得了很多成功，但它并不总是最好的方法。例如，端到端语音识别效果很好。但对于自动驾驶的端到端学习我持怀疑态度。接下来的几章将解释其原因。



## Chapter 49、Pros and cons of end-to-end learning

**端到端学习的优点和缺点**

考虑我们前面例子中相同的语音流水线：

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180812/56hl5k8b9H.png?imageslim)

该流水线的很多部分是“手工设计”的：

- MFCCs是一个手工设计的音频特征的集合。尽管它们提供了一个音频输入的合理总结，它们也通过丢弃一些信息来简化输入信号。
- 音素是语言学家的发明。它们是说话声音的不完美表示。在某种程度上，音素是对现实较差的近似，强制算法使用音素表示将限制语音系统的性能。

这些手工设计的组件限制了语音系统的潜在性能。然而，允许手工设计的组件也有一些优点：

- MFCC特征对不影响内容的某些语音属性（如说话者的音高）具有鲁棒性。因此，它们有助于简化学习算法的问题。
- 在某种程度上，音素是语音的合理表示，它们也能帮助学习算法理解基本的声音要素，从而提高其性能。

拥有更多手工设计的组件通常可以让语音系统以更少的数据学习。通过MFCCs捕获的手工设计的知识，以及音素“补充”的学习算法从数据中获取的知识。当我们没有太多数据时，这些知识是有用的。

现在，考虑端到端系统：

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180812/742f3Ga36G.png?imageslim)

该系统缺乏手工设计的知识。因此，当训练集很小时，它可能比手工设计的流水线要差。

但当训练集很大时， 那么它不会受到MFCC或基于音素表示的局限性的阻碍。如果学习算法是一个足够大的神经网络，并且训练数据足够多，那么它就有可能做的很好，甚至可能达到最优错误率。

当“两端”（输入端和输出端）都有很多标注数据时，端到端学习系统将表现良好。在该样例中，我们需要一个<音频，转录>对的大数据集。当该类型数据不可用时，请谨慎使用端到端学习方式处理。

如果你正在致力于一个机器学习问题，其训练集非常小，大部分算法的知识将不得不来自于你的洞察。即，来自于“手工设计”的组件。

如果你选择不使用端到端系统，你将不得不决定流水线中的步骤，以及如何将它们组合起来。在接下来的几个章节中，我们将为设计这些流水线提供一些建议。

## Chapter 50、Choosing pipeline components: Data availability

**选择流水线组件：数据可用性**

当构建一个非端到端的流水线系统时，对于流水线的组件来说什么是最好的选择呢？如何设计流水线将极大影响整个系统的性能。一个重要的因素是你是否可以容易地收集数据来训练每个组件。

例如，考虑如这种自动驾驶架构：

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180812/aDj4D3hIA6.png?imageslim)

你可以使用机器学习来检测汽车和行人。而且，获取这些数据并不难：有很多计算机视觉数据集，它们有大量标注的汽车和行人。你也可以使用众包（例如亚马逊土耳其机器人）来获取更大的数据集。因此获取训练数据来构建一个汽车检测器和行人检测器相对容易。

相反，考虑一个纯粹的端到端方法：

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180812/jkB1f00Abf.png?imageslim)

为了训练该系统，我们需要一个大的（图片，转向方向）对数据集。收集该数据需要人们开车并记录他们的转向方向，这很耗时而且很贵。你需要一个特殊装备的车队，以及大量的驾驶来涵盖各种可能的情况。这使端到端系统很难训练。获取已标注汽车和行人的大型数据集要容易的多。

更为一般的说，如果有很多数据可用于训练一个流水线（例如汽车检测器或行人检测器）的“中间模块”，那么你可以考虑使用有多个阶段的流水线。这种架构可能更优，因为你可以使用所有可用的数据来训练中间模块。

直到更多端到端数据可用之前，我相信非端到端方法对自动驾驶更有希望：其架构更好匹配数据的可用性。



## Chapter 51、Choosing pipeline components: Task simplicity

**选择流水线组件：任务简单**

除了数据可用性以外，当选择一个流水线的组件时，你还应该考虑第二个因素：各个组件解决的问题有多简单？你应该尝试选择易于构建和学习的流水线组件。但一个组件“易于”学习意味着什么？

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180812/ccAC0CKg6L.png?imageslim)

考虑这些机器学习任务，按难度递增的顺序罗列如下：

1. 分类图像是否过度曝光（如上例所示）
2. 分类图像是在室内还是室外拍摄
3. 分类图像是否包含猫
4. 分类图像是否包含黑色和白色毛皮的猫
5. 分类图像是否包含暹罗猫（特定品种的猫）

这些中的每一都是一个二进制图像分类任务：你必须输入一张图像，输出为0或1。但列表中较早的任务让一个神经网络来学习似乎太“更简单”。你将可以用更少的训练样本来学习更简单的任务。

机器学习没有很好的正式定义什么使任务变得容易或困难【1】。随着深度学习和多层神经网络的兴起，我们有时会说，如果一个任务可以以更少的计算步骤（对应于浅层神经网络）执行，那么该任务是“简单的”，如果一个任务需要更多计算步骤（需要更深的神经网络），那该任务是“困难的”。但这些都是非正式的定义。

如果你能够执行复杂的任务，并将其分解成简单的子任务，那么通过明确地编写子任务的步骤，你正在为算法提供先验知识，以帮助其更有效的学习任务。

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180812/4bdd1FIl28.png?imageslim)

假设你正在构建一个暹罗猫检测器。这是纯粹的端到端架构：

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180812/7aKk8Aecm4.png?imageslim)

相比之下，你可以使用有两个步骤的流水线架构：

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180812/Lm4BibF13A.png?imageslim)

第一个步（猫检测器）检测图片中所有的猫。

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180812/3K8dj7J2f8.png?imageslim)

第二步将每个检测出的猫（一次一个）的裁剪图像传入猫种类分类器，如果检测出的猫是暹罗猫，那么最终输出为1。

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180812/Bj1b32f33D.png?imageslim)

相比仅使用标签0/1训练一个纯粹的端到端分类器，流水线中两个组件的每一个（猫检测器和猫品种分类器）似乎更容易学习并且将需要更少的数据【2】。

作为最后一个例子，让我们再来看看自动驾驶流水线。

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180812/j3G2j85GGC.png?imageslim)

通过使用该流水线，你告诉算法驾驶有3个关键的步骤：(1)检测其他汽车，(2)检测行人，和(3)为你的车规划路线。此外，相对于纯粹的端到端学习方法，这些步骤中的每一个都是相对简单的功能（因此可以使用更少的数据学习）。

总之，在决定流水线中的组件应该是什么时，尝试构建一个流水线，其每个组件功能相对“简单”，因此可以只需从适量的数据中学习。

————————

【1】 信息理论具有“Kolmogorov复杂性”的概念，其表示学习函数的复杂性是可以产生该函数的最短计算机程序的长度。然而，这一理论概念在人工智能中几乎没有实际应用。可参见：https://en.wikipedia.org/wiki/Kolmogorov_complexity

【2】 如果您熟悉实际物体检测算法，您将认识到它们不仅仅学习0/1图像标签，而是使用作为训练数据一部分提供的边界框进行训练。对它们的讨论超出了本章的范围。如果您想了解有关此类算法的更多信息，请阅读Coursera上的深度学习专业（http://deeplearning.ai）。




## Chapter 52、Directly learning rich outputs

**直接学习丰富的输出**

图像分类算法将输入图像x，并输出一个整数来指示物体类别。算法可以输出描述图像的完整语句么？

例如：

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180812/5FjkD1bCde.png?imageslim)

监督学习的传统应用学习了函数 h: X->Y，其中输出y通常是一个整数或实数。例如：

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180812/FhH3lB6kBc.png?imageslim)

端到端深度学习中最激动人心的发展之一是它让我们直接学习远比数字复杂的多的东西。在上面的图片标题示例中，你可以让神经网络输入图片(x)，并直接输出标题(y)。

以下是更多的例子：

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180812/demBf4Eaj5.png?imageslim)

这是深度学习的一个加速趋势：当你拥有正确的已标注（输入, 输出）对时，即使输出是比单个数字更丰富的句子、图片、音频或其他输出，你有时也可以学习端到端。






## REF

- [machine-learning-yearning](https://github.com/xiaqunfeng/machine-learning-yearning/)
- 《Machine Learning Yearning》 by Andrew NG
