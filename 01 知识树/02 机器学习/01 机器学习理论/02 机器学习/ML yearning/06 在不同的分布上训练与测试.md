# Training and testing on different distributions



##Chapter 36、When you should train and test on different distributions

**何时应该在不同的分布下训练和测试**

你的猫图app用户已经上传了1W张图片，手动标注过是否包含猫。你还有一个更大的数据集，包含20W从互联网下载下来的图片。你该如何定义训练/开发/测试集？

由于这1W张用户图片密切地反映了你想要做好的数据实际的概率分布，你可以使用它们作为开发和测试集。如果你在训练一个数据饥渴的深度学习算法，可以给算法额外的20W互联网图片用于训练。因此，你的训练和开发/测试集来自不同的概率分布。这对工作有什么影响？

我们可以将这21W图片随机挪到训练/开发/测试集中去，而不是将数据分割成训练/开发/测试集。这种情况下，所有的数据来自相同的分布。但我建议不用这种方法，因为约 205000/2100000 = 97.6%的开发/测试数据可能来自互联网图片，这不能反映你想要做好的实际分布。记住在选择开发/测试集上我们的推荐：

选择开发测试集以反映你期望在未来获取并想做的更好的数据。

大多数机器学习上的学术文献都假定训练集、开发集和测试集都来自相同的分布【1】。在机器学习的早期，数据不足。我们通常只一些概率分布中获取一个数据集。所以我们会将数据随机切分为训练/开发/测试集，并且所有数据来自同一个来源假设通常都是满足的。

但在大数据时代，我们现在能够访问到大量的训练集，例如猫互联网图片。即使训练集和来自和开发/测试集不同的分布，我们仍希望将其用于学习，因为它能提供很多信息。

对于猫检测器例子，我们可以将用户上传的5000张图片，而不是所有的1W张放入开发/测试集中。我们可以将剩余的5000张用户上传的样例放入训练集。这样，你的205000大小的训练集中包含一些来自开发/测试分布的数据，以及20W互联网图片。我们将在下一章中讨论为什么该方法有用。

我们来看第二个例子。假设你正在构建一个语音识别系统，来转录语音控制的移动地图/导航app的街道地址。你有2W个用户讲街道地址的样例。但你也有50W用户谈论其他话题的音频剪辑。你可以将那1W个街道地址的样例作为开发/测试集，并使用剩下的1W，附加50W样例，用于训练。

我们将继续假设你的卡发数据和测试数据来自相同的分布。但重要的是，要明白不同的训练和开发/测试分布提供了一些特殊的挑战。

————————

【1】有一些关于训练和测试在不同分布上的学术研究。包括“domain adaptation”,"tarnsfer learning"和"multitask learning"。但理论和实践还是存在很大的差距。如果你在数据集A上训练，并在其上测试分布大不相同的数据B，运气会对你的算法执行效率产生巨大的影响。（这里的“运气”包含研究者对特定任务手动设计的功能，以及其他我们尚不了解的因素）这使得对不同分布上训练和测试的学术研究系统的进行比较困难。


## Chapter 37、How to decide whether to use all your data

**如何决定是否使用所有数据**

假设你的猫检测器的训练集包含1W张用户上传的图片。这些数据与独立的开发/测试集来自相同的分布，代表你关心并想做好的分布。你还有额外的2W从互联网下载的图片。你应该将所有的2W+1W=3W图片提供给学习算法作为它的训练集吗？还是丢弃这2W张互联网图片，怕它偏差学习算法？

当使用前几代的学习算法时（例如手工设计的计算机视觉特征，加上一个简单的线性分类器），合并两种类型的数据确实会造成算法表现糟糕的风险。因此，一些工程师会告诫你不要包含那2W张互联网图片。

但在现代强大灵活的学习算法（例如大型神经网络）下，该风险大大降低。如果你有能力构建一个拥有足够数量的隐藏单元/层的神经网络，你可以安全地将这2W张图片加入训练集中。添加这些图片更有可能提升你的表现。

该观察依赖于一个事实，就是有一些x->y的映射在两种类型的数据上都的能很好的工作。换句话说，存在某个系统，不论你输入互联网图片还是移动app端图片都能得到可靠的预测标签，甚至不需要知道图片的来源。

添加额外的2W图片有如下影响：

1. 它给你的神经网络提供更多的猫长啥样和不长啥样的样例。这很有帮助，因为互联网图片和用户上传的移动端app图片都共享一些相似之处。神经网络可以将从互联网图片获取到的知识应用到移动app图像上。
2. 它迫使神经网络花费一些能力来学习互联网图片特定的属性（例如高分辨率，图片框架下的不同分布，等等）。如果这些特性和移动app图片大不相同，它将消耗掉神经网络的一些代表性能力。因此从移动app图片分布中识别数据的能力较低，这才是你真正关心的。理论上来说，这可能会伤害到你算法的性能。

为了用不同的术语来描述第二种影响，我们可以转向虚拟人物福尔摩斯，他说你的大脑像阁楼；它只有有限数量的空间。他说“对于每一个新增的知识，你会忘记之前记得的东西。所以，最重要的是，不要用无用的事实去排挤有用的事实”【2】。

幸运的是，如果你有构建一个大的神经网络的能力（即一个大的阁楼），那么这并不是一个严重的问题。你有足够的能力去从互联网和移动app图像上学习，而不需要两种类型的数据竞争容量。算法的“大脑”足够大以至于你不必担心阁楼空间用完。

但是如果你没有足够大的神经网络（或另一个高度灵活的学习算法），那么你应该更多的关注和你的开发/测试集分布相匹配的训练数据。

如果你认为数据无用，出于计算原因，你应该忽略这些数据。例如，假设你的开发/测试集主要包含人物、地点、地标和动物图片。假设你也有大量的扫描历史文档：

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180812/g9Bbl3b8A0.png?imageslim)


这些文档不包含任何类似猫的东西。它们看起来也完全不像你的开发/测试分布。将这些数据作为负样本没有任何意义，因为上面第一个影响的好处可以忽略不计，你的神经网络几乎没有什么能从这些数据中学到它可以应用到你的开发/测试集分布。包含他们会浪费神经网络的计算资源和表示能力。

————————

【2】A Study in Scarlet   by Arthur Conan Doyle



## Chapter 38、How to decide whether to include inconsistent data

**如何决定是否包含不一致的数据**

假设你想学习预测纽约的房价。给定房屋的大小（输入特征x），你想预测其价格（目标标签y）。

纽约的房价非常高。假设你有位于密西根州底特律的第二个房价数据集，该地房价要低的多。你应该在训练集中包含这些数据么？

给定相同的大小x，房子的价格根据其是在纽约还是底特律而大相径庭。如果你只关心预测纽约的房价，那么将两个数据集放在一起将损害你的表现。在这种情况下，最好忽略不一致的底特律数据【3】。

纽约vs底特律的例子和移动app vs互联网猫图的例子相比有什么区别？

猫图例子不同，因为给定输入图片x，它可以可靠的预测标签y表明是否有猫，甚至不需要知道图片是来自互联网还是移动app。即，有一个从输入x可靠地映射到目标输出y的函数f(x)，甚至不需要知道x的来源。因此，从互联网图片中识别的任务和从移动app图片中识别的任务是“一致的”。这意味着包含所有的图片几乎没有缺点（除了计算开销），并有可能有一些显著优点。相反，纽约和密西根州底特律的数据并不一致。给定相同的x（房子的大小），价格根据房子的所在地差别很大。

————————

【3】有一种方法可以解决底特律数据和纽约数据不一致的问题，就是给每个训练样例添加额外的特征来表征城市。给定输入x（现在指定城市），目标值y现在是明确的。然而，实际中这种方法不常见。



## Chapter 39、Weighting data

**加权数据**

假设你有20w来自互联网的图片和5000来自你的移动app用户的图片。这些数据的大小比例是40:1。从理论上来说，只要你构建一个大的神经网络并在这所有205000张图片上训练足够长的时间，对于我们试图让算法在互联网图片和移动图片上做的更好来说并没有什么坏处。

但是实践上来说，相比移动app图片而言，其40倍的互联网图可能意味着相比只训练5000张图片，需要花费40倍（或更多）的计算资源来对二者进行建模。

如果你没有庞大的计算资源，你可以给互联网图片一个较低的权重作为妥协。

例如，假设你的优化目标是平方差（对于分类任务，这不是一个好的选择，但它会简化我们的解释）。因此，学习算法试图去优化：

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180812/lllLJ16KFf.png?imageslim)

上面的第一个和是5000张移动图片，第二个和是2W张互联网图片。你可以改为使用额外的参数 $\beta$ 进行优化：

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180812/bb7h5im13B.png?imageslim)

如果你设置 $\beta = 1/40$ ，算法会给5000移动图片和20W互联网图片相同的权重。你也可以设置参数 $\beta$ 为其他值，或者通过调整开发集。

通过将减少额外的互联网图降低权重，你不必构建一个大的神经网络来确保算法在两种类型的任务上都做的很好。只有当你怀疑附加数据（互联网图片）的分布与开发/测试集非常不同时，或附加数据远大于来自相同分布的开发/测试集（移动图片），此时这类数据需要重新调整权重。




## Chapter 40、Generalizing from the training set to the dev set

**从训练集到开发集的泛化**

假设你在训练和测试集分布不同的情况下应用ML。假设，训练集包含互联网图片和移动图片，并且开发/测试集仅包含移动图片。然而，算法工作的并不好：在开发/测试集上的错误比你想象的高很多。以下是可能出错的一些可能性：

1. 它在训练集上做的不好。这是训练集分布上的高（可避免）偏差问题。
2. 它在训练集上做的很好，但是并没有很好的泛化到之前和训练集来自相同分布的没有被看到的数据上。这是高方差。
3. 它很好的泛化到和训练集来自相同分布的新数据上，但没能很好的泛化开发/测试集分布的数据。我们称该问题为**数据不匹配**，因为训练数据和开发/测试集数据不匹配。

例如，假设在猫识别任务上人可以达到几乎完美的表现。你的算法达到如下成绩：

- 在训练集上1%的错误率
- 在算法没有看见的和训练集来自相同分布的数据上1.5%的错误率
- 在开发集上10%的错误率

在这种情况下，你显然存在数据不匹配问题。为了解决该问题，你可能需尝试获取和开发/测试集更类似的训练数据。我们稍后将讨论一些方法。

为了诊断算法在上述1-3问题上遭受何种程度的影响，有另一个数据集事有用的。具体来说，与其给算法所有可用的训练数据，不如将其分成两个子集：算法用于训练的实际训练集，和一个独立的数据集，我们称之为“训练开发”集，不用于训练。

现在你有四个数据子集：

- 训练集：这是算法将从中学习的数据（例如互联网图片和移动图片）。这不必从我们真正关心数据的相同分布（开发/测试集分布）中获取。
- 训练开发集：该数据和训练集来自相同的分布（即互联网图片和移动图片）。通常比训练集要小，它只需要足够大以评估和跟踪学习算法的进度就行。
- 开发集：和测试集来自相同的分布，它反映我们最终关心并想要做好的数据的分布（即移动图片）。
- 测试集：和开发集来自相同的分布（例如移动图片）。

有以上四个独立的数据集，现在你可以评估：

- 训练错误，通过对训练集进行评估。
- 算法泛化到和训练数据来自相同分布的新数据的能力，通过对训练开发集进行评估。
- 算法在你关心的任务上的表现，通过对开发、测试集进行评估。

大部分在第5~7章选择开发集大小的指导方针同样适用于训练开发集。


## Chapter 41、Identifying Bias, Variance, and Data Mismatch Errors

**识别偏差、方差和数据不匹配错误**

假设人在猫检测任务上可以达到几乎完美的表现（~0%错误），因此最优错误率大约是0%。假设你有：

- 训练集上1%的错误
- 训练开发集上5%的错误
- 开发集上5%的错误

这告诉你什么？这里，你了解到有高方差。先前描述的减少方差的方法应该可以使你取得进步。

现在，假设你的算法取得：

- 训练集上10%的错误
- 训练开发集上11%的错误
- 开发集上12%的错误

这告诉你在训练集上有高可避免偏差。即算法在训练集上做的很差。减少偏差的方法应该有所帮助。

上面的两个例子，算法只遭受有高可避免偏差或高方差。算法可能遭受任何子集的高可避免偏差，高方差和数据不匹配。例如：

- 训练集上10%的错误
- 训练开发集上11%的错误
- 开发集上20%的错误

算法遭受高可避免偏差和数据不匹配。然而，并没有在训练集分布上遭受高方差。

通过将不同类型错误绘制为表上的条目，可能更容易理解它们之间如何相互联系：

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180812/CaEjfJ63ma.png?imageslim)

继续猫图检测器的例子，你可以看到在x轴上有两种不同数据分布。在y轴上，有三种错误类型：人水平错误，在算法已经训练过样例上的错误，在算法没有训练过样例上的错误。我们可以填写上一章节中已经确定的不同错误类型。

如果你愿意，你也可以填写表格中剩下的两个框：通过让人来标注移动猫图数据并测量他们的错误率，将其填入右上角的框中（在移动图片上的人水平表现）。通过将移动猫图（分布B）中的一小部分放入训练集中，以至于神经网络也可以学习到它，将其填入下一个框中。然后在数据子集上测量学习模型的错误。填入这两条附加条目有时可以提供额外的洞察力，关于算法在两种不同分布（分布A和B）的数据上的工作。

通过理解哪种类型的错误算法遭受的最多，你将更好的决定是否专注在减少偏差、减少方差还是减少数据不匹配。


## Chapter 42、Addressing data mismatch

**处理数据不匹配**

假设你开发了一个语音识别系统，在训练集和训练测试集上表现的非常好。然而，在开发集上表现糟糕：你有数据不匹配问题。你能怎么做？

我推荐你：(i)试图去理解训练集分布和开发集分布之间数据的什么特性不同。(ii)试图寻找更多算法有问题的和开发集样例更匹配的训练数据【1】。

例如，假设你在语音识别开发集上执行错误分析：你手动检查100个样例，并试图去理解算法在哪里犯错了。你发现系统表现糟糕是因为大部分开发集里的音频剪辑是在车内获取的，而大部分的训练样例是在安静的背景下记录的。发动机和路上的噪音极大地恶化了语音系统的表现。在这种情况下，你可以尝试去获取更多的训练数据，包括在车内的音频剪辑。错误分析的目的是去理解导致数据不匹配的训练集合开发集之间的显著不同。

如果你的训练和训练开发集包含车内录制的音频，你还应该再次确认系统在该数据子集上的表现。如果它在训练集中的车数据上表现良好，但在训练开发集的车数据上表现不佳，那么这进一步验证了获取更多车数据会有帮助的假设。这就是为什么我们讨论的在训练集中包含一些和前一章中开发/测试集来自相同分布的数据的可能性。这样做允许你比较在训练集车数据和开发/测试集车数据上的表现。

不幸的是，这个过程中没有保证。例如，如果你没有获取更多和开发集数据更匹配的训练数据的方法，你可能没有一个清晰的途径来提升性能。

————————

【1】还有一些关于“域适应”的研究——如何在一个分布上训练算法，并将其泛化到一个不同的分布。这些方法通常只适用于特殊类型的问题，并比本章描述的想法使用的少得多。


## Chapter 43、Artificial data synthesis

**人工数据合成**

你的语音系统需要更多听起来像是从车内获取的数据。相比在驾车时手机许多数据，可能有一个更简单的方法去获取数据：通过人工合成它。

假设你获得了大量的车/道路噪音音频剪辑。你可以在多个网站上下载这些数据。假设你也有一个大的训练集，数据是人们在安静的房间里说话。如果你将一个人说话的音频剪辑和车/道路噪声音频剪辑“加”在一起，你将获得听起来像是人在吵闹的车内说话的音频剪辑。使用该过程，你可以“合成”大量听起来像是在车内收集的数据。

更一般的说，在几种情况下，人工数据合成可以让你创造出一个合理匹配开发集的庞大数据集。让我们用猫图检测器作为第二个例子。你注意到开发集图片有更多的运动模糊，因为它们倾向于来自于手机用户，用户在拍照时会轻微移动手机。你可以从互联网图片训练集中得到不模糊的图片，并为它们添加伪造运动模糊，从而使它们和开发集更类似。

记住人工数据合成有其挑战性：有时候创建对人来说看起来很逼真的合成数据比创建对电脑来说看起来很逼真的数据要容易。例如，假设你有1000小时的语音训练数据，但只有一小时的车噪声。如果你对原始1000小时训练数据的不同部分重复使用同样的这一小时的汽车噪声，你最终得到的合成数据集有着相同的汽车噪声，不断的重复。虽然听这种音频的人可能不能区分（对我们大多数人来说所有的汽车噪声都一样），但学习算法可能会“过拟合”这一个小时的汽车噪声。因此，对于汽车噪声听起来不同的新音频剪辑，算法可能泛化能力较差。

或者，假设你有1000个独特的汽车噪声小时，但它们全部来自仅 10 中不同的车。在这种情况下，算法那可能会“过拟合”这些车，如果在不同的汽车音频上测试，表现较差。不幸的是，这些问题很难被发现。

再看一个例子，假设你在构建一个识别车的计算机视觉系统。假设你和一个视频游公司合作，该公司拥有一些车的计算机图形模型。为了训练算法那，你使用这些模型生成汽车的合成图像。即使合成图片看起来很逼真，该方法（已被很多人独立提车）可能不会工作的很好。在整个视频游戏中可能有约20辆车设计。构建一个3D的汽车模型成本非常高；如果你在玩游戏，你可能不会注意到你反复看到同样的车，也许只是油漆色不同，也就是说，这些数据看起来对你非常逼真。但是和路上所有车的集合相比（因此你可能会在开发/测试集中看到），这20辆合成的车仅仅是世界汽车分布的一小部分。因此，如果你10W训练样本都来自这20辆车，系统将“过拟合”这20辆特定车的设计，并不能很好的泛化到包括其他车型设计的开发/测试集。

当合成数据的时，考虑一下你是否真的合成了一组具有代表性的样例。试图避免提供合成数据的属性，使得学习算法可以区分合成和非合成样本，例如如果所有的合成数据都来自20辆车设计中的一个，或所有的合成音频都来自车一个小时的噪声。这建议很难遵循。

当开展数据合成工作时，我的团队有时在生成数据上会花费数周，生成数据的详细信息足够贴近真实分布的，以便会有显著的影响。但如果你能正确获取细节，你会瞬间获取远比以前大的训练集。




## REF

- [machine-learning-yearning](https://github.com/xiaqunfeng/machine-learning-yearning/)
- 《Machine Learning Yearning》 by Andrew NG
