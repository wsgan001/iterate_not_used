# 【机器学习】模型融合方法概述

[贝尔塔](https://www.zhihu.com/people/denotepython)

我理解的Kaggle比赛中提高成绩主要有3个地方

1. 特征工程
2. 调参
3. 模型融合



之前每次打比赛都只做了前两部分，最后的模型融合就是简单的加权平均，对于进阶的Stacking方法一直没尝试，这几天摸索了一下还是把Stacking方法给弄懂了。(本文重点讲解Stacking,Bagging和Boosting有很多权威的好教程，所以不详细介绍)最早的Stacking思想早些年就有论文发表，但是应用Stacking方法到比赛中的相关文章还是少之甚少，这有两篇[https://mlwave.com/kaggle-ensembling-guide/](https://link.zhihu.com/?target=https%3A//mlwave.com/kaggle-ensembling-guide/)、[HUMAN ENSEMBLE LEARNING](https://link.zhihu.com/?target=https%3A//mlwave.com/human-ensemble-learning/)讲的很棒，但是之前因为理解不到位，有几处卡住了。在[@Wille](http://www.zhihu.com/people/dichotomy42) 的文章[如何在 Kaggle 首战中进入前 10%](https://link.zhihu.com/?target=https%3A//dnc1994.com/2016/04/rank-10-percent-in-first-kaggle-competition/)中Stacking只是作为一部分提到。因此决定自己写一篇关于模型融合的文章。本文不涉及到各个算法原理层次的深度，目的在于从宏观上帮助理解这几个模型融合方法。

## **一、Voting**




## **二、Averaging**



## **三、Bagging**

1. 重复K次



- 有放回地重复抽样建模
- 训练子模型





- 分类问题：voting

-

- 回归问题：average



Bagging算法不用我们自己实现，随机森林就是基于Bagging算法的一个典型例子，采用的基分类器是决策树。R和python都集成好了，直接调用。

## **四、Boosting**

PPT



![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180803/3bejDeLGHc.png?imageslim)

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180803/GbIeDELjff.png?imageslim)




## 五、Stacking


1. 基模型M1，对训练集train训练，然后用于预测train和test的标签列，分别是P1，T1
$\begin{pmatrix} \vdots  \\ P_1   \\ \vdots  \\ \vdots  \\ \end{pmatrix} \begin{pmatrix} \vdots  \\ T_1   \\ \vdots  \\ \vdots  \\ \end{pmatrix}$
对于M2和M3，重复相同的工作，这样也得到P2，T2,P3,T3。

2. 分别把P1,P2,P3以及T1,T2,T3合并，得到一个新的训练集和测试集train2,test2.$\begin{pmatrix} \vdots  \\ P_1   \\ \vdots  \\ \vdots  \\ \end{pmatrix} \begin{pmatrix} \vdots  \\ P_2   \\ \vdots  \\ \vdots  \\ \end{pmatrix} \begin{pmatrix} \vdots  \\ P_3   \\ \vdots  \\ \vdots  \\ \end{pmatrix} \implies \overbrace{\begin{pmatrix} \vdots &\vdots  &\vdots \\ P_1 & P_2 &P_3   \\ \vdots  &\vdots &\vdots \\ \vdots &\vdots &\vdots  \\ \end{pmatrix} }^{train2}$


Stacking本质上就是这么直接的思路，但是这样肯定是不行的，问题在于P1的得到是有问题的，用整个训练集训练的模型反过来去预测训练集的标签，毫无疑问过拟合是非常非常严重的，因此现在的问题变成了**如何在解决过拟合的前提下得到P1、P2、P3**，这就变成了熟悉的节奏——K折交叉验证。我们以2折交叉验证得到P1为例,假设训练集为4行3列

$\begin{pmatrix} a_{11} & a_{12} &a_{13}  \\ a_{21} & a_{22} &a_{23}  \\ a_{31} & a_{32} &a_{33}  \\ a_{41} & a_{42} &a_{43}  \\ \end{pmatrix}$
将其划分为2部分

$\overbrace{ \begin{pmatrix} a_{31} & a_{32} &a_{33}  \\ a_{41} & a_{42} &a_{43}  \\ \end{pmatrix} }^{trainb}$
用traina训练模型M1，然后在trainb上进行预测得到preb3和pred4
$\overbrace{ \begin{pmatrix} a_{11} & a_{12} &a_{13}  \\ a_{21} & a_{22} &a_{23}  \\ \end{pmatrix} }^{traina} \overbrace{\implies}^{train} \overbrace{ \begin{pmatrix} a_{31} & a_{32} &a_{33}  \\ a_{41} & a_{42} &a_{43}  \\ \end{pmatrix} }^{trainb} \overbrace{\implies}^{predict} \begin{pmatrix} pred3  \\ pred4   \\ \end{pmatrix}$
在trainb上训练模型M1，然后在traina上进行预测得到pred1和pred2
$\overbrace{ \begin{pmatrix} a_{31} & a_{32} &a_{33}  \\ a_{41} & a_{42} &a_{43}  \\ \end{pmatrix} }^{trainb} \overbrace{\implies}^{train} \overbrace{ \begin{pmatrix} a_{11} & a_{12} &a_{13}  \\ a_{21} & a_{22} &a_{23}  \\ \end{pmatrix} }^{traina} \overbrace{\implies}^{predict} \begin{pmatrix} pred1  \\ pred2   \\ \end{pmatrix}$
然后把两个预测集进行拼接
$\begin{pmatrix} pred1  \\ pred2   \\ \end{pmatrix} + \begin{pmatrix} pred3  \\ pred4   \\ \end{pmatrix} = \begin{pmatrix} pred1  \\ pred2   \\ pred3  \\ pred4   \\ \end{pmatrix} = \begin{pmatrix} \vdots  \\ P_1   \\ \vdots  \\ \vdots  \\ \end{pmatrix}$
对于测试集T1的得到，有两种方法。注意到刚刚是2折交叉验证，M1相当于训练了2次，所以一种方法是每一次训练M1，可以直接对整个test进行预测，这样2折交叉验证后测试集相当于预测了2次，然后对这两列求平均得到T1。
或者直接对测试集只用M1预测一次直接得到T1。
P1、T1得到之后，P2、T2、P3、T3也就是同样的方法。理解了2折交叉验证，对于K折的情况也就理解也就非常顺利了。所以最终的代码是两层循环，第一层循环控制基模型的数目，每一个基模型要这样去得到P1，T1，第二层循环控制的是交叉验证的次数K，对每一个基模型，会训练K次最后拼接得到P1，取平均得到T1。这下再把@Wille博文中的那张图片放出来就很容易看懂了。

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180803/hHe5ChAHaf.png?imageslim)


### python实现

Github

```python
def get_oof(clf, x_train, y_train, x_test):
 oof_train = np.zeros((ntrain,))
 oof_test = np.zeros((ntest,))
 oof_test_skf = np.empty((NFOLDS, ntest))  #NFOLDS行，ntest列的二维array
 for i, (train_index, test_index) in enumerate(kf): #循环NFOLDS次
     x_tr = x_train[train_index]
     y_tr = y_train[train_index]
     x_te = x_train[test_index]
     clf.fit(x_tr, y_tr)
     oof_train[test_index] = clf.predict(x_te)
     oof_test_skf[i, :] = clf.predict(x_test)  #固定行填充，循环一次，填充一行
 oof_test[:] = oof_test_skf.mean(axis=0)  #axis=0,按列求平均，最后保留一行
 return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)  #转置，从一行变为一列
```



### caretEnsemble包下的caretStack()方法

```
algorithmList <- c('lda', 'rpart', 'glm', 'knn', 'svmRadial')
stackControl <- trainControl(method="repeatedcv", number=10, repeats=3, savePredictions=TRUE, classProbs=TRUE)
stack.glm <- caretStack(models, method="glm", metric="Accuracy", trControl=stackControl)
```

博文

### h2o包的h2o.stack()方法

```
nfolds <- 5
glm1 <- h2o.glm(x = x, y = y, family = family,
             training_frame = train,
             nfolds = nfolds,
             fold_assignment = "Modulo",
             keep_cross_validation_predictions = TRUE)
gbm1 <- h2o.gbm(x = x, y = y, distribution = "bernoulli",
             training_frame = train,
             seed = 1,
             nfolds = nfolds,
             fold_assignment = "Modulo",
             keep_cross_validation_predictions = TRUE)
rf1 <- h2o.randomForest(x = x, y = y, # distribution not used for RF
                     training_frame = train,
                     seed = 1,
                     nfolds = nfolds,
                     fold_assignment = "Modulo",
                     keep_cross_validation_predictions = TRUE)
dl1 <- h2o.deeplearning(x = x, y = y, distribution = "bernoulli",
                     training_frame = train,
                     nfolds = nfolds,
                     fold_assignment = "Modulo",
                     keep_cross_validation_predictions = TRUE)
models <- list(glm1, gbm1, rf1, dl1)
metalearner <- "h2o.glm.wrapper"
stack <- h2o.stack(models = models,
                response_frame = train[,y],
                metalearner = metalearner,
                seed = 1,
                keep_levelone_data = TRUE)
# Compute test set performance:
perf <- h2o.ensemble_performance(stack, newdata = test)
```

h2o的Github网站



![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180803/GDFF1al4mB.png?imageslim)




## REF

-  http://zhuanlan.zhihu.com/p/25836678
