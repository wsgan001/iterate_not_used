剪枝优化



规则生成本质上是一个贪心搜索过程，需有一定的机制来缓解过拟合的风险，最常见的做法是剪枝（pruning）。与决策树相似，剪枝可发生在规则生长过程中，即“预剪枝”，也可发生在规则产生后，即“后剪枝”：通常是基于某种性能度量指标来评估增/删逻辑文字前后的规则性能，或增/删规则前后的规则集性能，从而判断是否要进行剪枝.



剪枝还可借助统计显著性检验来进行。例如CN2算法［Clark and Niblett, 1989］在预剪枝时，假设用规则集进行预测必须显著优于直接基于训练样例集 后验概率分布进行预测。为便于计算，CN2使用了似然率统计量（Likelihood Ratio Statistics,简称LHS）.令 $m_+$ , $m_-$ 分别表示训练样例集中的正、反例数目，则有

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180701/dB5hi92AJg.png?imageslim)



这实际上是一种信息量指标，衡量了规则（集）覆盖样例的分布与训练集经验分 布的差别：
- LRS越大，说明采用规则（集）进行预测与直接使用训练集正、反例 比率进行猜测的差别越大；
- LRS越小，说明规则（集）的效果越可能仅是偶然现象

在数据量比较大的现实任务中，通常设置为在LRS很大（例如0.99）时CN2 算法才停止规则（集）生长.


后剪枝最常用的策略是 “减错剪枝” (Reduced Error Pruning,简称REP),其基本做法是：将样例集划分为训练集和验证集,从训练集上学得规则集 $\mathcal{R}$ 后进行多轮剪枝，在每一轮穷举所有可能的剪枝操作,包括删除规则中某个文字、删除规则结尾文字、删除规则尾部多个文字、 删除整条规则等，然后用验证集对剪枝产生的所有候选规则集进行评估，保留最好的那个规则集进行下一轮剪枝，如此继续，直到无法通过剪枝提高验证集上的性能为止。

REP剪枝通常很有效，但其复杂度是 $O(m^4)$ ，m 为训练样例数目。IREP (Incremental REP) 将复杂度降到 $O(mlog^2m)$ ,其做法是：在生成每条规则前，先将当前样例集划分为训练集和验证集，在训练集上生成一条规则 $r$，立即在验证集上对其进行REP剪枝，得到规则 $r'$ ;将 $r'$ 覆盖的样例去除，在更新后的样例集上重复上述过程。显然，REP 是针对规则集进行剪枝，而 IREP 仅对单条规则进行剪枝， 因此后者比前者更高效.


若将剪枝机制与其他一些后处理手段结合起来对规则集进行优化，则往往能获得更好的效果.以著名的规则学习算法 RIPPER 为例，其泛化性能超过很多决策树算法，而且学习速度也比大多数决策树算法更快，奥妙就在于将剪枝与后处理优化相结合.

![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180701/j8BK5165B4.png?imageslim)

RIPPER算法描述如图 15.2 所示.它先使用 $IREP*$ 剪枝机制生成规则集 $\mathcal{R}$ 。$IREP*$  是IREP的改进，主要是以 $\frac{\hat{m}+(m_--\hat{m}_-)}{m_++m_-}$ 取代了 IREP 使用的准确率作为规则性能度量指标，在剪枝时删除规则尾部的多个文字，并在最终得到规则集之后再进行一次 IREP 剪枝。RIPPER中的后处理机制是为了在剪枝的基础上进一步提升性能.对 $\mathcal{R}$ 中的每条规则 $r_i$ ,RIPPER 为它产生两个变体：

- $r_i'$:基于 $r_i$ 覆盖的样例，用 IREP* 重新生成一条规则 $r_i'$ ,该规则称为替换规则(replacement rule)
- $r_i''$:对 $r_i$ 増加文字进行特化，然后再用 IREP* 剪枝生成一条规则$r_i''$,该规则称为修订规则(revised rule)

接下来，把$r_i'$和$r_i''$分别与 $\mathcal{R}$ 中除 $r_i$ 之外的规则放在一起，组成规则集 $\mathcal{R}'$ 和 $\mathcal{R}''$ ,将它们与 $\mathcal{R}$ 一起进行比较，选择最优的规则集保留下来，这就是图 15.2 中算法第4行做的操作.

为什么RIPPER的优化策略会有效呢？原因很简单：最初生成 $\mathcal{R}$ 的时候，规则是按序生成的，每条规则都没有对其后产生的规则加以考虑，这样的贪心 算法本质常导致算法陷入局部最优；RIPPER的后处理优化过程将 $\mathcal{R}$ 中的所有规则放在一起重新加以优化，恰是通过全局的考虑来缓解贪心算法的局部性，从而往往能得到更好的效果。




# REF
1. 《机器学习》周志华
