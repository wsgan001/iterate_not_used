# ML 调参数


TODO

* 只是简单的提了下，要好好总结下。
* 调参数是在验证集上调的吗？与验证集到底是什么关系？
* 步长和范围是怎么选定的？
* 超多参数的时候怎么办？
* 调参数是在那一步进行的？
* grid search 一直想知道是什么？
* 要****自己用Python 和C++进行实现，同时在 scikit、tensorflow上进行实现，要找个简单的例子。






# 调参与最终模型


**这个关于调参的还是要单独拿出来吧？**


## 调参怎么调？


大多数学习算法都有些参数 (parameter) 需要设定，参数配置不同，学得模型的性能往往有显著差别.因此，在进行模型评估与选择时，除了要对适用学习算法进行选择，还需对算法参数进行设定，这就是通常所说的 “参数调节” 或简称“调参” (parameter tuning)。

例如：大型的 “深度学习”  模型甚至有上百亿个参数。

读者可能马上想到，调参和算法选择好像没有什么本质区别：我们对每种参数配置都训练出模型，然后把对应最好模型的参数作为结果。

这样的考虑基本上是正确的，但是有一点需注意：学习算法的很多参数是在实数范围内取值，因此,对每种参数配置都训练出模型来是不可行的。

现实中常用的做法，是对每个参数选定一个范围和变化步长，例如：在 ［0,0.2］ 范围内以0.05为步长，则实际要评估的候选参数值有5个，最终是从这 5 个候选值中产生选定值。

显然，这样选定的参数值往往不是“最佳”值，但是这也是在计算开销和性能估计之间进行折中的结果，通过这个折中，学习过程才变得可行。

事实上，即便在进行这样的折中后，调参往往还是很困难。可以简单估算一下：假定算法有3个参数,每个参数仅考虑5个候选 值，那么这样的每一组训练/测试集就有 \(5^3 = 125\) 个模型需考察。很多强大的学习算法有大量参数需要设定，这将导致极大的调参工程量，以至于在不少应用任务中，参数调得好不好往往对最终模型性能有关键性影响。**是呀怎么办呢？**












## REF

1. 《机器学习》周志华
