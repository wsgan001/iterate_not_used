
# 10.3 Apply：General split-apply-combine（应用：通用的分割-应用-合并）

>general-purpose: 可以理解为通用，泛用。

>例子：在计算机软件中，通用编程语言(General-purpose programming language )指被设计为各种应用领域服务的编程语言。通常通用编程语言不含有为特定应用领域设计的结构。

>相对而言，特定域编程语言就是为某一个特定的领域或应用软件设计的编程语言。比如说，LaTeX就是专门为排版文献而设计的语言。

最通用的GroupBy(分组)方法是apply，这也是本节的主题。如下图所示，apply会把对象分为多个部分，然后将函数应用到每一个部分上，然后把所有的部分都合并起来：

![](http://oydgk2hgw.bkt.clouddn.com/pydata-book/81f9f.png)

返回之前提到的tipping数据集，假设我们想要根据不同组（group），选择前5个tip_pct值最大的。首先，写一个函数，函数的功能为在特定的列，选出有最大值的行:


```python
import numpy as np
import pandas as pd
```


```python
tips = pd.read_csv('../examples/tips.csv')
```


```python
# Add tip percentage of total bill
tips['tip_pct'] = tips['tip'] / tips['total_bill']
```


```python
tips.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>total_bill</th>
      <th>tip</th>
      <th>smoker</th>
      <th>day</th>
      <th>time</th>
      <th>size</th>
      <th>tip_pct</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>16.99</td>
      <td>1.01</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>2</td>
      <td>0.059447</td>
    </tr>
    <tr>
      <th>1</th>
      <td>10.34</td>
      <td>1.66</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>3</td>
      <td>0.160542</td>
    </tr>
    <tr>
      <th>2</th>
      <td>21.01</td>
      <td>3.50</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>3</td>
      <td>0.166587</td>
    </tr>
    <tr>
      <th>3</th>
      <td>23.68</td>
      <td>3.31</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>2</td>
      <td>0.139780</td>
    </tr>
    <tr>
      <th>4</th>
      <td>24.59</td>
      <td>3.61</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>4</td>
      <td>0.146808</td>
    </tr>
  </tbody>
</table>
</div>




```python
def top(df, n=5, column='tip_pct'):
    return df.sort_values(by=column)[-n:]
```


```python
top(tips, n=6)
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>total_bill</th>
      <th>tip</th>
      <th>smoker</th>
      <th>day</th>
      <th>time</th>
      <th>size</th>
      <th>tip_pct</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>109</th>
      <td>14.31</td>
      <td>4.00</td>
      <td>Yes</td>
      <td>Sat</td>
      <td>Dinner</td>
      <td>2</td>
      <td>0.279525</td>
    </tr>
    <tr>
      <th>183</th>
      <td>23.17</td>
      <td>6.50</td>
      <td>Yes</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>4</td>
      <td>0.280535</td>
    </tr>
    <tr>
      <th>232</th>
      <td>11.61</td>
      <td>3.39</td>
      <td>No</td>
      <td>Sat</td>
      <td>Dinner</td>
      <td>2</td>
      <td>0.291990</td>
    </tr>
    <tr>
      <th>67</th>
      <td>3.07</td>
      <td>1.00</td>
      <td>Yes</td>
      <td>Sat</td>
      <td>Dinner</td>
      <td>1</td>
      <td>0.325733</td>
    </tr>
    <tr>
      <th>178</th>
      <td>9.60</td>
      <td>4.00</td>
      <td>Yes</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>2</td>
      <td>0.416667</td>
    </tr>
    <tr>
      <th>172</th>
      <td>7.25</td>
      <td>5.15</td>
      <td>Yes</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>2</td>
      <td>0.710345</td>
    </tr>
  </tbody>
</table>
</div>



现在，如果我们按smoker分组，然后用apply来使用这个函数，我们能得到下面的结果：


```python
tips.groupby('smoker').apply(top)
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>total_bill</th>
      <th>tip</th>
      <th>smoker</th>
      <th>day</th>
      <th>time</th>
      <th>size</th>
      <th>tip_pct</th>
    </tr>
    <tr>
      <th>smoker</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="5" valign="top">No</th>
      <th>88</th>
      <td>24.71</td>
      <td>5.85</td>
      <td>No</td>
      <td>Thur</td>
      <td>Lunch</td>
      <td>2</td>
      <td>0.236746</td>
    </tr>
    <tr>
      <th>185</th>
      <td>20.69</td>
      <td>5.00</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>5</td>
      <td>0.241663</td>
    </tr>
    <tr>
      <th>51</th>
      <td>10.29</td>
      <td>2.60</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>2</td>
      <td>0.252672</td>
    </tr>
    <tr>
      <th>149</th>
      <td>7.51</td>
      <td>2.00</td>
      <td>No</td>
      <td>Thur</td>
      <td>Lunch</td>
      <td>2</td>
      <td>0.266312</td>
    </tr>
    <tr>
      <th>232</th>
      <td>11.61</td>
      <td>3.39</td>
      <td>No</td>
      <td>Sat</td>
      <td>Dinner</td>
      <td>2</td>
      <td>0.291990</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">Yes</th>
      <th>109</th>
      <td>14.31</td>
      <td>4.00</td>
      <td>Yes</td>
      <td>Sat</td>
      <td>Dinner</td>
      <td>2</td>
      <td>0.279525</td>
    </tr>
    <tr>
      <th>183</th>
      <td>23.17</td>
      <td>6.50</td>
      <td>Yes</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>4</td>
      <td>0.280535</td>
    </tr>
    <tr>
      <th>67</th>
      <td>3.07</td>
      <td>1.00</td>
      <td>Yes</td>
      <td>Sat</td>
      <td>Dinner</td>
      <td>1</td>
      <td>0.325733</td>
    </tr>
    <tr>
      <th>178</th>
      <td>9.60</td>
      <td>4.00</td>
      <td>Yes</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>2</td>
      <td>0.416667</td>
    </tr>
    <tr>
      <th>172</th>
      <td>7.25</td>
      <td>5.15</td>
      <td>Yes</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>2</td>
      <td>0.710345</td>
    </tr>
  </tbody>
</table>
</div>



我们来解释下上面这一行代码发生了什么。这里的top函数，在每一个DataFrame中的行组（row group）都被调用了一次，然后各自的结果通过pandas.concat合并了，最后用组名（group names）来标记每一部分。（译者：可以理解为，我们先按smoker这一列对整个DataFrame进行了分组，一共有No和Yes两组，然后对每一组上调用了top函数，所以每一组会返还5行作为结果，最后把两组的结果整合起来，一共是10行）。

最后的结果是有多层级索引（hierarchical index）的，而且这个多层级索引的内部层级（inner level）含有来自于原来DataFrame中的索引值（index values）（译者：即在smoker为No的这一组，No本身是一个索引，它的内层索引是88, 185, 51, 149, 232这五个行索引，这五个内部层级是来自于原始DataFrame的）。

如果传递一个函数给apply，可以在函数之后，设定其他一些参数：


```python
tips.groupby(['smoker', 'day']).apply(top, n=1, column='total_bill')
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th></th>
      <th>total_bill</th>
      <th>tip</th>
      <th>smoker</th>
      <th>day</th>
      <th>time</th>
      <th>size</th>
      <th>tip_pct</th>
    </tr>
    <tr>
      <th>smoker</th>
      <th>day</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="4" valign="top">No</th>
      <th>Fri</th>
      <th>94</th>
      <td>22.75</td>
      <td>3.25</td>
      <td>No</td>
      <td>Fri</td>
      <td>Dinner</td>
      <td>2</td>
      <td>0.142857</td>
    </tr>
    <tr>
      <th>Sat</th>
      <th>212</th>
      <td>48.33</td>
      <td>9.00</td>
      <td>No</td>
      <td>Sat</td>
      <td>Dinner</td>
      <td>4</td>
      <td>0.186220</td>
    </tr>
    <tr>
      <th>Sun</th>
      <th>156</th>
      <td>48.17</td>
      <td>5.00</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>6</td>
      <td>0.103799</td>
    </tr>
    <tr>
      <th>Thur</th>
      <th>142</th>
      <td>41.19</td>
      <td>5.00</td>
      <td>No</td>
      <td>Thur</td>
      <td>Lunch</td>
      <td>5</td>
      <td>0.121389</td>
    </tr>
    <tr>
      <th rowspan="4" valign="top">Yes</th>
      <th>Fri</th>
      <th>95</th>
      <td>40.17</td>
      <td>4.73</td>
      <td>Yes</td>
      <td>Fri</td>
      <td>Dinner</td>
      <td>4</td>
      <td>0.117750</td>
    </tr>
    <tr>
      <th>Sat</th>
      <th>170</th>
      <td>50.81</td>
      <td>10.00</td>
      <td>Yes</td>
      <td>Sat</td>
      <td>Dinner</td>
      <td>3</td>
      <td>0.196812</td>
    </tr>
    <tr>
      <th>Sun</th>
      <th>182</th>
      <td>45.35</td>
      <td>3.50</td>
      <td>Yes</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>3</td>
      <td>0.077178</td>
    </tr>
    <tr>
      <th>Thur</th>
      <th>197</th>
      <td>43.11</td>
      <td>5.00</td>
      <td>Yes</td>
      <td>Thur</td>
      <td>Lunch</td>
      <td>4</td>
      <td>0.115982</td>
    </tr>
  </tbody>
</table>
</div>



除了上面这些基本用法，要想用好apply可能需要一点创新能力。毕竟传给这个函数的内容取决于我们自己，而最终的结果只需要返回一个pandas对象或一个标量。这一章的剩余部分主要介绍如何解决在使用groupby时遇到的一些问题。

可以试一试在GroupBy对象上调用describe：


```python
result = tips.groupby('smoker')['tip_pct'].describe()
```


```python
result
```




    smoker       
    No      count    151.000000
            mean       0.159328
            std        0.039910
            min        0.056797
            25%        0.136906
            50%        0.155625
            75%        0.185014
            max        0.291990
    Yes     count     93.000000
            mean       0.163196
            std        0.085119
            min        0.035638
            25%        0.106771
            50%        0.153846
            75%        0.195059
            max        0.710345
    Name: tip_pct, dtype: float64




```python
result.unstack('smoker')
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>smoker</th>
      <th>No</th>
      <th>Yes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>151.000000</td>
      <td>93.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.159328</td>
      <td>0.163196</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.039910</td>
      <td>0.085119</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.056797</td>
      <td>0.035638</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.136906</td>
      <td>0.106771</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>0.155625</td>
      <td>0.153846</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>0.185014</td>
      <td>0.195059</td>
    </tr>
    <tr>
      <th>max</th>
      <td>0.291990</td>
      <td>0.710345</td>
    </tr>
  </tbody>
</table>
</div>



在GroupBy内部，当我们想要调用一个像describe这样的函数的时候，其实相当于下面的写法：

    f = lambda x: x.describe()
    grouped.apply(f)
    
# 1 Suppressing the Group Keys（抑制组键）

在接下来的例子，我们会看到作为结果的对象有一个多层级索引（hierarchical index），这个多层级索引是由原来的对象中，组键（group key）在每一部分的索引上得到的。我们可以在groupby函数中设置group_keys=False来关闭这个功能：


```python
tips.groupby('smoker', group_keys=False).apply(top)
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>total_bill</th>
      <th>tip</th>
      <th>smoker</th>
      <th>day</th>
      <th>time</th>
      <th>size</th>
      <th>tip_pct</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>88</th>
      <td>24.71</td>
      <td>5.85</td>
      <td>No</td>
      <td>Thur</td>
      <td>Lunch</td>
      <td>2</td>
      <td>0.236746</td>
    </tr>
    <tr>
      <th>185</th>
      <td>20.69</td>
      <td>5.00</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>5</td>
      <td>0.241663</td>
    </tr>
    <tr>
      <th>51</th>
      <td>10.29</td>
      <td>2.60</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>2</td>
      <td>0.252672</td>
    </tr>
    <tr>
      <th>149</th>
      <td>7.51</td>
      <td>2.00</td>
      <td>No</td>
      <td>Thur</td>
      <td>Lunch</td>
      <td>2</td>
      <td>0.266312</td>
    </tr>
    <tr>
      <th>232</th>
      <td>11.61</td>
      <td>3.39</td>
      <td>No</td>
      <td>Sat</td>
      <td>Dinner</td>
      <td>2</td>
      <td>0.291990</td>
    </tr>
    <tr>
      <th>109</th>
      <td>14.31</td>
      <td>4.00</td>
      <td>Yes</td>
      <td>Sat</td>
      <td>Dinner</td>
      <td>2</td>
      <td>0.279525</td>
    </tr>
    <tr>
      <th>183</th>
      <td>23.17</td>
      <td>6.50</td>
      <td>Yes</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>4</td>
      <td>0.280535</td>
    </tr>
    <tr>
      <th>67</th>
      <td>3.07</td>
      <td>1.00</td>
      <td>Yes</td>
      <td>Sat</td>
      <td>Dinner</td>
      <td>1</td>
      <td>0.325733</td>
    </tr>
    <tr>
      <th>178</th>
      <td>9.60</td>
      <td>4.00</td>
      <td>Yes</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>2</td>
      <td>0.416667</td>
    </tr>
    <tr>
      <th>172</th>
      <td>7.25</td>
      <td>5.15</td>
      <td>Yes</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>2</td>
      <td>0.710345</td>
    </tr>
  </tbody>
</table>
</div>



# 2 Quantile and Bucket Analysis（分位数与桶分析）

在第八章中，我们介绍了pandas的一些工具，比如cut和qcut，通过设置中位数，切割数据为buckets with bins(有很多箱子的桶)。

> 这里bucket我翻译为桶，可以理解为像group一样的概念，一个组内有不同的bins。而关于bins（箱）的部分，可以回顾看一下7.2

把函数通过groupby整合起来，可以在做桶分析或分位数分析的时候更方便。假设一个简单的随机数据集和一个等长的桶类型（bucket categorization），使用cut：


```python
frame = pd.DataFrame({'data1': np.random.randn(1000),
                       'data2': np.random.randn(1000)})
frame.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>data1</th>
      <th>data2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.723973</td>
      <td>0.120216</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.053617</td>
      <td>0.468000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.543073</td>
      <td>-1.874073</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.915136</td>
      <td>0.159179</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.775965</td>
      <td>0.105447</td>
    </tr>
  </tbody>
</table>
</div>




```python
quartiles = pd.cut(frame.data1, 4)
quartiles[:10]
```




    0     (0.194, 1.795]
    1     (1.795, 3.395]
    2    (-1.407, 0.194]
    3    (-1.407, 0.194]
    4     (0.194, 1.795]
    5     (0.194, 1.795]
    6     (0.194, 1.795]
    7    (-1.407, 0.194]
    8    (-1.407, 0.194]
    9    (-1.407, 0.194]
    Name: data1, dtype: category
    Categories (4, object): [(-3.0139, -1.407] < (-1.407, 0.194] < (0.194, 1.795] < (1.795, 3.395]]



cut返回的Categorical object（类别对象）能直接传入groupby。所以我们可以在data2列上计算很多统计值：


```python
def get_stats(group):
    return {'min': group.min(), 'max': group.max(),
            'count': group.count(), 'mean': group.mean()}
```


```python
grouped = frame.data2.groupby(quartiles)
```


```python
grouped.apply(get_stats).unstack()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>max</th>
      <th>mean</th>
      <th>min</th>
    </tr>
    <tr>
      <th>data1</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>(-3.0139, -1.407]</th>
      <td>70.0</td>
      <td>2.035166</td>
      <td>0.113238</td>
      <td>-2.363707</td>
    </tr>
    <tr>
      <th>(-1.407, 0.194]</th>
      <td>481.0</td>
      <td>3.284688</td>
      <td>-0.044535</td>
      <td>-2.647341</td>
    </tr>
    <tr>
      <th>(0.194, 1.795]</th>
      <td>407.0</td>
      <td>2.402272</td>
      <td>-0.043887</td>
      <td>-2.898145</td>
    </tr>
    <tr>
      <th>(1.795, 3.395]</th>
      <td>42.0</td>
      <td>2.051843</td>
      <td>0.095178</td>
      <td>-2.234979</td>
    </tr>
  </tbody>
</table>
</div>



也有相同长度的桶（equal-length buckets）；想要按照样本的分位数得到相同长度的桶，用qcut。这里设定labels=False来得到分位数的数量：


```python
# Return quantile numbers
grouping = pd.qcut(frame.data1, 10, labels=False)
```

译者：上面的代码是把frame的data1列分为10个bin，每个bin都有相同的数量。因为一共有1000个样本，所以每个bin里有100个样本。grouping保存的是每个样本的index以及其对应的bin的编号。


```python
grouped = frame.data2.groupby(grouping)
```


```python
grouped.apply(get_stats).unstack()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>max</th>
      <th>mean</th>
      <th>min</th>
    </tr>
    <tr>
      <th>data1</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>100.0</td>
      <td>2.178653</td>
      <td>0.078390</td>
      <td>-2.363707</td>
    </tr>
    <tr>
      <th>1</th>
      <td>100.0</td>
      <td>3.284688</td>
      <td>-0.018699</td>
      <td>-2.647341</td>
    </tr>
    <tr>
      <th>2</th>
      <td>100.0</td>
      <td>2.214011</td>
      <td>-0.066341</td>
      <td>-2.262063</td>
    </tr>
    <tr>
      <th>3</th>
      <td>100.0</td>
      <td>2.880188</td>
      <td>-0.014041</td>
      <td>-2.475753</td>
    </tr>
    <tr>
      <th>4</th>
      <td>100.0</td>
      <td>2.741344</td>
      <td>-0.007952</td>
      <td>-2.576095</td>
    </tr>
    <tr>
      <th>5</th>
      <td>100.0</td>
      <td>2.346857</td>
      <td>-0.109602</td>
      <td>-2.898145</td>
    </tr>
    <tr>
      <th>6</th>
      <td>100.0</td>
      <td>2.402272</td>
      <td>0.004522</td>
      <td>-1.911955</td>
    </tr>
    <tr>
      <th>7</th>
      <td>100.0</td>
      <td>2.351513</td>
      <td>-0.161472</td>
      <td>-2.640625</td>
    </tr>
    <tr>
      <th>8</th>
      <td>100.0</td>
      <td>2.135995</td>
      <td>-0.016079</td>
      <td>-1.986676</td>
    </tr>
    <tr>
      <th>9</th>
      <td>100.0</td>
      <td>2.051843</td>
      <td>0.037685</td>
      <td>-2.513164</td>
    </tr>
  </tbody>
</table>
</div>



对于pandas的Categorical类型，会在第十二章做详细介绍。

# 3 Example: Filling Missing Values with Group-Specific Values（例子：用组特异性值来填充缺失值）

在处理缺失值的时候，一些情况下我们会直接用dropna来把缺失值删除，但另一些情况下，我们希望用一些固定的值来代替缺失值，而fillna就是用来做这个的，例如，这里我们用平均值mean来代替缺失值NA：


```python
s = pd.Series(np.random.randn(6))
```


```python
s[::2] = np.nan
```


```python
s
```




    0         NaN
    1    0.878562
    2         NaN
    3   -0.264051
    4         NaN
    5    0.760488
    dtype: float64




```python
s.fillna(s.mean())
```




    0    0.458333
    1    0.878562
    2    0.458333
    3   -0.264051
    4    0.458333
    5    0.760488
    dtype: float64



假设我们想要给每一组填充不同的值。一个方法就是对数据分组后，用apply来调用fillna，在每一个组上执行一次。这里有一些样本是把美国各州分为西部和东部：


```python
states = ['Ohio', 'New York', 'Vermont', 'Florida',
          'Oregon', 'Nevada', 'California', 'Idaho']
```


```python
group_key = ['East'] * 4 + ['West'] * 4
group_key
```




    ['East', 'East', 'East', 'East', 'West', 'West', 'West', 'West']




```python
data = pd.Series(np.random.randn(8), index=states)
data
```




    Ohio          0.683283
    New York     -1.059896
    Vermont       0.105837
    Florida      -0.328586
    Oregon        1.973413
    Nevada        0.656673
    California    0.001700
    Idaho        -0.713295
    dtype: float64



我们令data中某些值为缺失值：


```python
data[['Vermont', 'Nevada', 'Idaho']] = np.nan
data
```




    Ohio          0.683283
    New York     -1.059896
    Vermont            NaN
    Florida      -0.328586
    Oregon        1.973413
    Nevada             NaN
    California    0.001700
    Idaho              NaN
    dtype: float64




```python
data.groupby(group_key).mean()
```




    East   -0.235066
    West    0.987556
    dtype: float64



然后我们可以用每个组的平均值来填充NA：


```python
fill_mean = lambda g: g.fillna(g.mean())
```


```python
data.groupby(group_key).apply(fill_mean)
```




    Ohio          0.683283
    New York     -1.059896
    Vermont      -0.235066
    Florida      -0.328586
    Oregon        1.973413
    Nevada        0.987556
    California    0.001700
    Idaho         0.987556
    dtype: float64



在另外一些情况下，我们可能希望提前设定好用于不同组的填充值。因为group有一个name属性，我们可以利用这个：


```python
fill_values = {'East': 0.5, 'West': -1}
```


```python
fill_func = lambda g: g.fillna(fill_values[g.name])
```


```python
data.groupby(group_key).apply(fill_func)
```




    Ohio          0.683283
    New York     -1.059896
    Vermont       0.500000
    Florida      -0.328586
    Oregon        1.973413
    Nevada       -1.000000
    California    0.001700
    Idaho        -1.000000
    dtype: float64



# 4 Example: Random Sampling and Permutation（例子：随机抽样和排列）

假设我们想要从一个很大的数据集里随机抽出一些样本，这里我们可以在Series上用sample方法。为了演示，这里县创建一副模拟的扑克牌：


```python
# Hearts红桃，Spades黑桃，Clubs梅花，Diamonds方片
suits = ['H', 'S', 'C', 'D']
card_val = (list(range(1, 11)) + [10] * 3) * 4
base_names = ['A'] + list(range(2, 11)) + ['J', 'K', 'Q']
cards = []
for suit in ['H', 'S', 'C', 'D']:
    cards.extend(str(num) + suit for num in base_names)

deck = pd.Series(card_val, index=cards)
```

这样我们就得到了一个长度为52的Series，索引（index）部分是牌的名字，对应的值为牌的点数，这里的点数是按Blackjack（二十一点）的游戏规则来设定的。

> Blackjack（二十一点）: 2点至10点的牌以牌面的点数计算，J、Q、K 每张为10点，A可记为1点或为11点。这里为了方便，我们只把A记为1点。


```python
deck[:13]
```




    AH      1
    2H      2
    3H      3
    4H      4
    5H      5
    6H      6
    7H      7
    8H      8
    9H      9
    10H    10
    JH     10
    KH     10
    QH     10
    dtype: int64



现在，就像我们上面说的，随机从牌组中抽出5张牌：


```python
def draw(deck, n=5):
    return deck.sample(n)
```


```python
draw(deck)
```




    7H     7
    6D     6
    AC     1
    JH    10
    JS    10
    dtype: int64



假设我们想要从每副花色中随机抽取两张，花色是每张牌名字的最后一个字符（即H, S, C, D），我们可以根据花色分组，然后使用apply：


```python
get_suit = lambda card: card[-1] # last letter is suit
```


```python
deck.groupby(get_suit).apply(draw, n=2)
```




    C  QC    10
       9C     9
    D  3D     3
       JD    10
    H  KH    10
       6H     6
    S  3S     3
       7S     7
    dtype: int64



另外一种写法：


```python
deck.groupby(get_suit, group_keys=False).apply(draw, n=2)
```




    7C     7
    KC    10
    AD     1
    4D     4
    AH     1
    8H     8
    7S     7
    9S     9
    dtype: int64



# 5 Example: Group Weighted Average and Correlation（例子：组加权平均和相关性）

在groupby的split-apply-combine机制下，DataFrame的两列或两个Series，计算组加权平均（Group Weighted Average）是可能的。这里举个例子，下面的数据集包含组键，值，以及权重：


```python
df = pd.DataFrame({'category': ['a', 'a', 'a', 'a',
                                'b', 'b', 'b', 'b'],
                   'data': np.random.randn(8),
                   'weights': np.random.rand(8)})
df
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>category</th>
      <th>data</th>
      <th>weights</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>a</td>
      <td>0.098020</td>
      <td>0.008455</td>
    </tr>
    <tr>
      <th>1</th>
      <td>a</td>
      <td>1.389496</td>
      <td>0.826219</td>
    </tr>
    <tr>
      <th>2</th>
      <td>a</td>
      <td>0.202869</td>
      <td>0.258955</td>
    </tr>
    <tr>
      <th>3</th>
      <td>a</td>
      <td>-0.242403</td>
      <td>0.470473</td>
    </tr>
    <tr>
      <th>4</th>
      <td>b</td>
      <td>-0.820507</td>
      <td>0.628758</td>
    </tr>
    <tr>
      <th>5</th>
      <td>b</td>
      <td>0.866326</td>
      <td>0.653632</td>
    </tr>
    <tr>
      <th>6</th>
      <td>b</td>
      <td>-1.297375</td>
      <td>0.639703</td>
    </tr>
    <tr>
      <th>7</th>
      <td>b</td>
      <td>0.525019</td>
      <td>0.012664</td>
    </tr>
  </tbody>
</table>
</div>



按category分组来计算组加权平均：


```python
grouped = df.groupby('category')
```


```python
get_wavg = lambda g: np.average(g['data'], weights=g['weights'])
```


```python
grouped.apply(get_wavg)
```




    category
    a    0.695189
    b   -0.399497
    dtype: float64



另一个例子，考虑一个从Yahoo！财经上得到的经济数据集，包含一些股票交易日结束时的股价，以及S&P 500指数(即SPX符号)：

>标准普尔500指数英文简写为S&P 500 Index，是记录美国500家上市公司的一个股票指数。这个股票指数由标准普尔公司创建并维护。

>标准普尔500指数覆盖的所有公司，都是在美国主要交易所，如纽约证券交易所、Nasdaq交易的上市公司。与道琼斯指数相比，标准普尔500指数包含的公司更多，因此风险更为分散，能够反映更广泛的市场变化。


```python
close_px = pd.read_csv('../examples/stock_px_2.csv', parse_dates=True,
                       index_col=0)
```


```python
close_px.info()
```

    <class 'pandas.core.frame.DataFrame'>
    DatetimeIndex: 2214 entries, 2003-01-02 to 2011-10-14
    Data columns (total 4 columns):
    AAPL    2214 non-null float64
    MSFT    2214 non-null float64
    XOM     2214 non-null float64
    SPX     2214 non-null float64
    dtypes: float64(4)
    memory usage: 86.5 KB
    


```python
close_px[-4:]
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>AAPL</th>
      <th>MSFT</th>
      <th>XOM</th>
      <th>SPX</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2011-10-11</th>
      <td>400.29</td>
      <td>27.00</td>
      <td>76.27</td>
      <td>1195.54</td>
    </tr>
    <tr>
      <th>2011-10-12</th>
      <td>402.19</td>
      <td>26.96</td>
      <td>77.16</td>
      <td>1207.25</td>
    </tr>
    <tr>
      <th>2011-10-13</th>
      <td>408.43</td>
      <td>27.18</td>
      <td>76.37</td>
      <td>1203.66</td>
    </tr>
    <tr>
      <th>2011-10-14</th>
      <td>422.00</td>
      <td>27.27</td>
      <td>78.11</td>
      <td>1224.58</td>
    </tr>
  </tbody>
</table>
</div>



一个比较有意思的尝试是计算一个DataFrame，包括与SPX这一列逐年日收益的相关性（计算百分比变化）。一个可能的方法是，我们先创建一个能计算不同列相关性的函数，然后拿每一列与SPX这一列求相关性：


```python
spx_corr = lambda x: x.corrwith(x['SPX'])
```

然后我们通过pct_change在close_px上计算百分比的变化：


```python
rets = close_px.pct_change().dropna()
```

最后，我们按年来给这些百分比变化分组，年份可以从每行的标签中通过一个一行函数提取，然后返回的结果中，用datetime标签来表示年份：


```python
get_year = lambda x: x.year
```


```python
by_year = rets.groupby(get_year)
```


```python
by_year.apply(spx_corr)
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>AAPL</th>
      <th>MSFT</th>
      <th>XOM</th>
      <th>SPX</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2003</th>
      <td>0.541124</td>
      <td>0.745174</td>
      <td>0.661265</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2004</th>
      <td>0.374283</td>
      <td>0.588531</td>
      <td>0.557742</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2005</th>
      <td>0.467540</td>
      <td>0.562374</td>
      <td>0.631010</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2006</th>
      <td>0.428267</td>
      <td>0.406126</td>
      <td>0.518514</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2007</th>
      <td>0.508118</td>
      <td>0.658770</td>
      <td>0.786264</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2008</th>
      <td>0.681434</td>
      <td>0.804626</td>
      <td>0.828303</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2009</th>
      <td>0.707103</td>
      <td>0.654902</td>
      <td>0.797921</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2010</th>
      <td>0.710105</td>
      <td>0.730118</td>
      <td>0.839057</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2011</th>
      <td>0.691931</td>
      <td>0.800996</td>
      <td>0.859975</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>



我们也可以计算列内的相关性。这里我们计算苹果和微软每年的相关性：


```python
by_year.apply(lambda g: g['AAPL'].corr(g['MSFT']))
```




    2003    0.480868
    2004    0.259024
    2005    0.300093
    2006    0.161735
    2007    0.417738
    2008    0.611901
    2009    0.432738
    2010    0.571946
    2011    0.581987
    dtype: float64



# 6 Example: Group-Wise Linear Regression（例子：组对组的线性回归）

就像上面介绍的例子，使用groupby可以用于更复杂的组对组统计分析，只要函数能返回一个pandas对象或标量。例如，我们可以定义regress函数（利用statsmodels库），在每一个数据块（each chunk of data）上进行普通最小平方回归（ordinary least squares (OLS) regression）计算：


```python
import statsmodels.api as sm
```


```python
def regress(data, yvar, xvars):
    Y = data[yvar]
    X = data[xvars]
    X['intercept'] = 1
    result = sm.OLS(Y, X).fit()
    return result.params
```

现在，按年用苹果AAPL在标普SPX上做线性回归：


```python
by_year.apply(regress, 'AAPL', ['SPX'])
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SPX</th>
      <th>intercept</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2003</th>
      <td>1.195406</td>
      <td>0.000710</td>
    </tr>
    <tr>
      <th>2004</th>
      <td>1.363463</td>
      <td>0.004201</td>
    </tr>
    <tr>
      <th>2005</th>
      <td>1.766415</td>
      <td>0.003246</td>
    </tr>
    <tr>
      <th>2006</th>
      <td>1.645496</td>
      <td>0.000080</td>
    </tr>
    <tr>
      <th>2007</th>
      <td>1.198761</td>
      <td>0.003438</td>
    </tr>
    <tr>
      <th>2008</th>
      <td>0.968016</td>
      <td>-0.001110</td>
    </tr>
    <tr>
      <th>2009</th>
      <td>0.879103</td>
      <td>0.002954</td>
    </tr>
    <tr>
      <th>2010</th>
      <td>1.052608</td>
      <td>0.001261</td>
    </tr>
    <tr>
      <th>2011</th>
      <td>0.806605</td>
      <td>0.001514</td>
    </tr>
  </tbody>
</table>
</div>


